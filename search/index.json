[{"categories":["TUD"],"contents":"Kurs Katalog Sommersemester 2021 INF-BAS3 Software- und Web-Engineering   Component-based Software Engineering (2/2/0)\n  Internet and Web Applications (2/2/0)\n  Software Fault Tolerance (2/2/0)\n  Softwaremanagement (2/2/0)\n  Spatiotemporal Modeling and Simulation of Biological Systems (2/2/0)\n  INF-BAS4 Systemarchitektur   Internet and Web Applications (2/2/0)\n  Software Fault Tolerance (2/2/0)\n  Distributed Operating Systems (2/1/0)\n  Wireless Sensor Networks (2/2/0)\n  INF-BAS6 Theoretische Informatik   Database Theory (4/2/0)\n  Einführung in das maschinelle Übersetzen natürlicher Sprachen (2/2/0)\n  INF-BAS7 Graphische Datenverarbeitung   Spatiotemporal Modeling and Simulation of Biological Systems (2/2/0)\n  Scientific Visualization (2/2/0)\n  ","permalink":"https://daijiabin.github.io/2021-sose/","tags":["Kurse"],"title":"2021 Sose"},{"categories":["Tool"],"contents":"Idea Tools - IntelliJ ShortCuts   psvm $\\rarr$ public static void main(String[] args){}\n  sout $\\rarr$ System.out.println()\n  CTRL + y $\\rarr$ delete a row\n  ALT + Insert $\\rarr$ add Something new\n  CTRL + SHIFT + F12 $\\rarr$ close Side-Window\n  ALT +  $\\rarr$ || $\\larr$ change the Tab\n  ALT + \\text{number} change Windows\n  CTRL + p remind Parameters in Functions\n  ","permalink":"https://daijiabin.github.io/idea-tools/","tags":["Tool"],"title":"Idea Tools"},{"categories":["Learn"],"contents":"Unix Programming Bash  Shortcuts     Function Shortcuts Help     previous Command CTRL + p previous   next Command CTRL + n next   move forward CTRL + f move forward   move backward CTRL + b move backwoard   Del CTRL + d delete   Home CTRL + a move to the Begin   End CTRL + e move to the End    Directories in UNIX  / root Directory  /bin executable Programms, like Commands /boot Kernerl and Initialization Programms /dev Devices /etc Config and Startup Files /home User\u0026rsquo;s main Directory /lib Library Files for System Programms /media media Devices like CD-ROM, USB Stick /mnt Temporate Mount-System /proc Memopry\u0026rsquo;s Map /sbin Super User executable Programms /usr  /usr/bin executable Programms / Applications /usr/game      Some often-used Commands Link  ln -s \u0026lt;Source\u0026gt; \u0026lt;Your_Link_Name\u0026gt; create a soft Link. Without the -s Parameter a hard Link will be created.  Search   find \u0026lt;Search_Directory\u0026gt; -name \u0026lt;File_Name\u0026gt;\n  grep \u0026lt;Pattern\u0026gt; \u0026lt;Search_Directory\u0026gt;\n  apt   Change Source\nedit the file /etc/apt/source.list\n  search Software\nsudo apt-cache search package\n  fix the Installation\nsudo apt-get -f install\n  install relative compile Enviroment\nsudo apt-get build-dep package\n  upgrade the System\nsudo apt-get dist-upgrade\n  get to know Depends\nsudo apt-cache depends package\n  dpkg   uninstall\nsudo dpkg -r --purge xxx.deb\n  get Infos\nsudo dpkg -info xxx.deb\n  show installed\nsudo dpkg -l\n  devices   get Infos about Disks\nsudo fdisk -l\n  mount the Disk\nmount \u0026lt;Device_Name\u0026gt; \u0026lt;Aim-Directory\u0026gt;\n  unmount the Disk\numount \u0026lt;Aim-Directory\u0026gt;\n  copy\ndd if=\u0026lt;InputFile\u0026gt; of=\u0026lt;OutputFile\u0026gt; [bs=\u0026lt;File_Size\u0026gt; count=\u0026lt;Block_Size\u0026gt;]\n  compressed Files tar   compress\ntar cvf \u0026lt;.tar File\u0026gt; \u0026lt;Source\u0026gt;\n  decompress\ntar xvf \u0026lt;.tar File\u0026gt; [-C \u0026lt;Aim-Directory\u0026gt;]\n  tar.gz   compress\ntar zcvf \u0026lt;.tar.gz File\u0026gt; \u0026lt;Source\u0026gt;\n  decompress\ntar zxvf \u0026lt;.tar.gz File\u0026gt; [-C \u0026lt;Aim-Directory\u0026gt;]\n  tar.bz2   compress\ntar jcvf \u0026lt;.tar.bz2 File\u0026gt; \u0026lt;Source\u0026gt;\n  decompress\ntar -jxvf \u0026lt;.tar.bz2 File\u0026gt; [-C \u0026lt;Aim-Directory\u0026gt;]\n  rar   compress\nrar a -r \u0026lt;.rar File\u0026gt; \u0026lt;Directory_Name\u0026gt;\n  decompress\nunrar x \u0026lt;.rar File\u0026gt;\n  zip   compress\nzip -r \u0026lt;.zip File\u0026gt; \u0026lt;Directory\u0026gt;\n  decompress\nunzip \u0026lt;.zipFile\u0026gt;\n  Process ps   ps aux\n  ps ajx\n  ps -Lf\n  kill kill [ -signal| -s signal ] pid ...\nkill -l\nenv   env check the Environment\n  add new $PATH:\n  for self, export PATH=$PATH:\u0026lt;path\u0026gt; in ~/.bashrc\n  for all users, export PATH=$PATH:\u0026lt;path\u0026gt; in /etc/profile\n    Networks   Info of Netcard\nifconfig\n  shutdown Netcard\nsudo ifconfig eth0 down\n  start Netcard\nsudo ifconfig eth0 up\n  assign temporary IP\nsudo ifconfig eth0 IP\n  Status of Network\nnetstat\n  transform WWW to IP\nnslookup\n  ","permalink":"https://daijiabin.github.io/unix-programming/","tags":["Unix"],"title":"Unix Programming"},{"categories":["Learn"],"contents":"Operating System ","permalink":"https://daijiabin.github.io/operating-system/","tags":["Basic of CS"],"title":"Operating System"},{"categories":["Learn"],"contents":"Computer Networks   Foreword:\nReferences:\n Videos: 2021王道计算机网络 on YouTube eBook: Google Drive Link here (Chinese)  Power Point: Google Drive Link here (Chinese)     Ch 01. System\u0026rsquo;s Structure of Computer Networks   Definition:\nA System that connects distributed and independent Computer Systems through Devices and Cables, therefore the Resources-Sharing and Information-Transportation are realized. It\u0026rsquo;s a Combination of connected and independent Computers.\n  Functions:\n  Data Communication\n  Resources-Sharing\n  Process distributly\n  Improve the Reliability\n  Balance the Load\n    Development:\nAPARnet -\u0026gt; internet -\u0026gt; Internet\n  3-Structures Internet:\nBottom layer network -\u0026gt; middle layer network -\u0026gt; backbone network\n  Some Terminologys:\n  ISP - Internet Service Provider\n  IXP - Internet Exchange Point\n  PCI ( Protocol Control Information ) + SDU ( Service Data Unit ) = PDU ( Protocol Data Unit, Unit between same-level Transportation )\n    Standards\n  OSI, TCP/IP\n  RFC ( Request For Comments ):\n Internet Draft Proposed Standard Draft Standard Internet Standard      Performance Indicators   Speed:\n  Transportation\u0026rsquo;s Speed: b/s ( $\\times10^3$ ) $\\rarr$ kb/s ( $\\times10^3$ ) $\\rarr$Mb/s ( $\\times10^3$ ) $\\rarr$Gb/s ( $\\times10^3$ ) $\\rarr$Tb/s\u0026hellip;\n  Difference in Storage: 1Byte = 8bit, 1KB = $2^{10}$ B = 1024B = 1024 $\\times$ 8b\n    Band-Width:\n The Capacity of the Transportation of the Cable. Normally it refers to the highest Speed from one Point to another Point in Internet in Element-Time. Unit see above.    Throughput:\n  The Amount of Data that go through the Internet in Unit-Time. Unit see above.\n  It\u0026rsquo;s limited by Band-Width.\n    Delay:\n  Sending-Delay:\n$\\text{S-Delay} = \\frac{\\text{Length of Data}}{\\text{Band-width}}$\n  Transportation-Delay:\n$\\text{T-Delay} = \\frac{\\text{Length of Band}}{\\text{Electromagnetic wave speed}}$\n  Pending-Delay:\nWait for the Usage of I/O Route\n  Process-Delay:\nProcedure with the Data\n    Time delay bandwidth product:\n  $\\text{Time delay bandwidth product} = \\text{Transportation-Delay} \\times \\text{Band-width}$\n  It talks about the Capacity of the Pipe.\n    RTT:\n  Delay between Sending and the Receive-Confirmation\n  Includes Transportation-Delay * 2 + Process-Time\n    Utilization rate\n Band Utilization Rate: $\\frac{\\text{Time, when Data pass}}{\\text{Time, when Data pass and not pass}}$    OSI Reference Module   Structure:\nPhysic Layer $\\rarr$ Data Link Layer $\\rarr$ Network Layer $\\rarr$ Transportation Layer ($\\rarr$ Session Layer $\\rarr$ Representation Layer) $\\rarr$ Uasge Layer\n  Functions of Representation Layer\n Transform the Data Format Encrypt / Decrypt the Data Compress and Decompress the Data    Functions of Session Layer\n Creates, manage and terminites the Session Restore the Communication through Checkpoint when something wrong goes with the Communication ( SYN ).    Functions of Transportation Layer\np.S. Responsible for the Communications between 2 Processes ( P2P )\n Reliable / Unreliable Transportation Control of Errors Control of Flow Multiplexing and splitting    Functions of Network Layer\np.S. Transport the Groups from Source to the End, provide the Communication Service for the Groups to swap different Hosts.\n Select the Route Control of Flow Control of Errors Control of Congestion    Functions of Data Link Layer\n Define the Begin and the End of the Frame Control of Errors ( Frame Error, Bit Error ) Control of Flow Control of Access    Functions of Physic Layer\n Define the Features of Interface Define the Transportation Mode Define the Transportation Speed Synchronization the Bits Encode the Bits    Ch 02. Physical Layer Basic Concepts   Physical Layer solves how to transport Data Bit Flow on the Transportation Media on Hosts.\n  Contains Mechanical Features, Electronic Features, Functional Features and Process Features.\n  ","permalink":"https://daijiabin.github.io/computer-networks/","tags":["Basic of CS"],"title":"Computer Networks"},{"categories":["Learn"],"contents":"Spring Notes Day 01. Basic Concepts  Kernel Techs: IoC(Inversion of Control) and aop. Loose the Relationships between Modules.  IoC ( Inversion of Control )   Creation, Value-Given and Management belong to the Containers beyond Codes.\n  Management:\nCreation, Attributes-Given and Management of the Relationships of Objects.\n  Inversion:\nTransfer the Rights of Management, Creation of Objects to the Containers ( here: Spring ) beyond Codes.\n  WHY IoC:\nWe\u0026rsquo;re LAZY. This can make the Management of Objects easier.\n  DI ( Dependency Injection ): Technic Realization\nOffer the Object\u0026rsquo;s Name only, no need to care how it\u0026rsquo;s created, value given and search, etc. In Spring, Reflection is used.\n  ","permalink":"https://daijiabin.github.io/spring/","tags":["Framework"],"title":"Spring"},{"categories":["Learn"],"contents":"Java Learning ( Data Structures, mostly ) \u0026hellip; And the greatest reason I learn it, is that I LOVE COFFEE ☕ its DS are soooooooooooo smoooooooth.\n01. Basic Usage in Java Way to write   A .java File can be compiled through javac into .class File. .java File is called Source Code, after Compling it can be deleted.\n  In every .java File can multiple Class be written. In every Class can multiple Methods be written.\n  After Compiling, execute java class_name in Terminal to run Functions in a specific class.\n  A .java File can contain multipule class, but only 1 public class. Besides, the name of the public class must be same as the .java file.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // C.java class A{ public static void main(String[] args){ //Codes here  } } class B{ public static void main(String[] args){ // Codes here  } } public class C{ public static void main(String[] args){ // Codes here  } }     In every class, there is only 1 main Method. The way to write it is always this:\n1 2 3 4 5 6 7  public class C{ public static void main(String[] args){ // Codes here  // Attribute(s)  // Method(s)  } }     At the end, like old Style, say \u0026ldquo;Hello world!\u0026quot;:)\n1 2 3 4 5 6  // HelloWorld.java public class HelloWorld { public static void main(String[] args){ System.out.println(\u0026#34;Hello World!\u0026#34;); } }     02. Transformation of DataTypes in Java   Except boolean, other DataType can be transformed into another.\n  Low Capacity Data to High Capacity Data is called Auto Transformation. Capacity from low to high:\nbyte \u0026lt; short / char \u0026lt; int \u0026lt; long \u0026lt; float \u0026lt; double\n  High Capacity Data to Low Capacity Data is called Forced Transformation. This can cause The Loss of Accurity.\n  Miss-Calculation among byte, short, char, they transform into int firstly.\n  Mix-Calculation among mix-DataTypes, they transform into the DataType with largest Capacity among them firstly.\n  03. Methods in Class What is Methods  Methods are a Piece of Code, they can handle with specific Problems and are written in Class ( Method in Method is not possible! ), and the Sequence of Methods have no Influence on Code.  Format 1 2 3  [Modifier List] return-Type Method-Name(Parameters){ Codes that handle with Problems; }   static or NOT?   Methods without static can be used only through an Object. They are called as Instance Methods.\n  if a Move needs Object to take part in, DONOT use static.\n  Methods with static donot need Object to take part in. To access, Class_Name.Method()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  class Method{ public static void doSome(){ // Codes  } public void doOther(){ // Codes  } public static void main(String[] args){ Student s = new Student(); Method.doSome(); // doSome();  Method m = new Method(); m.doOther(); } }     Usage   You can define Methods, but you must not use them.\n  In Class, type: Class-Name.Method-Name(Parameters)\n  If static is in [Modifier List](Reference here) or the Methods are with the Calling-Code in the same Class, Class-Name can be ignored.\n  Methods in other Class, must be Class-Name.Method-Name(Parameters).\n  Overload: Methods with same Names and finish similar Functions.   See Code below:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  public class OverloadTest(){ public static void main(String[] args){ int result1 = sumInt(1,2); System.out.println(result1); double result2 = sumDouble(1.0, 2.0); System.out.println(result2); long result3 = sunLong(1L, 2L); System.out.println(result3); } public static int sumInt(int a, int b){ return a + b; } public static double sumDouble(double a, double b){ return a + b; } public static long sumLong(long a, long b){ return a + b; } }     Though Functions sumInt(), sumDouble(), sumLong() are different, but they are similar.\n  Overload see below:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  public class OverloadTest(){ public static void main(String[] args){ int result1 = mySum(1,2); System.out.println(result1); double result2 = mySum(1.0, 2.0); System.out.println(result2); long result3 = mySum(1L, 2L); System.out.println(result3); } public static int mySum(int a, int b){ return a + b; } public static int mySum(double a, double b){ return a + b; } public static int mySum(long a, long b){ return a + b; } }     Code above will automatically select which mySum will be used.\n When will Overload occur, it goes with Parameters only\u0026hellip;     Case Examples     in same Class Basic 1   with the same Method Name Basic 2   Parameters in different amount public static void m1(); public static void m1(int a)   Parameters in different Sequence public static void m2(int a, double b); public static void m2(double a, int b)   Paramaters in different Types public static void m3(int a); public static void m3(double a)    04. JVM 3 primary Memory Spaces in JVM Ref here   Method Areas: Codes and static Variables ( Instance Variables )\n  Heap: storage Instance Variables. This Memory are handeled by Trash cycle Programm.\n  Stacks: when Methods are used, assign Room here, Stack-push. when Methods are finished, Stack-pop. on Running-Phase local Variables are storaged here. This Memory are mostly used.\n  where are the Variables?   Variables / Attributes beyond Methods in Class are called Member Variables ( It\u0026rsquo;s accessble only through Object ).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  class Student{ //Member Variables below  int stu_No; String name; int age; String address; ... // Member Variables without `static` are called Instance Variables;  // instead, Member Variables with `static` are called static Variables. } public class myClass{ public static void main(String[] args){ int i = 10; Student s = new Student(); // s maps the Address of the Instance,  // Instance / Object is storaged in Heap in JVM  // s and i are storaged in Stack in JVM  // s have Member Variables.  } }     In the Code above, i and s called local Variable ( in Stack ), s' Attributes like stu_No, age, etc. are called Instant Variables ( in Heap ).\n Member Variables contain static Variables and Instance Variables.     Modifier Function     public accessible anywhere   static accessible without Object   protacted accesible in the same Package, and Subclass   None accessible in the same Package    05. Object-oriented 3 Features   Encapsulation ( Attributions )\n  simplify, offer simple Interfaces for Users. ( i.e, Camera )\n  after Encapsulation there is Object\n  after Encapsulation the Programms becomes resuable\n  improve the Security\n  private Attributions $\\rarr$ write Interfaces ( set and get. These 2 Methods have no Modifier static)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  class Student{ private String name; private int age; private String addr; public void setName(String myName){ name = myName; // Code that determins the Legality  } public String getName(){ return name; } }       Inheritance\n  Ancestor: java.lang.Object\n  [Modifiers] class subclass extands superclass{}\n  Basic: Reusablility of Codes;\n  Advanced: Base Stone of the Overload and the Polymorphism\n  superclass and subclass\n  private, Constructors are not inheritance.\n    Polymorphism\n  upcasting: subclass $\\rarr$ superclass ( automatic )\n  downcasting: superclass $\\rarr$ subclass ( forced ) when specific Methods are only in Subclass\n  There must be extend-Relationship by upcasting and downcasting\n  大家都知道花木兰替父从军的例子，花木兰替父亲花弧从军。那么这时候花木兰是子类，花弧是父类。花弧有自己的成员属性年龄，姓名，性别。花木兰也有这些属性，但是很明显二者的属性完全不一样。花弧有自己的非静态成员方法‘骑马杀敌’，同样花木兰也遗传了父亲一样的方法‘骑马杀敌’。花弧还有一个静态方法‘自我介绍’，每个人都可以问花弧姓甚名谁。同时花木兰还有一个自己特有的非静态成员方法‘涂脂抹粉’。但是，现在花木兰替父从军，女扮男装。这时候相当于父类的引用（花弧这个名字）指向了子类对象（花木兰这个人），那么在其他类（其他的人）中访问子类对象（花木兰这个人）的成员属性（姓名，年龄，性别）时，其实看到的都是花木兰她父亲的名字（花弧）、年龄（60岁）、性别（男）。当访问子类对象（花木兰这个人）的非静态成员方法（骑马打仗）时，其实都是看到花木兰自己运用十八般武艺在骑马打仗。当访问花木兰的静态方法时（自我介绍），花木兰自己都是用她父亲的名字信息在向别人作自我介绍。并且这时候花木兰不能使用自己特有的成员方法‘涂脂抹粉’。\n  那么终于一将功成万骨枯，打仗旗开得胜了，花木兰告别了战争生活。有一天，遇到了自己心爱的男人，这时候爱情的力量将父类对象的引用（花弧这个名字）强制转换为子类对象本来的引用（花木兰这个名字），那么花木兰又从新成为了她自己，这时候她完全是她自己了。名字是花木兰，年龄是28，性别是女，打仗依然那样生猛女汉子，自我介绍则堂堂正正地告诉别人我叫花木兰。OMG！终于，终于可以使用自己特有的成员方法‘涂脂抹粉’了。从此，花木兰完全回到了替父从军前的那个花木兰了。并且和自己心爱的男人幸福的过完了一生。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  public class Animal{ public void move(){ System.out.println(\u0026#34;Animal Moving!\u0026#34;); } public static void main(String[] args){ Animal a = new Bird(); a.move(); //Bird to Animal, upcasting  // a.move() -\u0026gt; Bird Flying!  // a.sing() -\u0026gt; CANNOT compile. In Class Animal there\u0026#39;s no Method called \u0026#34;sing()\u0026#34;  // In other Word: Compile check a\u0026#39;s Class, Animal. But Animal cannot sing.  // Run: run Methods in Bird. Because we have a Bird() Object \u0026#34;newed\u0026#34;.  // when we want Animal a to sing, we can transform its\u0026#39; DataType  Bird b = (Bird) a;//Animal to Bird, downcasting  b.move(); //Bird Fying!  b.sing(); // Bird Singing!  Cat c = (Cat) a; } } class Bird extends Animal{ public void move(){ System.out.println(\u0026#34;Bird Flying!\u0026#34;); } public void sing(){ System.out.println(\u0026#34;Bird Singing!\u0026#34;); } } class Cat extends Animal{ public void move(){ System.out.println(\u0026#34;Cat Jumoing!\u0026#34;); } public void catchMouse(){ System.out.println(\u0026#34;Cat catches Mouse!\u0026#34;); } }     java.lang.ClassCastException It happens in downcasting.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /* Codes below can compile. */ public class Animal{ public void move(){ System.out.println(\u0026#34;Animal Moving!\u0026#34;); } public static void main(String[] args){ Animal a = new Bird(); // We created a Bird Object, store its\u0026#39; Address in a with Animal.  Cat c = (Cat) a; // Bird and Cat have no Inheritance Relationship. It cannot run.  // But in Compile, while a\u0026#39;s Type is Animal, Animal and Cat have Inheritance Relationship, compile works.  } }     how to avoid java.lang.ClassCastException $\\rarr$ instanceof\n  Reference instanceof Data-Type\n  returns boolean\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  public class Animal{ public void move(){ System.out.println(\u0026#34;Animal Moving!\u0026#34;); } public static void main(String[] args){ Animal a = new Bird(); // We created a Bird Object, store its\u0026#39; Address in a with Animal.  // a is an Instance of Bird, but Reference is Animal.  if(a instanceof Cat){ Cat c = (Cat) a; c.catchMouse(); } else if(a instanceof Bird){ Bird b = (Bird) a; b.sing(); } } }     classic Polymorphism Codes\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  public class Test{ public static void main(String[] args){ Master m = new Master(); // Parentclass oriented Programming  Pet p = new Cat(); m.feed(p); // Cat eating  } } class Master{ public void feed(Pet p){ p.eat(); } } class Pet{ public void eat(){ System.out.println(\u0026#34;Pet eating\u0026#34;); } } class Cat extends Pet{ public void eat(){ System.out.println(\u0026#34;Cat eating\u0026#34;); } } class Dog extends Pet{ public void eat(){ System.out.println(\u0026#34;Dog eating\u0026#34;); } }       In the Life Circle:   Object Oriented Analysis (OOA)\n  Object Oriented Design (OOD)\n  Object Oriented Programming (OOP)\n  Class / Object ( Instance ) in Java   Class:\n  A Template, a Concept, doesn\u0026rsquo;t exist in the real World, an abstract Result after Thought.\n  describes mostly Status (Attributes) and Actions (Methods).\n    Object: Individual in the real World.\n  Constructor   Differences between Methods and Constructor ( has return-Type or not )\n1 2 3 4 5 6 7 8  [Modifier List] Constructor-Name(parameters){ //Codes } [Modifier List] return-Type Method-Name(Parameters){ //Codes }     Constructor-Name must be same as Class-Name.\n  this Key Word   Appears in Constructor and Methods, cannot appear in static Method\n  this points at the Object itself. It\u0026rsquo;s saved in Heap.\n  this appears in Instance Methods ( Methods without static )\n  this can also appear in Constructors, using other Constructors at the meanwhile.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  public class Customer{ String name; public Customer(){ // this.name = \u0026#34;NULL\u0026#34;;  this(name); } public Customer(String name){ this.name = name; } public void shopping(){ System.out.println(this.name + \u0026#34;is shopping!\u0026#34;); } }     static   an Example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public class Customer { public static void shopping() { System.out.println(\u0026#34;In shopping!\u0026#34;); } public void running() { System.out.println(\u0026#34;On running!\u0026#34;); } public static void main(String[] args){ Customer c1 = new Customer(); // Method \u0026#34;running()\u0026#34; is only through an Object accessible.  c1.running(); // The following Codes output without Nullpointer Error.  // There\u0026#39;s Warning. static Methods are accessible through object, too.  // BUT, Advice is, use it through \u0026#34;Class.static_Method()\u0026#34;.  c1 = null; c1.shopping(); } }     when static Variables?\n  Same Attribute(s) in Objects\n  static Variables are storaged during the Load of Class in \u0026ldquo;Method Area\u0026rdquo;\n  static Variables have Nothing to do with Objects.\n  static Code Block will be executed during the Load of Class from up to down and only once.\n  static Code Block can be used to record when the Class are loaded. ( Log )\n  p.S. Instance Code Block can be used to record when the Object are created.\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14  public class Chinese{ private String name; private String id; // the Variable \u0026#34;country\u0026#34; here are same: China.  // private String country;  // So we write it in this Way  static String country = \u0026#34;China\u0026#34;; // By writing in this way the Variable \u0026#34;country\u0026#34; is saved in \u0026#34;Method Area\u0026#34; instead of in \u0026#34;Heap\u0026#34;  // It\u0026#39;s accessible by:  // zhangsan.country;  // Chinese.country; }     In static there\u0026rsquo;s no this. It cannot visit Instance Variables and Instance Methods directly ( must through an Object ).\n  Override   when Override?\n  Methods in Superclass cannot feed the Need of Subclass\n  Override Methods have same Modifier, returnType and Parameters\n  The Access Right must be same or higher\n  The Number of Errors must be same or less\n  Deals with only Methods ( except static Methods )\n  Override the Methods in the closet Superclass\n  1 2 3 4 5 6 7 8 9 10 11 12  public class Animal{ protected void move(){ System.out.println(\u0026#34;Moving\u0026#34;); } } public class Bird extends Animal{ public void move(){ System.out.println(\u0026#34;Flying\u0026#34;); } }     final   final Class cannot be inheritaged\n  final Methods cannot be override\n  final Variables cannot be changed after Value given\n  final Variable must be Value given manually\n  final static Variable is called Constant ( e.g., final static double PI = 3.1415926, Constant should be written in UPPERCASE )\n1 2 3 4 5  public class Test{ final int age = 24; // Variable age here must be a Value given.  // And it cannot be given Value again. }   1 2 3 4 5 6 7 8 9  public class Test{ final int age; public Test(){ this.age = 24; } // Variable age here must be a Value given.  // And it cannot be given Value again. }   1 2 3 4 5 6 7 8 9 10 11 12 13 14  public class Test{ public static void main(String[] args){ User u = new User(100); // Variable u above watiting to be handeled by Trash Recycling.  Usre u = new User(200); } } class User{ int credit; public User(int credit){ this.credit = credit; } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  public class Test{ public static void main(String[] args){ final User u = new User(100); // Variable u above CANNOT be handeled by Trash Recycling.  // And we are noot allowed to new a new User Object  u.credit = 10000; // But Variables in u can be modified.  } } class User{ int credit; public User(int credit){ this.credit = credit; } }     super   Father first, then Child.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  public class A{ public A(){ System.out.println(\u0026#34;Constructor without Parameters in A!\u0026#34;); } public static void main(String[] args) { A a = new A(); System.out.println(\u0026#34;------------------------------------\u0026#34;); B b = new B(); } } class B extends A{ public B(){ System.out.println(\u0026#34;Constructor without Parameters in B!\u0026#34;); } } // output  Constructor without Parameters in A! ------------------------------------ Constructor without Parameters in A! Constructor without Parameters in B!   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  public class A { public A() { System.out.println(\u0026#34;Constructor without Parameters in A!\u0026#34;); // -\u0026gt; 1. Father First  } public static void main(String[] args) { A a = new A(); System.out.println(\u0026#34;------------------------------------\u0026#34;); B b = new B(); b.getName(); } } class B extends A { private String name; public B() { this(\u0026#34;zhangsan\u0026#34;); // -\u0026gt; 2. Constructor with String  System.out.println(\u0026#34;Constructor without Parameters in B!\u0026#34;); // -\u0026gt; 3. syso  System.out.println(); } public B(String name) { this.name = name; System.out.println(\u0026#34;Constructor with String in B!\u0026#34;); // -\u0026gt; 2. Constructor with String  } public void getName() { System.out.println(this.name); } } // output  Constructor without Parameters in A! ------------------------------------ Constructor without Parameters in A! // -\u0026gt; 1. Father First Constructor with String in B! // -\u0026gt; 2. Constructor with String Constructor without Parameters in B! // -\u0026gt; 3. syso  zhangsan     abstract class   Definition\n  Class and Class have commen Features. These Features become abstract class.\n  abstract class cannot have Instance. But it can have Constructors -\u0026gt; used by Subclass\n  abstract class are used to be inherited.\n  the Subclass of abstract class can also be abstract class.\n  final and abstract cannot be together.\n    Howto\n1 2 3  [modifier] abstract class class_Name{ //Codes }     abstract Methods -\u0026gt; ( half abstract )\n1 2  public abstract void doSome(); // No Function Body ( no \u0026#39;{}\u0026#39; ), end with ;   abstract class may not have abstract Methods, but abstract Methods must show up in abstract class.\nwhen there\u0026rsquo;s a Subclass ( Non-abstract ), it must rewrite the abstract Mehtods in its' Parent Class.\n1 2 3 4 5 6 7 8 9 10  public abstract Animal{ public abstract void move(); } class Bird extends Animal{ public void move(){ } // if there\u0026#39;s no rewirte of this Method, compile error. }     interface -\u0026gt; ( total abstract )   Howto\n1 2 3  [Modifier] interface interface_Name{ //Codes }     interface supports ( multy ) Inheritage\n  interface has only 2 Parts: ( public static final ) Const and ( public abstract ) Methods.\n  Everthing in interface are public. public abstract before Methods can be ignored.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  interface A{ } interface B{ } interface myMath extends A, B{ double PI = 3.1415926; //public static final double PI = 3.1415926;  int sum(int a, int b); //public abstract int sum(int a, int b); }     when an unabstract class implements an interface, every ( public abstract ) Methods in interface must be rewritten. [Modifier] must have public.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public class interface_Test { public static void main(String[] args) { myMath m1 = new myMathImpl(); System.out.println(m1.sub(2,1)); System.out.println(m1.sum(3,4)); } } interface myMath{ double PI = 3.1415926; int sum(int a, int b); int sub(int a, int b); } class myMathImpl implements myMath{ public int sum(int a, int b){ return a + b; } public int sub(int a, int b){ return a - b; } }     one class can implement multiple interface. interface can transform into other interface without Inheritage.\ndifferent from class, upcasting and downcasting in class must have Inheritage.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  public class multi_implements { public static void main(String[] args) { A a = new D(); B b = new D(); C c = new D(); B b1 = (B) a; //interface can transform into other interface  // better way to write:  if(a instanceof B) B b1 = (B) a; b1.m2(); } } interface A{ void m1(); } interface B{ void m2(); } interface C{ void m3(); } class D implements A, B, C{ @Override public void m1(){ System.out.println(\u0026#34;m1...\u0026#34;); } @Override public void m2() { System.out.println(\u0026#34;m2...\u0026#34;); } @Override public void m3() { System.out.println(\u0026#34;m3...\u0026#34;); } }   This completes, that in Java class can extend only one single class.\n  when implements and extends exist together: class_Name extends parent_Class_Name implements interface_Name\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  public class test04 { public static void main(String[] args) { flyable f = new Cat(); f.Fly(); flyable f1 = new Pig(); f1.Fly(); //Polymorphism  } } interface flyable{ void Fly(); } class Animal{ } class Cat extends Animal implements flyable{ public void Fly(){ System.out.println(\u0026#34;Cat! Fly me to the Moon!\u0026#34;); } } class Pig extends Animal implements flyable{ public void Fly(){ System.out.println(\u0026#34;Flying Pig! FFFFFFFF!\u0026#34;); } } // output // Cat! Fly me to the Moon! // Flying Pig! FFFFFFFF!     In a Word..   is a -\u0026gt; extends\n1 2 3  class Cat extends Animal{ //Codes }     has a -\u0026gt; Attributes\n1 2 3  class Cat extends Animal{ private boolean Tail; }     is like a -\u0026gt; implements\n1 2 3 4 5 6 7 8 9  interface Menu{ void Steak(); } class Cooker implements Menu{ public void Steak(){ System.out.println(\u0026#34;cooking Steak...\u0026#34;); } }     An Example 1 2 3 4 5  // Menu.java public interface Menu { void Steak(); void Pasta(); }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  // Customer.java public class Customer { private Menu foodmenu; public Customer() { } public Customer(Menu foodmenu) { this.foodmenu = foodmenu; } public Menu getFoodmenu() { return this.foodmenu; } public void order() { foodmenu.Pasta(); foodmenu.Steak(); } }   1 2 3 4 5 6 7 8 9 10 11 12  // AmericanCooker.java public class AmericanCooker implements Menu { @Override public void Pasta() { System.out.println(\u0026#34;Pasta with Pfeffer Minz!\u0026#34;); } @Override public void Steak() { System.out.println(\u0026#34;Steak with Butter!\u0026#34;); } }   1 2 3 4 5 6 7 8 9 10 11 12  // ChineseCooker.java public class ChineseCooker implements Menu{ @Override public void Steak() { System.out.println(\u0026#34;Steak with chinese Oil!\u0026#34;); } @Override public void Pasta() { System.out.println(\u0026#34;Pasta with chinese Tomatoes!\u0026#34;); } }   1 2 3 4 5 6 7 8  // menu_Test.java public class menu_Test { public static void main(String[] args) { Menu cooker1 = new ChineseCooker(); Customer customer = new Customer(cooker1); customer.order(); } }   Differences between interface and abstract class    interface abstract class     total abstract half abstract   without Constructor with Constructor   multiple Inheritance single Inheritance   only Const and abstract Methods a class can implements multiple interface, but only 1 class to inheritage    06. package and import   package \u0026lt;Package_Name\u0026gt;;\n  Template of Package Name\n  Reverse of the Company's Host + Project_Name + Module_Name + Function_Name\n  Write in Lowercase ( i.e., package org.apache.tomcat.core' )\n  a package maps a Directory\n  after using package, Class has changed into package_Name + Class_Name\n    how to compile\n  javac -d . XXX.java\n  the Command above creates multiple Directories, that splits package_Name into Direstories.\n    how to run .class\n  run Command java package_Name.XXX under the same Directory of XXX.java File.\n  that is to say, the class_Name of xxx.java becomes package_Name.XXX\n    an Example 1 2 3 4 5 6 7 8  // HelloWorld.java package self.study; public class HelloWorld{ public static void main(String[] args){ System.out.println(\u0026#34;package test!\u0026#34;); } }   1 2 3 4 5 6 7 8 9  // Test.java package self; public class Test{ public static void main(String[] args){ self.study.HelloWorld hw = new self.study.HelloWorld(); System.out.println(\u0026#34;In Test!\u0026#34;); } }     HelloWorld.java and Test.java locate at the same Dirtectory. HelloWorld.class locates in ./self/study, Test.class locates in ./self. when we new an Object of HelloWorld.class, we have to write it in self.study.HelloWorld hw = new self.study.HelloWorld() without import.\n  with import, we rewrite Test.java, and import the class we need.\n1 2 3 4 5 6 7 8 9  // Test.java package self; import self.study.HelloWorld public class Test{ public static void main(String[] args){ HelloWorld hw = new HelloWorld(); System.out.println(\u0026#34;In Test!\u0026#34;); } }     when import   class A and class B locate in same package, we donot need to import\n  class A and class B locate in different package, we need to import\n  import locates under package \u0026lt;package_Name\u0026gt;; above [Modifiers] class \u0026lt;class_Name\u0026gt;\n  an often-used Case: import java.util.Scanner Here java.util is a package_Name.\n  java.lang package will be automatically imported.\n  07. Access Control ( [Modifiers] )    private protected public -     same Class same Class, same Package and Subclass Anywhere same Class and Package     public \u0026gt; protected \u0026gt; - \u0026gt; private  08. typical Methods in Class Object  toString()    It\u0026rsquo;s recommanded, that toString() should be rewritten.\n  when a Ref / Instance is output, toString() will be aumomatically used.\n   equals()\n1 2 3  public boolean equals(Object obj){ return this == obj; }       to decide, wether 2 Objects are same - comparing their Memory Addresses.\n  It\u0026rsquo;s recommanded, that equals() should be rewritten.\n  08. Data Structure Math \u0026amp; Nums   Short, Integer, Long, Float, Double, Boolean, Character, Byte.\n  Methods of Classes above: click here\n  P.S. Nums.toString(): transfer a Number to String\n  String   Mostly used Methods:\n char charAt(int index): returns the Character at the Index. int length(): returns the Length of the String. int parseInt(): transfer the String into an Integer. char[] toCharArray(): transfer the String into an Character-Array. boolean isEmpty(): if the String is empty. int hashCode(): returns the HashCode of the String. int indexOf(char ch(,int fromIndex)): returns the Index of the Character ch the first time it appears( after the fromIndex).    Other Methods of String: click here\n  The DataType above is often used to initialize a DataStructure ( See below ).\n  Queue \u0026amp; Stack \u0026amp; Bag    Initialization Queue     Initialization Queue\u0026lt;DataType\u0026gt; queue_name = new Queue\u0026lt;DataType\u0026gt;()   int size() returns the size of the Queue   boolean isEmpty() judge if the Queue is empty   enqueue(DataType Item) enqueue an Item into a Queue   DataType dequeue() dequeue the first-in Item       Options Stack     Initialization Stack\u0026lt;DataType\u0026gt; stack_name = new Stack\u0026lt;DataType\u0026gt;()   int size() returns the size of the Stack   boolean isEmpty() judge if the Stack is empty   push(DataType item) push a new element into a Stack   DataType pop() returns the last-in Item       Options Bag     Initialization Bag\u0026lt;DataType\u0026gt; bag_name = new Bag\u0026lt;DataType\u0026gt;()   int size() returns the size of the Bag   add(DataType Item) add an Item into the Bag    ArrayList    Options ArrayList     Initialization ArrayList\u0026lt;DataType\u0026gt; arraylist_name = new ArrayList\u0026lt;DataType\u0026gt;()   int size() returns the Size of the ArrayList   add(int Index, _DataType Item) add an Item into index   contains(DataType Item) if the ArrayList contains the Item   get(int index) get the Item through index   int indexOf(DataType Item) returns the Index of the Item   sort() sort the ArrayList   toArray() transfer the ArrayList into an Array   toString() transfer the ArrayList into a String    P.S. For more Options, click here.\nLinkedList    Options LinkedList     Initialization LinkedList\u0026lt;DataType\u0026gt; list = new LinkedList\u0026lt;DataType\u0026gt;()   int size() returns the Size of the LinkedList   add((int index, )DataType Item) add an Item at the end of the LinkedList / index   remove(int index) remove the index-th Item of the LinkedList   get(int index) get the index-th Item of the LinkedList   Object[] toArray() returns an Array composed by the Items of LinkedList    P.S. For more Options, click here.\nHashMap    Options HashMap     Initialization HashMap\u0026lt;DataType Key, DataType Value\u0026gt; sites = new HashMap\u0026lt;DataType Key, DataType Value\u0026gt;()   int size() returns the size of the HashMap   value\u0026rsquo;s DataType get(DataType Key) returns the value of Key   boolean containsKey(DataType Key) if the HashMap contains the Key-Value   remove(DataType Key) remove the Item of the HashMap    P.S. For more Options, click here.\nHashSet    Options HashSet     Initialization HashSet\u0026lt;DataType\u0026gt; sites = new HashSet\u0026lt;DataType\u0026gt;()   int size() returns the size of the HashSet   boolean contains(DataType Item) if the HashSet contains the Item   remove(DataType Item) remove the Item of the HashSet    P.S. For more Options, click here.\n","permalink":"https://daijiabin.github.io/java-learning/","tags":["Languages"],"title":"Java Learning"},{"categories":["Learn"],"contents":"Go Through LeetCode Recursion / Binary Tree 112. Path Sum - simple recursion   Discription:\n  Given the root of a binary tree and an integer targetSum, return true if the tree has a root-to-leaf path such that adding up all the values along the path equals targetSum.\n  A leaf is a node with no children.\n    Idea:\n  What kind of traverse should we use? \u0026ndash;\u0026gt; Preorder ( why? )\n  What\u0026rsquo;s the Base-Case and what\u0026rsquo;s the Task for every single TreeNode?\n    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  /** * Definition for a binary tree node. * struct TreeNode { * int val; * TreeNode *left; * TreeNode *right; * TreeNode() : val(0), left(nullptr), right(nullptr) {} * TreeNode(int x) : val(x), left(nullptr), right(nullptr) {} * TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {} * }; */ class Solution { public: bool hasPathSum(TreeNode* root, int targetSum) { if(root == NULL) return false; if(targetSum == root -\u0026gt; val \u0026amp;\u0026amp; root -\u0026gt; left == NULL \u0026amp;\u0026amp; root -\u0026gt; right == NULL) return true; targetSum -= root -\u0026gt; val; bool left = hasPathSum(root -\u0026gt; left, targetSum); bool right = hasPathSum(root -\u0026gt; right, targetSum); return left || right; } };   230. Kth Smallest Element in a BST   Discription:\n Given a binary search tree, write a function kthSmallest to find the kth smallest element in it.    Idea:\n  What\u0026rsquo;s the Defination / Features of BST?\n  What kind of traverse should we use? \u0026ndash;\u0026gt; Inorder ( why? )\n    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  /** * Definition for a binary tree node. * struct TreeNode { * int val; * TreeNode *left; * TreeNode *right; * TreeNode() : val(0), left(nullptr), right(nullptr) {} * TreeNode(int x) : val(x), left(nullptr), right(nullptr) {} * TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {} * }; */ class Solution { public: // The most simple Resolution: Serealize the BST and push every element into a vector.  // Return the k-1th element ( Vector besgins with 0 ).  vector\u0026lt;int\u0026gt; nums; int kthSmallest(TreeNode* root, int k) { traverse(nums, root); // traverse(root, k);  return nums[k-1]; } void traverse_withVector(vector\u0026lt;int\u0026gt; \u0026amp;nums, TreeNode* root){ if(root == NULL) return; else{ traverse(nums, root -\u0026gt; left); nums.push_back(root -\u0026gt; val); traverse(nums, root -\u0026gt; right); } } // Without Vector, use Recursion only.  int count = 0; int result; void traverse(TreeNode* root, int k){ if(root == NULL) return; traverse(root -\u0026gt; left, k); count++; if(count == k){ result = root -\u0026gt; val; return; } traverse(root -\u0026gt; right, k); } };   538. Convert BST to Greater Tree   Discription:\n  Given the root of a Binary Search Tree (BST), convert it to a Greater Tree such that every key of the original BST is changed to the original key plus sum of all keys greater than the original key in BST.\n  As a reminder, a binary search tree is a tree that satisfies these constraints:\n  The left subtree of a node contains only nodes with keys less than the node\u0026rsquo;s key.\n  The right subtree of a node contains only nodes with keys greater than the node\u0026rsquo;s key.\n  Both the left and right subtrees must also be binary search trees.\n    Idea:\n  What kind of traverse should we use? \u0026ndash;\u0026gt; Inorder ( why? )\n  What\u0026rsquo;s the Base-Case and what\u0026rsquo;s the Task for every single TreeNode?\n    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  class Solution { public: int sum = 0; TreeNode* convertBST(TreeNode* root) { if(root == NULL) return root; root -\u0026gt; right = convertBST(root -\u0026gt; right); root -\u0026gt; val += sum; sum = root -\u0026gt; val; root -\u0026gt; left = convertBST(root -\u0026gt; left); return root; } };   652. Find Duplicate Subtrees - hash table, serealization   Discription:\n  Given the root of a binary tree, return all duplicate subtrees.\n  For each kind of duplicate subtrees, you only need to return the root node of any one of them.\n  Two trees are duplicate if they have the same structure with the same node values.\n    Idea:\n  What kind of traverse should we use? \u0026ndash;\u0026gt; Postorder ( why? )\n  How to compare subtrees that come from different roots? \u0026ndash;\u0026gt; Serealize the subtree to a String and store them into a Hash table ( unordered_map in C++).\n    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  /** * Definition for a binary tree node. * struct TreeNode { * int val; * TreeNode *left; * TreeNode *right; * TreeNode() : val(0), left(nullptr), right(nullptr) {} * TreeNode(int x) : val(x), left(nullptr), right(nullptr) {} * TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {} * }; */ class Solution { public: unordered_map\u0026lt;string, int\u0026gt; memo; vector\u0026lt;TreeNode*\u0026gt; res; vector\u0026lt;TreeNode*\u0026gt; findDuplicateSubtrees(TreeNode* root) { traverse(root, res); return res; } string traverse(TreeNode* root, vector\u0026lt;TreeNode*\u0026gt;\u0026amp; res){ if(root == NULL) return \u0026#34;#\u0026#34;; string left = traverse(root -\u0026gt; left, res); string right = traverse(root -\u0026gt; right, res); string result = left + \u0026#39;,\u0026#39; + right + \u0026#39;,\u0026#39; + to_string(root -\u0026gt; val); if(memo.find(result) == memo.end()) memo[result]++; else if(memo[result] == 1){ memo[result]++; res.push_back(root); } else memo[result]++; return result; } };     Discription:\n  Idea:\n  1 2 3    Linked List 19. Remove Nth Node From End of List ( Middle ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */ class Solution { private ListNode myFunc(ListNode head, int n){ ListNode slow = head, fast = head; while(n \u0026gt; 0){ fast = fast.next; n--; } if(fast == null) return head.next; while(fast.next != null){ slow = slow .next; fast = fast.next; } slow.next = slow.next.next; return head; } public ListNode removeNthFromEnd(ListNode head, int n) { if(head == null) return head; head = myFunc(head, n); return head; } }   141. Linked List Cycle ( Easy ) ( -\u0026gt; HashSet? ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  /** * Definition for singly-linked list. * class ListNode { * int val; * ListNode next; * ListNode(int x) { * val = x; * next = null; * } * } */ public class Solution { public boolean hasCycle(ListNode head) { if(head == null || head.next == null) return false; ListNode slow = head, fast = head; while(fast != null \u0026amp;\u0026amp; fast.next != null){ slow = slow.next; fast = fast.next.next; if(slow == fast) return true; } return false; } }   149. Reorder List ( Middle ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92  /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */ class Solution { private ListNode reverse(ListNode head){ // Reverse a List.  if(head == null || head.next == null) return head; ListNode retNode = null; while(head != null){ ListNode nxt = head.next; head.next = retNode; retNode = head; head = nxt; } return retNode; } private ListNode findMid(ListNode head){ // Find the Middle Node of a List ( slow - fast )  ListNode slow = head, fast = head.next; while(fast != null \u0026amp;\u0026amp; fast.next != null){ slow = slow.next; fast = fast.next.next; } return slow; } private ListNode merge(ListNode left, ListNode right){ // Merge 2 List. Here we use \u0026#34;index\u0026#34; to decide which List-Node to be chosen.  // When we merge a list ascend, we can compare the Values of Nodes.  ListNode retNode = new ListNode(-1); ListNode temp = retNode; int index = 0; while(left != null \u0026amp;\u0026amp; right != null){ if(index % 2 == 0){ temp.next = left; left = left.next; } else if(index % 2 == 1){ temp.next = right; right = right.next; } temp = temp.next; index++; } if(left != null) temp.next = left; else temp.next = right; return retNode.next; } public void reorderList(ListNode head) { if(head == null || head.next == null) return; ListNode midNode = findMid(head); ListNode left = head; ListNode right = reverse(midNode.next); midNode.next = null; ListNode retNode = merge(left, right); head = retNode; return; } }   ","permalink":"https://daijiabin.github.io/leetcode/","tags":["LeetCode"],"title":"LeetCode"},{"categories":["Learn"],"contents":"Ideas Recursion   What important is, NEVER JUMP INTO RECURSION.\n  Actually\u0026hellip; If it\u0026rsquo;s possible, you can jump into it\u0026hellip; (Well\u0026hellip; You can take a try:) )\n  In a Word, what the Blog above says, is that you must make sure that you know the very Defination of your Recursion Function, and trust that it can finish its Work perfectly.\n  1. Recursion in List   Figure out what does your Function proceedure with, what kind of value will it return.\n  Consider about the Base-Case, with which we can end the recursion\n  Deal with the rest part ( beyond the Base-Case ) recursively by using your Function.\n  Proceedure the Details of Base-Case.\n  1.1. Reverse a complete-List 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  listNode* reverse(ListNode* head){ // Base-Case  if(head -\u0026gt; next == NULL) return head; // With Nothing to do, because it\u0026#39;s a single-element List.  listNode* last = reverse(head -\u0026gt; next); head -\u0026gt; next -\u0026gt; next = head; head -\u0026gt; next = NULL; return last; }   1.2 Reverse the first n-element in a List 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  listNode* successor = NULL; listNode* reverseN(listNode* head, int n){ if(n == 1){ successor = head.next; return head; } listNode* last = reverseN(head -\u0026gt; next, n - 1); head -\u0026gt; next = successor; head -\u0026gt; next -\u0026gt; next = head; return last; }   1.3 Reverse the [m, n] elements in a List 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  listNode* reverseMN(listNode *head, int m, int n){ if(m == 1) return reverseN(head, n); /* Here we consider about the Situation by sub-List([head-\u0026gt;next, end]). For this sub-List we begin with m-1, the length we need to proceedure is n - 1. */ head -\u0026gt; next = reverseMN(head -\u0026gt; next, m - 1, n - 1); return head; }   1.4 Reverse a List in K-elements Group  Reverse a List in Iteration:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  listNode* reverse_Iteration(listNode* head){ listNode* prev, cur, nxt; cur = nxt = head; prev = NULL; while(cur != NULL){ // For given-Node case, we modify the loop:  // while(cur != givenNode)  nxt = cur -\u0026gt; next; cur -\u0026gt; next = prev; prev = cur; cur = nxt; } return prev; }   1.5 Reverse a List in K-elements Group 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  listNode* reverseKGroup(listNode* head, int k){ if(head == NULL) return head; listNode* b; b = head; for(int i = 0; i \u0026lt; k; i++){ if(b == NULL) return head; b = b -\u0026gt; next; } listNode* newHead = reverse_givenNode(head, b); head -\u0026gt; next = reverseKGroup(b, k); return newHead; }   2. Recursion in Binary Tree  What kind of order should be used, must know.  2.1 Traverse - preorder, inorder, postorder 1 2 3 4 5 6 7 8 9 10 11  void traverse(TreeNode* root){ // Base-case  if(root == NULL) return; cout \u0026lt;\u0026lt; root -\u0026gt; val; // Preorder  traverse(root -\u0026gt; left); cout \u0026lt;\u0026lt; root -\u0026gt; val; // Inorder  traverse(root -\u0026gt; right); cout \u0026lt;\u0026lt; root -\u0026gt; val; // Postorder }   Sort Algorithms Merge-Sort   Ideas:\n  sort On-Place. We need an aux Array.\n  devide and conquer: devide Array into 2 Parts ( based on mid ) until the Base-Case, then we merge them.\n  how to merge: copy the Elements to aux Array.\n    Code:\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  public class mergeSort{ public static void main(String[] args){ int[] nums = {9,8,7,6,5,4,3,2,1}; sort(nums); /* for(int i = 0; i \u0026lt; nums.length; i++) System.out.print(nums[i]); */ } private static int[] aux; private static void merge(int[] a, int lo, int mid, int hi){ int i = lo; int j = mid + 1; // copy original Array to Aux[]: sort on Place.  for(int k = i; k \u0026lt;= hi; k++) aux[k] = a[k]; for(int k = lo; k \u0026lt;= hi; k++){ if(i \u0026gt; mid) a[k] = aux[j++]; else if(j \u0026gt; hi) a[k] = aux[i++]; else if(aux[j] \u0026lt;= aux[i]) a[k] = aux[j++]; else a[k] = aux[i++]; } } private static void sort(int[] nums, int lo, int hi){ if(hi \u0026lt;= lo) return; int mid = lo + (hi - lo) / 2; sort(nums, lo, mid); sort(nums, mid + 1, hi); merge(nums, lo, mid, hi); } private static void sort(int[] a){ aux = new int[a.length]; sort(a, 0, a.length - 1); } }   Quick Sort   Ideas:\n  devide and conquer: select a Standard, move it to the proper Position, then devide the Array into 2 Parts, sort them.\n  how to move the Standard to the proper Position: a while - Loop. The left Side of the Standard should no greater than the Standard, the right Side should no less than it.\n  sort the left Side and the right Side.\n    Code:\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  public class quickSort { public static void main(int[] nums) { // TODO Auto-generated method stub \tsort(nums, 0, nums.length - 1); } private static void sort(int[] a, int lo, int hi) { if(hi \u0026lt;= lo) return; int j = partition(a, lo, hi); sort(a, lo, j - 1); sort(a, j + 1, hi); } private static int partition(int[] a, int lo, int hi) { int i = lo, j = hi + 1; int v = a[lo]; while(true) { while(a[++i] \u0026lt; v) { if(i == hi) break; } while(v \u0026lt; a[--j]) { if(j == lo) break; } if(i \u0026gt;= j) break; swap(a, i, j);\t} swap(a, lo, j); return j; } private static void swap(int[] a, int i, int j) { int temp = a[i]; a[i] = a[j]; a[j] = temp; } }   ","permalink":"https://daijiabin.github.io/algorithms/","tags":["Algorithms"],"title":"Algorithms -- Recursion"},{"categories":["Learn"],"contents":"Lecture by Andrew Ng, Coursera Basic Concepts \u0026amp; Linear Regression Supervised Learning vs. Unsupervised Learning   Supervised Learning:\n In supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output.\n   Training Data already has the value, which our Function should predict for a new, strange input. i.e, In the case below, we want to get a function, so that we can calculate the price of a house to be sold. We have 4 Training Data in this table and each Data has 4 Features that have a influence on its' price ( we call it as Multi-Features. It\u0026rsquo;ll be discussed later:) ).\n  It\u0026rsquo;s devided in Regression and Classification Problems\n        Size Number of Bedrooms Number of Floors Age(years) Price(1000$)     $TrainingData_1$ 2104 5 1 45 460   $TrainingData_2$ 1416 3 2 40 232   $TrainingData_3$ 1534 3 2 30 315   $TrainingData_4$ 852 2 1 36 178   \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip;    ($x_1$) ($x_2$) ($x_3$) ($x_4$) ($x_5$)      Unsupervised Learning\n Unsupervised learning, on the other hand, allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don\u0026rsquo;t necessarily know the effect of the variables.\n   Regression vs. Classification   Regression: The Value we want to predict is continious instead of discrete. E.g., the Price of a House.\n In a regression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function.\n   Classification: As its' name, we want to devide the input in different classes. E.g., After training, with the help of the color, weight, outlook and smel ( Features ), we want to predict if the coffee beans we have come from Arabica or Robusta.\n In a classification problem, we are instead trying to predict results in a discrete output. In other words, we are trying to map input variables into discrete categories.\n   Linear Regression with 1 Variable / Feature   Hypothesis Function\n $\\hat y = h_\\theta = \\theta_0 + \\theta_1x$    Cost Function\n  $J(\\theta_0, \\theta_1) = \\frac{1}{2m} \\sum_{i=1}^m(\\hat y_i - y_i)^2$\n$\\rarr J(\\theta_0, \\theta_1) = \\frac{1}{2m} \\sum_{i=1}^m(h_\\theta(x_i) - y_i)^2$\n    Optimize\n  Gradient Descent. More specifically, repeat:\n$tmp_0 = \\theta_0 - \\alpha\\frac{\\partial}{\\theta_0}{J(\\theta_0, \\theta_1)}$\n$\\rarr tmp_0 = \\theta_0 - \\alpha\\frac{1}{m}\\sum_{i=1}^m{(h_\\theta(x_i) - y_i)}$\n$tmp_1 = \\theta_1 - \\alpha\\frac{\\partial}{\\theta_1}{J(\\theta_0, \\theta_1)}$\n$\\rarr tmp_1 = \\theta_1 - \\alpha\\frac{1}{m}\\sum_{i=1}^m{((h_\\theta(x_i) - y_i)x_1)}$\n$\\theta_0 = tmp_0$\n$\\theta_1 = tmp_1$\nWe call $\\alpha$ Learning Rate. Its' value has influence on the speed, how fast we can find the parameters, with that we can reach a local optimal value.\n  When $\\alpha$ too large / too small is:\n  too large: we might miss the parameters, which can help us get the local optimal value.\n  too small: We need more iterations ( Baby Steps / more time ).\n  We can make the judge, whether $\\alpha$ too large / small ist by drawing the plot of iterations - $J(\\theta_0, \\theta_1)$: It should be lower. Otherwise is $\\alpha$ too large.\n  We can start $\\alpha$ from 0.001, \u0026hellip;, 0.01, \u0026hellip;, 0.1. And Andrew Ng advises us to use 3 times ( 0.001, 0.003, 0.01, 0.03, 0.1 ) to try it.\n      Multiple Features and Matrix   Vector:\n A vector is a Matrix with one Column and many rows. E.g., $\\begin{bmatrix}x_0 \\\\ x_1 \\\\x_2 \\\\x_3 \\end{bmatrix}$    Hypothesis:\n  We use the table above as example, we have 4 Training Data and each of them has 4 Features. According to this, we should have 4+1 parameters $\\theta_0-\\theta_4$. We write the Hypothesis below:\n$h_\\theta(x^i) = \\theta_0 + \\sum_{j=1}^4\\theta_jx_j^i$\n$x_i^j$ here means the jth Feature of the ith Training Data.\nActually we can add a Feature $x_0 \\equiv 1$, then we can use the Matrix. So that we can write the Equation above as below:\n$h_\\theta(x^i) = \\sum_{j=0}^4\\theta_jx_j^i$\nWe let:\n$\\Theta = \\begin{bmatrix}\\theta_0, \\theta_1, \\theta_2, \\theta_3, \\theta_4\\end{bmatrix}$,\n$X = \\begin{bmatrix} x^1_0 \u0026amp; x^2_0 \u0026amp; x^3_0 \u0026amp; x^4_0 \\\\ x^1_1 \u0026amp; x^2_1 \u0026amp; x^3_1 \u0026amp; x^4_1 \\\\ x^1_2 \u0026amp; x^2_2 \u0026amp; x^3_2 \u0026amp; x^4_2 \\\\ x^1_3 \u0026amp; x^2_3 \u0026amp; x^3_3 \u0026amp; x^4_3 \\\\ x^1_4 \u0026amp; x^2_4 \u0026amp; x^3_4 \u0026amp; x^4_4 \\end{bmatrix}$.\nSo that $h_\\theta(x^i) = \\Theta * i_{th}$ column of $X$. In Matrix $X$, element $x_0^i \\equiv 1$. We can also calculate $\\Theta * X$ directly, the $i_{th}$ colum is the value of $h_\\theta(x^i)$.\n    Cost Function:\n  Assume we have m Training Data, each of them has n Features.\n$J(\\theta_0, \\theta_1, \u0026hellip; \\theta_n) = \\frac{1}{2m}\\sum_{i=1}^m(h_\\theta(x^i) - y^i)^2$\n    Gradien Descent:\n  repeat:\n$tmp_i = \\theta_i - \\alpha\\frac{\\partial}{\\partial\\theta_i}J(\\theta_0, \\theta_1, \u0026hellip;, \\theta_n)$\n$\\rarr tmp_i = \\theta_i - \\alpha\\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^i) - y^i)* x^i)$\n$\\theta_i = tmp_i$\n    Feature Scaling   We use this technique when the range of Features have great Difference. E.g., $0 \\leq x_1 \\leq 2000, 0 \\leq x_2 \\leq 5$, then we can $x_1 \\coloneqq \\frac{x_1}{2000}, x_2 \\coloneqq \\frac{x_2}{5}.$ This helps with the speed up of the Gradient Descent.\n  Andrew Ng advices that scaling all Features approximately into the range [-1, 1].\n  We can also scale the Features by using this:\n$x_i = \\frac{x_i - \\mu_i}{s_i}$\nHere $\\mu_i$ is the average value of Feature $x_i$, $s_i$ is normally $value_{max} - value_{min}$.\n  Normal Equation   The Method to solve for $\\Theta$ analytically:\n$\\Theta = (X^TX)^{-1}X^Ty$ can minimize the $J(\\theta)$.\n$x^i = \\begin{bmatrix}x_0^i, x_1^i, \u0026hellip;, x_n^i\\end{bmatrix}$\n$X = \\begin{bmatrix} x_0^1 \u0026amp; x_1^1 \u0026amp; {\u0026hellip;} \u0026amp; x_n^1 \\\\ x_0^2 \u0026amp; x_1^2 \u0026amp; {\u0026hellip;} \u0026amp; x_n^2 \\\\ \u0026hellip; \u0026amp; \u0026hellip; \u0026amp; \u0026hellip; \u0026amp; \u0026hellip; \\\\x_0^m \u0026amp; x_1^m \u0026amp; {\u0026hellip;} \u0026amp; x_n^m \\end{bmatrix}$\nIn this Matrix, we write each row the Features of one Training Data.\n$y = \\begin{bmatrix}y^{(1)}\\\\\u0026hellip;\\\\y^{(m)}\\end{bmatrix}$\n  Suppose $m \\leq n$, then is $X^TX$ is degenerated.\n  The following table can helps us decide, when to use Normal Equation, when to use Gradient Descent.\n   Normal Equation Gradient Descent     No need to choose $\\alpha$. May have \u0026ldquo;Baby Step\u0026rdquo; issue, or miss the local optimal value when $\\alpha$ too large.   Can be slow when n ( Number of Features ) too large is. Works fine even when n large is.   Some Matrix is singular or degenerated.    $n \\leq 10,000$ $n \u0026gt; 10,000$      Reasons of uninvertibility of Matrix $(X^TX)^{-1}$:\n  Redundant Elements: linear depent.\nE.g., $x_1 = $size in $feet^2$, $x_2$ = size in $m^2$.\n    Too many Features: Just delete some of them, or use regulization ( discuss later ).\n  Logistic Regression \u0026amp; Overfitting \u0026amp; Regularization Logistic Regression - Classification   Examples: Email (Spam / Not Spam), Online Transactions: Fraudulent ( Yes / No ) ?\n  $y \\isin {0, 1} \\begin{cases} 0 \u0026amp;\\text{Negative Class} \\\\ 1 \u0026amp;\\text{Positive Class} \\end{cases}$\n  p.s. In multi-class Prolems this set can have more than 2 elements.\n  What if we use linear Regression in a classfication problem?\n $h_\\theta(x) = \\theta^Tx\u0026lt; 0$ or $\u0026gt; 1$    In Logistic Regression, it shouled always be: $0 \\leq h\\theta(x) \\leq 1$_. So we do the following transformation, then we get the Hypothesis:\n  $h_\\theta(x) = g(\\theta^Tx)$\n  Then we use Sigmoid Function / Logistic Function:\n $g(z) = \\frac{1}{1 + e^{-z}}$    We have now:\n $h_\\theta(x) = \\frac{1}{1 + e ^ {-\\theta^Tx}}$    This Function $h_\\theta(x)$ comes out the result that estimated probability that $y = 1$ on input x. We can also write it in the following Form:\n$h_\\theta(x) = P(y = 1 | x; \\theta)$ $\\rarr$ Probability that $y = 1$, given $x$, parameterized by $\\theta$.\n  $P(y = 1 | x; \\theta) + P(y = 0 | x; \\theta) = 1$\n    Deciding Boundary   The decision boundary is the line that separates the area where y = 0 and where y = 1. It is created by our hypothesis function.\n  Linear\n  Non-Linear\n  The way our logistic function g behaves is that when its input is greater than or equal to zero, its output is greater than or equal to 0.5:\n$g(z) \\geq 0.5$\n$\\text{when}\\ z \\geq 0$\nRemeber:\n$z = 0, e^0 = 1\\Rightarrow \\ g(z) = \\frac{1}{2}$\n$z \\rarr \\infty, e^{-\\infty}\\rarr \\ 0 \\Rightarrow \\ g(z) = 1$\n$z \\rarr -\\infty, e^{\\infty}\\rarr \\ \\infty \\Rightarrow \\ g(z) = 0$\n  Cost Function   Training Set: ${(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \u0026hellip;, (x^{(m)}, y^{(m)})}$, m examples\n  x $\\isin \\begin{bmatrix}x_0 \\\\ x_1 \\\\ \u0026hellip; \\\\ x_m\\end{bmatrix}, x_0 \\equiv 1, y \\isin (0, 1)$\n  $h_\\theta(x) = \\frac{1}{1 + e ^ {-\\theta^Tx}}$\n Brief Review: Cost Function in Linear Regression:\n$J(\\theta) = \\frac{1}{m}\\sum_{i=1}^m\\frac{1}{2}(h_\\theta(x^{(i)} - y^{(i)})^2$\n$Cost(h_\\theta(x), y) = \\frac{1}{2}(h_\\theta(x) - y)^2$\n   We cannot use the same cost function that we use for linear regression because the Logistic Function will cause the output to be wavy, causing many local optima. In other words, it will not be a convex function.\n  $Cost(h_\\theta(x), y) = \\begin{cases}-log(h_\\theta(x))\u0026amp;\\text{if y = 1}\\\\-log(1 - h_\\theta(x)) \u0026amp;\\text{if y=0}\\end{cases}$\n  if $y = 1, h_\\theta(x) = 1 \\rarr Cost = 0$.\n  But as $h_\\theta(x) \\rarr 0, Cost \\rarr \\infty$\nPredict $P(y=1|x; \\theta) = 0$, but $y = 1$, we\u0026rsquo;ll penalize learning algorithm by a very large cost.\n    We can also write it like below:\n $Cost(h_\\theta(x), y) = -ylog(h_\\theta(x)) - (1-y)log(1 - h_\\theta(x))$    Gradient Descent   $J(\\theta) = \\frac{1}{m}\\sum_{i=1}^mCost(h_\\theta(x^{(i)}), y^{(i)})$\n$\\rarr J(\\theta) = -\\frac{1}{m}[\\sum_{i=1}^my^{(i)}log(h_\\theta(x^{(i)}) - y^{(i)}) + (1 - y^{(i)})log(1 - h_\\theta(x^{(i)}))]$\n  Repeat:\n$\\theta_j := \\theta_j - \\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)$\n$\\rarr \\theta_j := \\theta_j - \\alpha\\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}_j$\nIt looks identical to Linear Regression. BUT:\n  $h_\\theta(x) = \\theta^Tx$ in Linear Regression\n  In Logistic Regression is $h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^Tx}}$\n    A vectorized implementation is:\n$\\theta := \\theta - \\frac{\\alpha}{m}X^T(g(X\\theta) - y)$\n  Anvanced Optimization   Algorithms:\n  Gradient Descent\n  Conjugate gradient\n  BFGS\n  L-BFGS\n  Advantages:\n  No need to manually choose $\\alpha$\n  Often faster than gradient descent\n  Disadvantages:\n More complex    We can write a single function that returns both of these:\n1 2 3 4  function [jVal, gradient] = costFunction(theta) jVal = [...code to compute J(theta)...]; gradient = [...code to compute derivative of J(theta)...]; end     Then we can use octave\u0026rsquo;s \u0026ldquo;fminunc()\u0026rdquo; optimization algorithm along with the \u0026ldquo;optimset()\u0026rdquo; function that creates an object containing the options we want to send to \u0026ldquo;fminunc()\u0026rdquo;.\n1 2 3  options = optimset(\u0026#39;GradObj\u0026#39;, \u0026#39;on\u0026#39;, \u0026#39;MaxIter\u0026#39;, 100); initialTheta = zeros(2,1); [optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);     Multi-class Classification: one-vs-all ( one-vs-rest )   E.g., Email foldering / tagging: Work, Friends, Family, Hobby ($y=1, y=2, y=3, y=4$)\n  We are basically choosing one class and then lumping all the others into a single second class. We do this repeatedly, applying binary logistic regression to each case, and then use the hypothesis that returned the highest value as our prediction.\n  $h_\\theta^{(i)} = P(y = i | x; \\theta)$ $(i=1,2,3)$\n  Train a logistic regression classifier $h_\\theta^{(i)}(x)$ for each class $i$ to predict the probability that $y=i$. On a new input $x$, to make a prediction, pick the class $i$ that maximizes $max_ih_\\theta^{(i)}(x)$.\n  Overfitting Definiation  If we have too many Features, the learned hypothesis may fit the training set very well, but fail to generalize to new examples. $\\darr$   On Logistic Regression $\\darr$   Underfitting, or high bias, is when the form of our hypothesis function h maps poorly to the trend of the data. It is usually caused by a function that is too simple or uses too few features. At the other extreme, overfitting, or high variance, is caused by a hypothesis function that fits the available data but does not generalize well to predict new data. It is usually caused by a complicated function that creates a lot of unnecessary curves and angles unrelated to the data.  Adressing Overfitting:   Reduce number of Features\n  Manually select which Features to keep\n  Model selection algorithm\n    Regularization\n  Keep all the Features, but reduce magnitude / values of parameters $\\theta$.\n  Works well when we have a lot of Features, each of which contributes a bit to predicting $y$.\n    Regularization   Small Values for parameters $\\theta_0, \\theta_1, \u0026hellip;, \\theta_n$\n  \u0026ldquo;Simpler\u0026rdquo; hypothesis\n  Less prone to overfitting\n    E.g. Housing:\n  Features: $x_1, x_2, \u0026hellip;, x_{100}$\n  Parameters: $\\theta_0, \\theta_1, \u0026hellip;, \\theta_n$\n  $J(\\theta) = \\frac{1}{2m}[\\sum_{i=1}^m(h_\\theta(x^{(i)} - y^{(i)})^2 + \\lambda\\sum_{j=1}^{n}\\theta_j^2]$. We pinelize only $\\theta_{i \u0026gt; 0}$\n  $\\lambda$ is called Regulization Parameter. It determines how much the costs of our theta parameters are inflated.\n  When the $\\lambda$ too large is, $h_\\theta(x) = \\theta_0$ (Because this can make $\\theta_{i \u0026gt; 0} \\thickapprox 0$)\n    Regularized Linear Regression   Cost Function:\n $J(\\theta) = \\frac{1}{2m}[\\sum_{i=1}^m(h_\\theta(x^{(i)} - y^{(i)})^2 + \\lambda\\sum_{j=1}^{n}\\theta_j^2]$.    Gradient Descent:\n  $\\theta_0 := \\theta_0 - \\alpha \\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)}) - y^{(i)})(x_0 \\equiv 1))$\n  $\\theta_{j \u0026gt; 0} := \\theta_j - \\alpha[\\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)} - y^{(i)}))x^{(i)} + \\frac{\\lambda}{m}\\theta_j]$\n$\\rarr \\theta_{j \u0026gt; 0} := \\theta_j(1- \\alpha\\frac{\\lambda}{m}) - \\alpha\\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)} - y^{(i)}))x^{(i)}$\n  In the Equation above, $ \\theta_j(1- \\alpha\\frac{\\lambda}{m}) \u0026lt; 1$. We can be sure that the parameter will be smaller in each iteration.\n    Normal Equition:\n  $X = \\begin{bmatrix}(x^{(i)})^T\\\\\u0026hellip;\\\\(x^{(m)})^T\\\\\\end{bmatrix}$\n  $y = \\begin{bmatrix}y^{(1)}\\\\\u0026hellip;\\\\y^{(m)}\\end{bmatrix}$\n  $\\theta = (X^TX + \\lambda\\begin{bmatrix}0 \u0026amp; 0 \u0026amp; 0\\\\0 \u0026amp; 1 \u0026amp;0 \\\\ 0 \u0026amp; 0 \u0026amp; 1\\end{bmatrix})^{-1}X^Ty$\n  The Elements in the Matrix next to $\\lambda[\\text{size} = (n + 1)\\times (n + 1)]$ looks like: $e_{11} = 0,\\ e_{i \\not = j} = 0,\\ e_{i=j\\not = 1} = 1$. (With 0 at the top left and 1\u0026rsquo;s down the diagonal, with 0\u0026rsquo;s everywhere else.)\n  if $\\lambda \u0026gt; 0$, the Matrix $(X^TX + \\lambda\\begin{bmatrix}0 \u0026amp; 0 \u0026amp; 0\\\\0 \u0026amp; 1 \u0026amp;0 \\\\ 0 \u0026amp; 0 \u0026amp; 1\\end{bmatrix})$ can always transport.\n      Regularized Logistic Regression   Cost Function:\n $J(\\theta) = -[\\frac{1}{m}\\sum_{i=1}^my^{(i)}logh_\\theta(x^{(i)}) + (1 - y^{(i)})log(1 - h_\\theta(x^{(i)}))] + \\frac{\\lambda}{2m}\\sum_{j=1}^m\\theta_j^2$    Gradient Descent:\n  $\\theta_0 := \\theta_0 - \\alpha \\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)}) - y^{(i)})(x_0 \\equiv 1))$\n  $\\theta_{j \u0026gt; 0} := \\theta_j - \\alpha[\\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)} - y^{(i)}))x^{(i)} + \\frac{\\lambda}{m}\\theta_j]$\n$\\rarr \\theta_{j \u0026gt; 0} := \\theta_j(1- \\alpha\\frac{\\lambda}{m}) - \\alpha\\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)} - y^{(i)}))x^{(i)}$\n  Here $h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^Tx}}$\n    Non-Linear Hypothesis - Neural Networks   What should we do when we proceed an Image?\n Transfer it into a grayscale-image. It has only $\\frac{1}{3}$ Features that RGB-image has.    Neural Network   Origins: Algorithms that try to mimic the brain.\n  Neuron Model: Logistic Unit\n$x = \\begin{bmatrix}x_0\\\\x_1\\\\\u0026hellip;\\\\x_n\\end{bmatrix}$ (Just a Vector of Features.)\n$\\theta = \\begin{bmatrix}\\theta_0\\\\\\theta_1\\\\\u0026hellip;\\\\\\theta_n\\end{bmatrix}$\nIn this Picture, $x_0$ is called the bias unit or the bias neuron. And $x_0 \\equiv 1$\nThere\u0026rsquo;s a sigmoid(logistic) Activaition Function in this Picture\n$\\theta$( \u0026ldquo;Parameters\u0026rdquo; ) are called as \u0026ldquo;Weights\u0026rdquo; here.\n  Presentations:   $a_i^{(j)}: $ Activation of Unit $i$ in Layer $j$\n  Input Layer is the 1st Layer.\n  $\\Theta^{(j)}: $ Matrix of weights controlling function mapping from layer $j$ to layer $j+1$\n  $\\theta^{(1)}: 3\\times 4$\n  $a_1^{(2)} = g(\\Theta_{10}^{(1)}x_0 + \\Theta_{11}^{(1)}x_1 + \\Theta_{12}^{(1)}x_2 + \\Theta_{13}^{(1)}x_3)$\n$a_2^{(2)} = g(\\Theta_{20}^{(1)}x_0 + \\Theta_{21}^{(1)}x_1 + \\Theta_{22}^{(1)}x_2 + \\Theta_{23}^{(1)}x_3)$\n$a_1^{(3)} = g(\\Theta_{30}^{(1)}x_0 + \\Theta_{31}^{(1)}x_1 + \\Theta_{32}^{(1)}x_2 + \\Theta_{33}^{(1)}x_3)$\n$h_{\\Theta}(x) = a_1^{(3)} = g(\\Theta_{10}^{(2)}a_0^{(2)} + \\Theta_{11}^{(2)}a_1^{(2)} + \\Theta_{12}^{(2)}a_2^{(2)} + \\Theta_{13}^{(2)}a_3^{(2)})$\n    ⚠️ If networks has $s_j$ units in layer $j$, $s_{j+1}$ Units in layer $j+1$, then $\\Theta^{(j)}$ will be of dimension $s_{j+1} \\times (s_j + 1)$ ( Because there\u0026rsquo;s a Bias Unit in j+1th Layer ). And it should be randomly intialized.\n  Vectorized Implementation \u0026amp; Forward Propagation:   $x = \\begin{bmatrix}x_0\\\\x_1\\\\x_2\\\\x_3\\end{bmatrix}$\n$z^{(2)} = \\begin{bmatrix}z_1^{(2)}\\\\z_2^{(2)}\\\\z_3^{(2)}\\end{bmatrix}$\n$z^{(2)} = \\Theta^{(1)}x$\n  We define the Input Layer as $a^{(1)}$. Then we can write in this Form:\n$z^{(2)} = \\Theta^{(1)}a^{(1)}$\n  $a^{(2)} = g(z^{(2)})$ (Here $g$ is the Sigmoid Function.)\nAdd $a_0^{(2)} = 0$\n$z^{(3)} = \\Theta^{(2)}a^{(2)}$\n$h_\\theta(x) = a^{(3)} = g(z^{(3)})$\n  In a word, Setting $x = a^{(1)}$, we can write:\n$z^{(j)} = \\Theta^{(j - 1)}a^{(j - 1)}$\n$a^{(j)} = g(z^{(j)})$\n$h_\\Theta(x) = a^{(j + 1)} = g(z^{(j + 1)})$\n  We can through choosing $\\theta$ to realize AND, OR, NOT, XOR, XNOR\u0026hellip;\n  Cost Function Definitions:   Training Datas: ${(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \u0026hellip;, (x^{(m)}, y^{(m)})}$\n  $L = $ total no. of Layers in network\n  $s_l = $ no. of units ( not counting bias unit ) in layer $l$.\n  Classification Problems:    Binary Classification Multi-class Classification ( K classes )     $y = 0$ or $1$ $y \\isin \\R^K$, E.g. $\\begin{bmatrix}1\\\\0\\\\0\\\\0\\end{bmatrix}$, $\\begin{bmatrix}0\\\\1\\\\0\\\\0\\end{bmatrix}$, $\\begin{bmatrix}0\\\\0\\\\1\\\\0\\end{bmatrix}$, $\\begin{bmatrix}0\\\\0\\\\0\\\\1\\end{bmatrix}$   1 output unit K output units    Logistic Regression:  Brief Review:\n$J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^{m}[y^{(i)}log(h_\\theta(x^{(i)})) + (1 - y^{(i)})log(1 - h_\\theta(x^{(i)}))] + \\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_j^2$\n   Neural Network:\n$h_\\Theta(x) \\isin \\R^K, (h_\\Theta(x))_i = i^{th}$ Output\n$J(\\Theta) = -\\frac{1}{m}[\\sum_{i=1}^{m}\\sum_{k=1}^{K}y_k^{(i)}log(h_\\Theta(x^{(i)}))_k + (1 - y_k^{(i)})log(1 - (h_\\Theta(x^{(i)}))_k)] + \\frac{\\lambda}{2m}\\sum_{l = 1}^{L - 1}\\sum_{i = 1}^{s_l}\\sum_{j = 1}^{s_{l+1}}(\\Theta_{ji}^{l})^2$\n  Backpropagation Algorithm   Gradiet Descent, we need to compute:\n  $J(\\Theta)$\n  $\\frac{\\partial}{\\partial\\Theta_{ij}^{(l)}}J(\\Theta)$\n   $J(\\Theta) = -\\frac{1}{m}[\\sum_{i=1}^{m}\\sum_{k=1}^{K}y_k^{(i)}log(h_\\Theta(x^{(i)}))_k + (1 - y_k^{(i)})log(1 - (h_\\Theta(x^{(i)}))_k)] + \\frac{\\lambda}{2m}\\sum_{l = 1}^{L - 1}\\sum_{i = 1}^{s_l}\\sum_{j = 1}^{s_{l+1}}(\\Theta_{ji}^{l})^2$\n   Intuition:\n  $\\delta_j^{(l)}$ = \u0026ldquo;error\u0026rdquo; of node $j$ in layer $l$.\n  For each output Unit ( Layer = 4 ):\n$\\delta_j^{(4)} = a_j^{(4)} - y_j$\n$a_j^{(4)} = (h_\\theta(x))_j$\nWe have: $\\delta^{(4)} = a^{(4)} - y$\n  Then we execute the following Operations:\n$\\delta^{(3)} = (\\Theta^{(3)})^T\\delta^{(4)} .* g'(z^{(3)})$\n$\\delta^{(2)} = (\\Theta^{(2)})^T\\delta^{(3)} .* g'(z^{(2)})$\nHere $g'(z^{(n)}) = a^{(n)} .* (1 - a^{(n)})$\n$\\delta^{(l)} = ((\\Theta^{(l)})^T\\delta^{(l + 1)}) .* a^{(l)} .* (1 - a^{(l)})$\n    Specifically:\n  Training Set: ${(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \u0026hellip;, (x^{(m)}, y^{(m)})}$\n  Set $\\Delta_{ij}^{(l)} = 0$, for all $i, j, l$\n  For $i = 1$ to $m$:\nSet $a^{(1)} = x^{(i)}$\nPerform forward propagation to compute $a^{(l)}$ for $l = 2, 3, \u0026hellip;, L$\nUsing $y^{(i)}$, compute $\\delta^{(L)} = a^{(L)} - y^{(i)}$\nCompute $\\delta^{(L - 1)}, \\delta^{(L - 2)}, \u0026hellip;, \\delta^{(2)}$\n$\\Delta_{ij}^{(l)}:= \\Delta_{ij}^{(l)} + a_j^{(l)}\\delta_i^{(l+1)}$\n  Vectorization:\n$\\Delta^{(l)} := \\Delta^{(l)} + \\delta^{(l + 1)}(a^{(l)})^T$\n  $D_{ij}^{(l)} := \\frac{1}{m}(\\Delta_{ij}^{(l)} + \\lambda\\Theta_{ij}^{(l)})$ if $j \\neq 0$\n  $D_{ij}^{(l)} := \\frac{1}{m}\\Delta_{ij}^{(l)}$ if $j = 0$\n    Training Neural Network   Randomly initialize weights\n  Implement forward propagation to get $h_\\Theta(x^{(i)})$ for any $y^{(i)}$\n  Implement code to compute cost function $J(\\Theta)$\n  Implement backpropagation to compute partial derivates $\\frac{\\partial}{\\partial\\Theta_{jk}^{(l)}} J(\\Theta)$\n  Use Gradient Checking to compare $\\frac{\\partial}{\\partial\\Theta_{jk}^{(l)}} J(\\Theta)$ computed using back propagation vs. using numerical estimate of gradient of $J(\\Theta)$, then disable gradient checking code.\n  Use Gradient Descent or advanced optimization method with backpropagation to try to minimize $J(\\Theta)$ as a function of parameters $\\Theta$\n  1 2 3  for i = 1:m, Perform forward propagation and backpropagation using example (x(i),y(i)) (Get activations a(l) and delta terms d(l) for l = 2,...,L   Evaluating Hypothesis   Split the labeled data randomly into 2 Parts: Training Set ( 70% ) and Test Set ( 30% ).\n  Learn the parameter $\\theta$ from Training data\n  Computing test Set error:\n  In Linear Regression: $J(\\theta) = \\frac{1}{2m_{test}}\\sum_{i = 1}^{m_{test}}(J(x_{test}^{(i)}) - y_{test}^{(i)})^2$\n  In Logistic Regression: $J(\\theta) = -\\frac{1}{m_{test}}\\sum_{i = 1}^{m_{test}}[y^{(i)}logh_{\\theta}(x^{(i)}_{test}) + (1 - y^{(i)})log(1 - h_{\\theta}(x^{(i)}_{test}))]$\n    Misclassification error ( 0/1 multiclassification error ):\n $err(h_{\\theta}(x), y) = 1$, if $h_{\\theta}(x) \\leq 0.5, y = 1 | h_{\\theta}(x) \\geq 0.5, y = 0$ $Test_{error} = \\frac{1}{m_{test}}\\sum_{i = 1}^{m_{test}}err(h_{\\theta}(x_{test}^{(i)}), y^{(i)})$    Model Selection, Training, Validation and Test Model Selection 1). $h_{\\theta}(x) = \\theta_0 + \\theta_1(x) \\rarr \\theta^{(1)} \\rarr J_{test}(\\theta^{(1)})$\n2). $h_{\\theta}(x) = \\theta_0 + \\theta_1(x) + \\theta_2^2(x) \\rarr \\theta^{(2)} \\rarr J_{test}(\\theta^{(2)})$\n3). $h_{\\theta}(x) = \\theta_0 + \\theta_1(x) + \\theta_2^2(x) + \\theta_3^3(x) \\rarr \\theta^{(3)} \\rarr J_{test}(\\theta^{(3)})$\n\u0026hellip;\n10). $h_{\\theta}(x) = \\theta_0 + \\theta_1(x) + \\theta_2^2(x) + \\theta_3^3(x) + \u0026hellip; + \\theta_{10}^{10}(x) \\rarr \\theta^{(10)} \\rarr J_{test}(\\theta^{(10)})$\n  We should\u0026rsquo;t use the chosen $\\theta^{(5)}$ to test how well it fits in our Test Set. Because we become it from Training Set, and the Test Set has the same Dimension as the Training Set. It lacks of Generalization on New Data Set.\n  Thus, we split the Data Set into 3 pieces: Training Set ( 60% ), Cross Validation Set ( 20% ), Test Set ( 20% ).\n  Train ( Books ) / Validation ( Homework ) / Test Error ( Examination )   Training Error\n $J_{train}(\\theta) = \\frac{1}{2m_{train}}\\sum_{i = 1}^{m_{train}}(h_{\\theta}(x_{train}^{(i)}) - y_{train}^{(i)})^2$    Validation Error\n $J_{cv}(\\theta) = \\frac{1}{2m_{cv}}\\sum_{i = 1}^{m_{cv}}(h_{\\theta}(x_{cv}^{(i)}) - y_{cv}^{(i)})^2$    Test Error\n $J_{test}(\\theta) = \\frac{1}{2m_{test}}\\sum_{i = 1}^{m_{test}}(h_{\\theta}(x_{test}^{(i)}) - y_{test}^{(i)})^2$  1). $h_{\\theta}(x) = \\theta_0 + \\theta_1(x) \\rarr \\theta^{(1)} \\rarr J_{cv}(\\theta^{(1)})$\n2). $h_{\\theta}(x) = \\theta_0 + \\theta_1(x) + \\theta_2^2(x) \\rarr \\theta^{(2)} \\rarr J_{cv}(\\theta^{(2)})$\n3). $h_{\\theta}(x) = \\theta_0 + \\theta_1(x) + \\theta_2^2(x) + \\theta_3^3(x) \\rarr \\theta^{(3)} \\rarr J_{cv}(\\theta^{(3)})$\n\u0026hellip;\n10). $h_{\\theta}(x) = \\theta_0 + \\theta_1(x) + \\theta_2^2(x) + \\theta_3^3(x) + \u0026hellip; + \\theta_{10}^{10}(x) \\rarr \\theta^{(10)} \\rarr J_{cv}(\\theta^{(10)})$\nPick $h_{\\theta}(x) = \\theta_0 + \\theta_1(x) + \\theta_2^2(x) + \\theta_3^3(x) + \\theta_4^4(x)$, Estimate generalization error for test set $J_{test}(\\theta^{(4)})$\n  Diagnosing Bias ( Too high -\u0026gt; underfit ) vs. variance ( Too high -\u0026gt; overfit )   Training Error\n $J_{train}(\\theta) = \\frac{1}{2m_{train}}\\sum_{i = 1}^{m_{train}}(h_{\\theta}(x_{train}^{(i)}) - y_{train}^{(i)})^2$    Validation Error\n $J_{cv}(\\theta) = \\frac{1}{2m_{test}}\\sum_{i = 1}^{m_{cv}}(h_{\\theta}(x_{cv}^{(i)}) - y_{cv}^{(i)})^2$    Draw the \u0026ldquo;Degree of polynomioal d - Error\u0026rdquo; plot. In this Plot draw the $J_{train}(\\theta), J_{cv/test}(\\theta)$. Then we can make sure wether it\u0026rsquo;s high bias or high variance.\n    Bias ( Underfit, when d too small ):\n  $J_{train}(\\theta)$ will be high\n  $J_{train}(\\theta) \\approx J_{cv}(\\theta)$\n    Variance ( Overfit, when d too large ):\n  $J_{train}(\\theta)$ will be low\n  $J_{cv}(\\theta) \\gg J_{train}(\\theta)$\n    Regularization and bias / variance   Linear Regression with Regularization\nModel: $h_{\\theta}(x) = \\theta_0 + \\theta_1x + \\theta_2x^2 + \\theta_3x^3 + \\theta_4x^4$\nGoal: $J(\\theta) = \\frac{1}{2m}\\sum_{i = 1}^m(h_\\theta(x^{(i)}) - y^{(i)})^2 + \\frac{\\lambda}{2m}\\sum_{j = 1}^n\\theta_j^2$\n$J_{train}(\\theta) = \\frac{1}{2m_{train}}\\sum_{i = 1}^{m_{train}}(h_{\\theta}(x_{train}^{(i)}) - y_{train}^{(i)})^2$\n$J_{cv}(\\theta) = \\frac{1}{2m_{cv}}\\sum_{i = 1}^{m_{cv}}(h_{\\theta}(x_{cv}^{(i)}) - y_{cv}^{(i)})^2$\n$J_{test}(\\theta) = \\frac{1}{2m_{test}}\\sum_{i = 1}^{m_{test}}(h_{\\theta}(x_{test}^{(i)}) - y_{test}^{(i)})^2$\n  Chossing the parameter $\\lambda$\n1). Try $\\lambda = 0 \\rarr minJ(\\theta) \\rarr \\theta^{(1)} \\rarr J_{cv}(\\theta^{(1)})$\n2). Try $\\lambda = 0.01 \\rarr minJ(\\theta) \\rarr \\theta^{(2)} \\rarr J_{cv}(\\theta^{(2)})$\n3). Try $\\lambda = 0.02 \\rarr minJ(\\theta) \\rarr \\theta^{(3)} \\rarr J_{cv}(\\theta^{(3)})$\n4). Try $\\lambda = 0.04 \\rarr minJ(\\theta) \\rarr \\theta^{(4)} \\rarr J_{cv}(\\theta^{(4)})$\n5). Try $\\lambda = 0.08 \\rarr minJ(\\theta) \\rarr \\theta^{(5)} \\rarr J_{cv}(\\theta^{(5)})$\n\u0026hellip;\n10). Try $\\lambda = 10 \\rarr minJ(\\theta) \\rarr \\theta^{(10)} \\rarr J_{cv}(\\theta^{(10)})$\nPick $\\theta^{(5)}$, Test Error: $J_{test}(\\theta^{(5)})$\n  Draw the \u0026ldquo;lambda - Error\u0026rdquo; plot. In this Plot draw the $J_{train}(\\theta), J_{cv/test}(\\theta)$.\n  When $\\lambda$ too large:\n  $J_{train}(\\theta)$ will be high\n  $J_{train}(\\theta) \\approx J_{cv}(\\theta)$\n    When $\\lambda$ too small:\n  $J_{train}(\\theta)$ will be low\n  $J_{cv}(\\theta) \\gg J_{train}(\\theta)$\n    The Situation is contrary to the Dimension d.\n   Think in this way: when $\\lambda$ is too large, it penalizes $\\theta$ strongly, $J(\\theta)$ is just a straight line, this causes underfitting. When too small ( i.g. 0 ), it causes overfitting ( what $lambda$ aims to overcoming ).  Learning Curves   $J_{train}(\\theta) = \\frac{1}{2m_{train}}\\sum_{i = 1}^{m_{train}}(h_{\\theta}(x_{train}^{(i)}) - y_{train}^{(i)})^2$\n$J_{cv}(\\theta) = \\frac{1}{2m_{cv}}\\sum_{i = 1}^{m_{cv}}(h_{\\theta}(x_{cv}^{(i)}) - y_{cv}^{(i)})^2$\n  Draw the \u0026ldquo;m ( size of Training Set ) - Error\u0026rdquo; plot. Reduce $m$ artificially.\n  Training Set Error will increase when m increases (if m very small, we can predict it perfectly, but getting harder if m grows ), and the Cross Validation Error will decrease on the contrary ( Because we optimize the parameters ).\n  High Bias:\n   High Variance:    Overfitting for large m is very hard. There\u0026rsquo;s a large gap between 2 curves. ( $J_{train}(\\theta), J_{test}(\\theta)$)\n  In \u0026ldquo;high Variance\u0026rdquo; Situation, it helps to get more training examples.\n  How to deal with high Bias \u0026amp; high Variance?    high Bias high Variance     Getting additional Features Getting more Training examples   Try adding polynomial Features Try smaller sets of Features   Try decreasing $\\lambda$ Try increasing $\\lambda$    Error Analysis Recommand Approach   Start with a simple algorithm that you can implement quickly. Implement it and test it on Cross-Validation Set.\n  Plot learning curves to decide if more Data, more Features, etc.\n  Error Analysis: Manually examine the examples ( In Cross Validation Set ) that your algorithm made errors on. See if you spot any systematic trend in what type of examples it is making errors on.\n  Error metrics for skewed classes   Cancer classification example:\n  Train logistic regression model $h_\\theta(x). ( y = 1 if cancer )\n  Find you got $1%$ error on test set\n  Only $0.50%$ patients have cancer\n1 2 3  function y = predictCancer(x) y = 0; // ignore x! Because 99.5% Patients don\u0026#39;t have cancer! return       Precision / Recall     1 0     1 True positiv False positiv   0 False Negative True Negative      Precision: Of all patients where we predicted $y = 1$, what fraction actually has cancer?\nTrue positives / predicted Positive = True positives / (True Pos + False Pos)\n  Recall( Of all patients that actually have cancer, what fraction did we corrently detect as having cancer? )\nTrue positives / actual Positives = True Positives / (True Pos + False Neg)\n  Trading off precision and recall   Logistic Regression: $0 \\leq h_\\theta(x) \\leq 1$ Predict 1 if $h_\\theta(x) \\geq 0.5$ Predict 0 if $h_\\theta(x) \\leq 0.5$\n  Suppose we want to predict $y = 1$ ( cancer ) only if very confident\n$\\rarr \\text{Higher Precision, lower Recall}$\n  Suppose we want to avoid missing too many cases of cancer ( avoid false Negatives )\n$\\rarr \\text{Higher Recall, lower Precision}$\n  More generally, predict 1 if $h_\\theta(x) \\geq \\text{threshold}$\n  F Score  How to compare Precision / Recall numbers?      Precision (P) Recall (R) F Score     Algorithm 1 0.5 0.4 0.444   Algorithm 2 0.7 0.1 0.175   Algorithm 3 0.02 1 0.0392     F Score: $2\\frac{PR}{P + R}$  Support Vector Machines Optimization objective  Brief Review of Logistic Regression\n$h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^Tx}}$\nif $y = 1$, we want $h_\\theta(x) \\approx 1, \\theta^Tx \\gg 0$\nif $y = 0$, we want $h_\\theta(x) \\approx 0, \\theta^Tx \\ll 0$\n$J(\\theta) = -\\frac{1}{m}\\sum_{i = 1}^{m}[y^{(i)}log(h_\\theta(x^{(i)})) + (1 - y^{(i)})log(1 - h_\\theta(x^{(i)}))] + \\frac{\\lambda}{2m}\\sum_{j = 1}^{n}\\theta_j^2$\n   $-log\\frac{1}{1 + e^{-x}} \\rarr Cost_1(\\theta^Tx^{(i)})$\n  $-log(1 - \\frac{1}{1 + e^{-x}}) \\rarr Cost_0(\\theta^Tx^{(i)})$\n  Cost Function:   We use a new function to replace $-log\\frac{1}{1 + e^{-x}} \\text{and} -log(1 - \\frac{1}{1 + e^{-x}})$. We name they as $Cost_1(\\theta^Tx^{(i)})\\text{and}Cost_0(\\theta^Tx^{(i)})$. Then the Cost Function in SVM is:\n$\\frac{1}{m}\\sum_{i = 1}^{m}[y^{(i)}Cost_1(\\theta^Tx^{(i)}) + (1 - y^{(i)})Cost_0(\\theta^Tx)] + \\frac{\\lambda}{2m}\\sum_{j = 1}^{n}\\theta_j^2$\nThe following Plot is the Picture of 2 new Functions:\nOur goal is to minimize the following Function:\n$min_\\theta C\\sum_{i = 1}^{m}[y^{(i)}Cost_1(\\theta^Tx^{(i)}) + (1 - y^{(i)})Cost_0(\\theta^Tx)] + \\frac{1}{2}\\sum_{j = 1}^{n}\\theta_j^2$\n  SVM Hypothesis:  $h_\\theta(x) = \\begin{cases}1, \\theta^Tx \\geq 0\\\\0, \\theta^Tx \u0026lt; 0\\end{cases}$  Large Margin Intuition  Take a look at the Plot of the new Cost Functions:  if $y = 1$, we want $\\theta^Tx \\geq 1$ if $y = 0$, we want $\\theta^Tx \\leq -1$    SVM Decision Boundary   $min_\\theta C\\sum_{i = 1}^{m}[y^{(i)}Cost_1(\\theta^Tx^{(i)}) + (1 - y^{(i)})Cost_0(\\theta^Tx^{(i)})] + \\frac{1}{2}\\sum_{j = 1}^{n}\\theta_j^2 ( C = \\frac{1}{\\lambda} )$\n Large C: lower Bias, higher Variance Small C: higher Bias, lower Variance    In \u0026ldquo;Large Margin Boundary\u0026rdquo; we know, we just have to optimize the following function:\n$\\frac{1}{2}\\sum_{j = 1}^{n}\\theta_j^2$ ( Because the front part can be 0. )\n  Kernels Kernel Function   Given x,:\n$f_i = similarity(x, l^{(i)}) = exp(-\\frac{||x - l^{(2)}||^2}{2\\sigma^2})$\n  Large $\\sigma^2$: Features $f_i$ vary very smmothly: Higher Bias, lower Variance\n  Small $\\sigma^2$: Features $f_i$ vary very smmothly: lower Bias, higher Variance\n  SVM with Kernels   Where to get $l^{(1)}, l^{(2)}, l^{(3)} \u0026hellip; ?$\n  Given $(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \u0026hellip;, (x^{(m)}, y^{(m)})$\n  Choose $l^{(1)} = x^{(1)}, l^{(2)} = x^{(2)}, \u0026hellip;, l^{(m)} = x^{(m)}$\n    Given $x$:\n$f_1 = similarity(x, l^{(1)})$\n$f_2 = similarity(x, l^{(2)})$\n\u0026hellip;\n$f = \\begin{bmatrix}f_0\\\\f_1\\\\f_2\\\\\u0026hellip;\\\\f_m\\end{bmatrix}, f_0 = 1$\n  For Training example $(x^{(i)}, y^{(i)}):$\n$f_1^{(i)} = similarity(x^{(i)}, l^{(1)})$\n$f_2^{(i)} = similarity(x^{(i)}, l^{(2)})$\n$f_3^{(i)} = similarity(x^{(i)}, l^{(3)})$\n\u0026hellip;\n$f_m^{(i)} = similarity(x^{(i)}, l^{(m)})$\n$f^{(x)} = \\begin{bmatrix}f_0^{(i)}\\\\f_1^{(i)}\\\\\u0026hellip;\\\\f_m^{(i)}\\end{bmatrix}$\n  Predict $y = 1, \\text{if } \\theta^Tf \\geq 0$\n  Training: $min_\\theta C\\sum_{i = 1}^{m}[y^{(i)}Cost_1(\\theta^Tf^{(i)}) + (1 - y^{(i)})Cost_0(\\theta^Tf^{(i)})] + \\frac{1}{2}\\sum_{j = 1}^{n}\\theta_j^2$\n  Logistic Regression vs. SVMs   n = number of Features, m = number of Training examples\n  if n is large ( relative to m ):\nUse logistic Regression, or SVM without a kernel\n  if n is small, m is intermediate:\nUse SVM with Gaussian Kernel\n  if n is small, m is large:\nCreate / Add more Features, then use logistic regression or SVM without a Kernel\n  Unsupervised Learning Clustering K-Mean Algorithm   Input:\n  K ( Number of clusters )\n  Training Set ${x^{(1)}, x^{(2)}, \u0026hellip;, x^{(m)}}$\n  $x^{(i)} \\isin \\R^n$ ( Drop $x_0 = 1$ convention )\n    Randomly initialize K cluster Centroids $\\mu_1, \\mu_2, \u0026hellip;, \\mu_k\\isin\\R^n$\n  Repeat:\n1 2 3 4 5 6 7  // Cluster Assignment for i = 1 to m: c^(i) := index ( from 1 to K ) of Cluster Centroid closest to x^(i) // ||x^(i) - mu_k|| // Move Centroid for k = 1 to K: mu_k := average ( mean ) of points asssigned to cluster k // A vector in R^n     In the code above\n  $c^{(i)}$ means the index of cluster to which example $x^{(i)}$ is currently assigned.\n  $\\mu_k\\ \\text{means the cluster centroid}\\ k (\\mu_k \\isin\\R^n)$\n  $\\mu{c^{(i)}}$ means the cluster centroid of cluster to which example $x^{(i)}$ has been assigned._\n      Optimization Objective of K-Mean: Distortion Function  $J(c^{(1)}, \u0026hellip;, c^{(m)}, \\mu_1, \u0026hellip;, \\mu_k) = \\frac{1}{m}\\sum_{i = 1}^m||x^{(i)} - \\mu_{c^{(i)}}||^2$  Initialize K-Means   Randomly pick K training examples\n  Set $\\mu_1, \u0026hellip;, \\mu_k$ equal to these K examples.\n1 2 3 4 5 6 7 8  for i = 1 to 100{ Randomly initialize K-means Run K-means, Get c^(1), ..., c^(m), mu^(1), ..., , mu^(K) Compute the distortion Function } Pick clustering that gave lowest distortion Function value.     Choosing the number of clusters   Alternative: Draw the \u0026ldquo;K - Distortion Function Value\u0026rdquo; plot. ( Elbow Method )\n  Dimentionality Reduction PAC: Principal Component Analysis   Reduce from 2-dimension to 1-dimension: Find a direction ( a vector $\\mu^{(1)} \\isin \\R^n$ ) onto which to project the data so as to minimize the projection error.\n  Reduce from n-dimension to k-dimension: Find k vectors ( vectors $\\mu^{(1)}, \u0026hellip;, \\mu^{(k)}$ ) onto which to project the data, so as to minimize the projection error.\n  Reduce memory / disk needed to store data\n  Speed up learning algorithm\n  Bad use of PCA: To prevent overfitting. Instead, use regularization.\n  PCA is not Linear Regression!\n  Data Processing   Training Set: $x^{(1)}, x^{(2)}, \u0026hellip;, x^{(m)}$\n  Preprocessing ( Feature Scaling / Mean Normalization )\n$\\mu_j = \\frac{1}{m}\\sum_{i = 1}^mx_j^{(i)}$\nReplace each $x_j^{(i)}$ with $x_j - \\mu_j$\nIf different features have different scales, scale Features to have comparable range of values $x_j \\larr \\frac{x_j^{(i)} - \\mu_j}{s_j}$\n  PCA algorithm   Reduce data from n-dimensions to k-dimensions\n  Compute \u0026ldquo;convariance matrix\u0026rdquo;\n$\\Sigma = \\frac{1}{m}\\sum_{i = 1}^{m}(x^{(i)})(x^{(i)})^T, \\Sigma \\isin \\R^{n\\times n}$\n  Compute the \u0026ldquo;eigenvectors\u0026rdquo; of $\\Sigma$:\n1 2 3  [U, S, V] = svd( Sigma ) // Singular Value Decomposition; Uredece = U(:, 1:k); z = Ureduce\u0026#39; * x;   From the formular above we get:\n$U = \\begin{bmatrix}|\u0026amp;|\u0026amp;\u0026hellip;\u0026amp;|\\\\u^{(1)}\u0026amp;u^{(2)}\u0026amp;\u0026hellip;\u0026amp;u^{(n)}\\\\|\u0026amp;|\u0026amp;\u0026hellip;\u0026amp;|\\end{bmatrix} \\isin \\R^{n\\times n}$\nThen we use the first k columns in the Matrix:\n$z^{(i)} = U_{reduce}^Tx^{(i)} = \\begin{bmatrix}|\u0026amp;|\u0026amp;\u0026hellip;\u0026amp;|\\\\u^{(1)}\u0026amp;u^{(2)}\u0026amp;\u0026hellip;\u0026amp;u^{(k)}\\\\|\u0026amp;|\u0026amp;\u0026hellip;\u0026amp;|\\end{bmatrix}^Tx^{(i)} = \\begin{bmatrix}-\u0026amp;(u^{(1)})^T\u0026amp;-\\\\\u0026hellip;\u0026amp;\u0026hellip;\u0026amp;\u0026hellip;\\\\-\u0026amp;(u^{(k)})^T\u0026amp;-\\end{bmatrix}x^{(i)} \\isin \\R^{k\\times 1}$\n  Choosing k ( number of principle components )   Average squaied projection error: $\\frac{1}{m}\\sum_{i = 1}^m||x^{(i)} - x_{approx}^{(i)}||^2$\n  Total variation in the data: $\\frac{1}{m}\\sum_{i = 1}^{m}||x^{(i)}||^2$\n  Typically, choose k to be smallest value so that:\n$\\frac{\\frac{1}{m}\\sum_{i = 1}^m||x^{(i)} - x^{(i)}_{approx}||^2}{\\frac{1}{m}\\sum_{i = 1}^{m}||x^{(i)}||^2} \\leq 0.01$\n\u0026ldquo;99% of variances is retained\u0026rdquo;\n  Algorithm:\n  Try PCA with k = 1\n  Compute $U_{reduce}, z^{(1)}, z^{(2)}, \u0026hellip;, z^{(m)}, x_{approx}^{(1)}, \u0026hellip;, x^{(m)}_{approx}$\n  Check if $\\frac{\\frac{1}{m}\\sum_{i = 1}^m||x^{(i)} - x^{(i)}_{approx}||^2}{\\frac{1}{m}\\sum_{i = 1}^{m}||x^{(i)}||^2} \\leq 0.01$\n[U, S, V] = svd( Sigma )\nFor given k, $\\frac{\\frac{1}{m}\\sum_{i = 1}^m||x^{(i)} - x^{(i)}_{approx}||^2}{\\frac{1}{m}\\sum_{i = 1}^{m}||x^{(i)}||^2} = 1 - \\frac{\\sum_{i = 1}^ks_{ii}}{\\sum_{i = 1}^{n}s_{ii}} \\rarr \\frac{\\sum_{i = 1}^ks_{ii}}{\\sum_{i = 1}^{n}s_{ii}} \\geq 0.99$\n  Pick k, that satisfies $\\frac{\\sum_{i = 1}^ks_{ii}}{\\sum_{i = 1}^{n}s_{ii}} \\geq 0.99$\n    Reconstruction from compressed representation  $X_{approx} = U_{reduce} \\times z$  Design of ML system with PCA   Get Training Set\n  Run PCA to reduce $x^{(i)}$ in dimension to get $z^{(i)}$\n  Train logistic regression on ${(z^{(1)}, y^{(1)}), \u0026hellip;, (z^{(m)}, y^{(m)})}$\n  Test on test set: Map $x_{test}^{(i)}\\ \\text{to}\\ z_{test}^{(i)}$. Run $h_\\theta(z)$ on ${(z_{test}^{(1)}, y_{test}^{(1)}), \u0026hellip;, (z_{test}^{(m)}, y_{test}^{(m)})}$\n  Before implementing PCA, first try running whatever you want to do with original / raw data $x^{(i)}$. Only if that doesn\u0026rsquo;t do what you want, then implement PCA and consider using $z^{(i)}$\n  Anomoly Detection Example: Fraud Detection   $x^{(i)}$ = features of user i\u0026rsquo;s activities\n  Model $p(x)$ from data\n  Identify unusual users by checking which have $p(x) \u0026lt; \\epsilon$\n  Gaussian Distribution   Say $x \\isin \\R$. If x is a disatributed Gaussian with mean $\\mu$, variance $\\sigma^2$.\n  $p(x; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma}exp^{(-\\frac{(x - \\mu)^2}{2\\sigma^2})}$. Here $\\sigma$ is the standard deviation.\n  As for \u0026ldquo;Parameter estimation\u0026rdquo;\u0026hellip;\n $\\mu = \\frac{1}{m}\\sum_{i = 1}^mx^{(i)}$ $\\sigma^2 = \\frac{1}{m}\\sum_{i = 1}^m(x^{(i)} - \\mu)^2$    Algorithm   Training Set ${x^{(1)}, \u0026hellip;, x^{(m)}}$\n  Each Example is $x \\isin \\R^n$\n    Chosse features $x_i$ that you think might be indicative of anomalous examples.\n  Fit parameters $\\mu_1, \u0026hellip;, \\mu_n, \\sigma_1^2, \u0026hellip;, \\sigma_n^2$\n$\\mu = \\frac{1}{m}\\sum_{i = 1}^mx^{(i)}$\n$\\sigma^2 = \\frac{1}{m}\\sum_{i = 1}^m(x^{(i)} - \\mu)^2$\n  Given new example x, compute $p(x)$\n$p(x) = \\prod_{j = 1}^np(x_j;\\mu_j, \\sigma_j^2) = \\prod_{j = 1}^n\\frac{1}{\\sqrt{2\\pi}\\sigma}exp^{(-\\frac{(x - \\mu)^2}{2\\sigma^2})}$\n  Anomaly if $p(x) \u0026lt; \\epsilon$\nEvaluation   Fit model $p(x)$ on training set ${x^{(1)}, \u0026hellip;, x^{(m)}}$\n  On a Cross Validation / Test example, predict\n$y = \\begin{cases}1,\\ p(x) \u0026lt; \\epsilon\\ \\text{(anomaly)}\\\\0,\\ p(x) \\geq \\epsilon\\ \\text{(normal)}\\end{cases}$\n  Possible evaluation metrics:\n  True positive, false positive, false negative, true negative\n  Precision / Recall\n  F-Score\n  Can also use the Cross Validation Set to choose parameter $\\epsilon$\n  Anomoly Detection vs. Supervised Learning    Anomoly Detection Supervised Learning     Very small number of positiv examples but large number of negative examples Large number of positive and negative examples   Many different types of anomalies. Hard for any algorithm to learn from positive examples what the anomalies looks like Enough positive examples for algorithm to get a sense of what positive examples are like   Future anomalies may look nothing like any of the anomalous examples we\u0026rsquo;ve seen so far Future positive examples likely to be similar to ones in training set    Error Analysis for anomaly detection   Want $p(x)$ large for normal examples x\n$p(x)$ small for anomalous examples x\n  Most commen Problem:\n$p(x)$ is comparable ( say, both large ) for normal and anomalous examples.\n  Multivariance Gaussian Distribution   $x \\isin \\R^n$, don\u0026rsquo;t model $p(x_1), p(x_2)$, \u0026hellip;, etc. separately. Instead, model $p(x)$ all in one go.\n  Parameters: $\\mu\\isin\\R^n, \\Sigma \\isin \\R^{n\\times n}$, the \u0026ldquo;convariance matrix\u0026rdquo;\n  $p(x; \\mu, \\Sigma) = \\frac{1}{(2\\pi)^{(\\frac{n}{2})}|\\Sigma|^\\frac{1}{2}}exp(=\\frac{1}{2}(x - \\mu)^T\\Sigma^{-1}(x - \\mu))$\n  Recommander Systems Problem Formulation Example: Predicting movie ratings    Movie Alice(1) Bob(2) Carol(3) Dave(4)     Love at last 5 5 0 0   Romance forever 5 ? ? 0   Cute Puppies of love ? 4 0 ?   Nonstop car cashes 0 0 5 4   Swords vs. karate 0 0 5 ?      $n_u$: no.users\n$n_m$: no.movies\n$r(i, j) = 1$: if user $j$ has rated movie $i$\n$y^{(i,j)} \\isin [0,5]$: rating given by user $j$ to movie $i$ ( defined only if $r(i, j) = 1$ )\n  Contnet-based recommendations    Movie Alice(1) Bob(2) Carol(3) Dave(4) $x_1$(romance) $x_2$(action)     Love at last 5 5 0 0 0.9 0   Romance forever 5 ? ? 0 1.0 0.01   Cute Puppies of love ? 4 0 ? 0.99 0   Nonstop car cashes 0 0 5 4 0.1 1.0   Swords vs. karate 0 0 5 ? 0 0.9      For each user j, learn a parameter $\\theta^{(j)} \\isin \\R^3$. Predict user j as rating movie i with $(\\theta^{(j)})^Tx^{(i)}$ stars. ( $x_0 = 1$ )\n  $\\theta^{(j)} =$ parameter vector for user $j$\n$x^{(i)} =$ feature vector for movie $i$\nFor user j, movie i, predicting rating: $(\\theta^{(j)})^Tx^{(i)}$\n$m^{(j)} =$ no.of movies rated by user $j$\n  To learn $\\theta^{(j)}$:\n$min_{\\theta^{(j)}}\\frac{1}{2m^{(j)}}\\sum_{i:r(i, j) = 1}((\\theta^{(j)})^T(x^{(i)} - y^{(i, j)})^2 + \\frac{\\lambda}{2m^{(j)}}\\sum_{k = 1}^{n}(\\theta_k^{(j)})^2$\n$\\rarr min_{\\theta^{(j)}}\\frac{1}{2}\\sum_{i:r(i, j) = 1}((\\theta^{(j)})^T(x^{(i)} - y^{(i, j)})^2 + \\frac{\\lambda}{2}\\sum_{k = 1}^{n}(\\theta_k^{(j)})^2$\n  To learn $\\theta^{(1)}, \\theta^{(2)}, \u0026hellip;, \\theta^{(n_u)}$:\n$min_{\\theta^{(1)}, \\theta^{(2)}, \u0026hellip;, \\theta^{(n_u)}}\\frac{1}{2}\\sum_{j = 1}^{n_u}\\sum_{i:r(i, j) = 1}((\\theta^{(j)})^T(x^{(i)} - y^{(i, j)})^2 + \\frac{\\lambda}{2}\\sum_{j = 1}^{n_u}\\sum_{k = 1}^{n}(\\theta_k^{(j)})^2$\n  Optimization Algorithm   $min_{\\theta^{(1)}, \\theta^{(2)}, \u0026hellip;, \\theta^{(n_u)}}\\frac{1}{2}\\sum_{j = 1}^{n_u}\\sum_{i:r(i, j) = 1}((\\theta^{(j)})^T(x^{(i)} - y^{(i, j)})^2 + \\frac{\\lambda}{2}\\sum_{j = 1}^{n_u}\\sum_{k = 1}^{n}(\\theta_k^{(j)})^2$\n  Gradient Descent update:\n$\\theta_k^{(j)} \\coloneqq \\theta_k^{(j)} - \\alpha\\sum_{i:r(i, j) = 1}((\\theta^{(j)})^Tx^{(i)} - y^{(i, j)})x_k^{(i)}$ ( for $k = 0$ )\n$\\theta_k^{(j)} \\coloneqq \\theta_k^{(j)} - \\alpha(\\sum_{i:r(i, j) = 1}((\\theta^{(j)})^Tx^{(i)} - y^{(i, j)})x_k^{(i)} + \\lambda\\theta_k^{(j)})$ ( for $k \\not = 0$ )\n  Collaborative Filtering Optimization Algorithm   Given $\\theta^{(1)}, \\theta^{(2)}, \u0026hellip;, \\theta^{(n_u)}$, to learn $x^{(i)}$:\n$min_{x^{(i)}}\\frac{1}{2}\\sum_{j = 1}^{n_u}\\sum_{i:r(i, j) = 1}((\\theta^{(j)})^T(x^{(i)} - y^{(i, j)})^2 + \\frac{\\lambda}{2}\\sum_{k = 1}^{n}(x_k^{(i)})^2$\n  Given $\\theta^{(1)}, \\theta^{(2)}, \u0026hellip;, \\theta^{(n_u)}$, to learn $x^{(1)}, \u0026hellip;, x^{(n_u)}$:\n$min_{x^{(1)}, x^{(2)}, \u0026hellip;, x^{(n_m)}}\\frac{1}{2}\\sum_{i = 1}^{n_m}\\sum_{i:r(i, j) = 1}((\\theta^{(j)})^T(x^{(i)} - y^{(i, j)})^2 + \\frac{\\lambda}{2}\\sum_{i = 1}^{n_m}\\sum_{k = 1}^{n}(x_k^{(i)})^2$\n  Collaborative Filtering   Given $x^{(1)}, x^{(2)}, \u0026hellip;, x^{(n_m)}$ (and movie ratings), can estimate $\\theta^{(1)}, \\theta^{(2)}, \u0026hellip;, \\theta^{(n_u)}$\n  Given $\\theta^{(1)}, \\theta^{(2)}, \u0026hellip;, \\theta^{(n_u)}$, can estimate $x^{(1)}, x^{(2)}, \u0026hellip;, x^{(n_m)}$\n  Guess $\\theta \\rarr x \\rarr \\theta \\rarr x \\rarr \\theta \\rarr x \\rarr \u0026hellip;$\n  Collaborative Filtering Algorithm   Collaborative flitering optimization objective\n  Given $x^{(1)}, x^{(2)}, \u0026hellip;, x^{(n_m)}$, estimate $\\theta^{(1)}, \\theta^{(2)}, \u0026hellip;, \\theta^{(n_u)}$\n$min_{\\theta^{(1)}, \\theta^{(2)}, \u0026hellip;, \\theta^{(n_u)}}\\frac{1}{2}\\sum_{j = 1}^{n_u}\\sum_{i:r(i, j) = 1}((\\theta^{(j)})^T(x^{(i)} - y^{(i, j)})^2 + \\frac{\\lambda}{2}\\sum_{j = 1}^{n_u}\\sum_{k = 1}^{n}(\\theta_k^{(j)})^2$\n  Given $\\theta^{(1)}, \\theta^{(2)}, \u0026hellip;, \\theta^{(n_u)}$, estimate $x^{(1)}, x^{(2)}, \u0026hellip;, x^{(n_m)}$\n$min_{x^{(1)}, x^{(2)}, \u0026hellip;, x^{(n_m)}}\\frac{1}{2}\\sum_{i = 1}^{n_m}\\sum_{i:r(i, j) = 1}((\\theta^{(j)})^T(x^{(i)} - y^{(i, j)})^2 + \\frac{\\lambda}{2}\\sum_{i = 1}^{n_m}\\sum_{k = 1}^{n}(x_k^{(i)})^2$\n  $min_{(x^{(1)}, x^{(2)}, \u0026hellip;, x^{(n_m)}, \\theta^{(1)}, \\theta^{(2)}, \u0026hellip;, \\theta^{(n_u)})}\\frac{1}{2}\\sum_{(i, j):r(i, j) = 1}((\\theta^{(j)})^T(x^{(i)} - y^{(i, j)})^2 + \\frac{\\lambda}{2}\\sum_{i = 1}^{n_m}\\sum_{k = 1}^{n}(x_k^{(i)})^2 + \\frac{\\lambda}{2}\\sum_{j = 1}^{n_u}\\sum_{k = 1}^{n}(\\theta_k^{(j)})^2$\n    Collaborative flitering Algorithm\n    Initialize $x^{(1)}, x^{(2)}, \u0026hellip;, x^{(n_m)}, \\theta^{(1)}, \\theta^{(2)}, \u0026hellip;, \\theta^{(n_u)}$ to small random values\n  Minimize $J(x^{(1)}, x^{(2)}, \u0026hellip;, x^{(n_m)}, \\theta^{(1)}, \\theta^{(2)}, \u0026hellip;, \\theta^{(n_u)})$ using gradient descent ( or advanced optimization algorithm ). E.g. For every $j = 1, \u0026hellip;, n_u, i = 1, \u0026hellip;. n_m:$\n$x_k^{(i)} \\coloneqq x_k^{(i)} - \\alpha(\\sum_{j:r(i, j) = 1}((\\theta^{(j)})^T(x^{(i)} - y^{(i, j)}))\\theta_k^{(j)} + \\lambda x_k^{(i)})$\n$\\theta_k^{(j)}\\coloneqq\\theta_k^{(j)} - \\alpha(\\sum_{i:r(i, j) = 1}((\\theta^{(j)})^T(x^{(i)} - y^{(i, j)}))\\theta_k^{(j)} + \\lambda \\theta_k^{(j)})$\n  For a user with parameters $\\theta$ and a movie with (learned) features $x$, predict a star rating $\\theta^Tx$.\n  Vectorization: Low rank matrix factorization    Movie Alice(1) Bob(2) Carol(3) Dave(4)     Love at last 5 5 0 0   Romance forever 5 ? ? 0   Cute Puppies of love ? 4 0 ?   Nonstop car cashes 0 0 5 4   Swords vs. karate 0 0 5 ?    $Y = \\begin{bmatrix}5\u0026amp;5\u0026amp;0\u0026amp;0\u0026amp;?\\\\5\u0026amp;?\u0026amp;?\u0026amp;0\u0026amp;?\\\\?\u0026amp;4\u0026amp;0\u0026amp;?\u0026amp;?\\\\0\u0026amp;0\u0026amp;5\u0026amp;4\u0026amp;?\\\\0\u0026amp;0\u0026amp;5\u0026amp;0\u0026amp;?\\end{bmatrix}$\nPredicted ratings ($X\\Theta^T, (i, j) = (\\theta^{(j)})^T(x^{(i)})$):\n$\\begin{bmatrix}(\\theta^{(1)})^T(x^{(1)})\u0026amp;(\\theta^{(2)})^T(x^{(1)})\u0026amp;\u0026hellip;\u0026amp;(\\theta^{(n_u)})^T(x^{(1)})\\\\(\\theta^{(1)})^T(x^{(2)})\u0026amp;(\\theta^{(2)})^T(x^{(2)})\u0026amp;\u0026hellip;\u0026amp;(\\theta^{(n_u)})^T(x^{(2)})\\\\\u0026hellip;\u0026amp;\u0026hellip;\u0026amp;\u0026hellip;\u0026amp;\u0026hellip;\u0026amp;\\\\(\\theta^{(1)})^T(x^{(n_m)})\u0026amp;(\\theta^{(2)})^T(x^{(n_m)})\u0026amp;\u0026hellip;\u0026amp;(\\theta^{(n_u)})^T(x^{(n_m)})\\end{bmatrix}$\n$X = \\begin{bmatrix}-\u0026amp;(x^{(1)})^T\u0026amp;-\\\\-\u0026amp;(x^{(2)})^T\u0026amp;-\\\\\u0026hellip;\u0026amp;\u0026hellip;\u0026amp;\u0026hellip;\\\\-\u0026amp;(x^{(n_m)})^T\u0026amp;-\\\\\\end{bmatrix}$ $\\Theta = \\begin{bmatrix}-\u0026amp;(\\theta^{(1)})^T\u0026amp;-\\\\-\u0026amp;(\\theta^{(2)})^T\u0026amp;-\\\\\u0026hellip;\u0026amp;\u0026hellip;\u0026amp;\u0026hellip;\\\\-\u0026amp;(\\theta^{(n_m)})^T\u0026amp;-\\\\\\end{bmatrix}$\n  Finding related movies\nFor each product $i$, we learn a feature vector $x^{(i)}\\isin \\R^n$.\nHow to find movies $j$ related to movie $i$?\nFind movies with the smallest $||x^{(i)} - x^{(j)}||$\n  Mean Normalization    Movie Alice(1) Bob(2) Carol(3) Dave(4) Eve(5)     Love at last 5 5 0 0 ?   Romance forever 5 ? ? 0 ?   Cute Puppies of love ? 4 0 ? ?   Nonstop car cashes 0 0 5 4 ?   Swords vs. karate 0 0 5 ? ?    $Y = \\begin{bmatrix}5\u0026amp;5\u0026amp;0\u0026amp;0\u0026amp;?\\\\5\u0026amp;?\u0026amp;?\u0026amp;0\u0026amp;?\\\\?\u0026amp;4\u0026amp;0\u0026amp;?\u0026amp;?\\\\0\u0026amp;0\u0026amp;5\u0026amp;4\u0026amp;?\\\\0\u0026amp;0\u0026amp;5\u0026amp;0\u0026amp;?\\end{bmatrix}$ $\\mu = \\begin{bmatrix}2.5\\\\2.5\\\\2\\\\2.25\\\\1.25\\end{bmatrix}\\rarr Y = \\begin{bmatrix}2.5\u0026amp;2.5\u0026amp;-2.5\u0026amp;-2.5\u0026amp;?\\\\2.5\u0026amp;?\u0026amp;?\u0026amp;-2.5\u0026amp;?\\\\?\u0026amp;2\u0026amp;-2\u0026amp;?\u0026amp;?\\\\-2.25\u0026amp;-2.25\u0026amp;2.75\u0026amp;1.75\u0026amp;?\\\\-1.25\u0026amp;-1.25\u0026amp;3.75\u0026amp;-1.25\u0026amp;?\\end{bmatrix}$\n$min_{(x^{(1)}, x^{(2)}, \u0026hellip;, x^{(n_m)}, \\theta^{(1)}, \\theta^{(2)}, \u0026hellip;, \\theta^{(n_u)})}\\frac{1}{2}\\sum_{(i, j):r(i, j) = 1}((\\theta^{(j)})^T(x^{(i)} - y^{(i, j)})^2 + \\frac{\\lambda}{2}\\sum_{i = 1}^{n_m}\\sum_{k = 1}^{n}(x_k^{(i)})^2 + \\frac{\\lambda}{2}\\sum_{j = 1}^{n_u}\\sum_{k = 1}^{n}(\\theta_k^{(j)})^2$\nFor user j, on movie i predict:\n$\\rarr (\\theta^{(j)})^T(x^{(i)}) + \\mu_i$\nUser Eve:\n$\\theta^{(5)} = \\begin{bmatrix}0\\\\0\\end{bmatrix}\\rarr (\\theta^{(5)})^T(x^{(i)}) + \\mu_i$\nLearning with large datasets Stochastic gradient descent   $Cost(\\theta, (x^{(i)}, y^{(i)}) = \\frac{1}{2}(h_\\theta(x^{(i)}) - y^{(i)})^2$\n$J_{train}(\\theta) = \\frac{1}{m}\\sum_{i = 1}^mcost(\\theta, (x^{(i)}, y^{(i)})$\n  Randomly shuffle training examples, repeat $\\theta_j\\coloneqq\\theta_j - \\alpha(h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}$\n  Mini-batch gradient descent   Batch gradient descent: Use all m examples in each iteration\n  Stochastic gradient descent: Use 1 example in each iteration\n  Mini-batch gradient descent: Use b examples in each iteration\n  Convergence   Batch gradient descent\nPlot $J_{train}(\\theta)$ as a function of the number of iterations of gradient descent.\n  Stochastic gradient descent:\nDuring learning, compute $cost(\\theta, (x^{(i)}, y^{(i)}))$ before updating $\\theta$ using $(x^{(i)}, y^{(i)})$.\nEvery 1000 iterations(say), plot $cost(\\theta, (x^{(i)}, y^{(i)}))$ averaged over the last 1000 examples processed by algorithm.\n  At the End\u0026hellip; Thank you, Andrew Ng!\n","permalink":"https://daijiabin.github.io/machine-learning/","tags":["AI"],"title":"Machine Learning"},{"categories":null,"contents":"About Me Basic Infos   Name: Dai Jiabin\n  Birthday: 30.04.1997\n  Nation: China\n  Contact   Mobile ( Germany ): TURFMU1qSXhOREk1TVRBNENnPT0K\n  E-Mail: YTJWamFHOTFMbVJoYVVCbmJXRnBiQzVqYjIwSwo=\n p.S: run echo \u0026lt;String above\u0026gt; | base 64 -d| base 64 -d to get the Phone Number and the E-Mail Address.    Academic Background   08.2015 - 06.2019\nBachelor in Xidian University, China, majored in Computer Science and Technology\nGPA: 3.6\nGraduate Thesis: Design and Realize the CAPTCHA Recognization System based on Convolutional Neural Networks\n  10.2019 - 07.2020\nLanguage ( German ) Learning in Germany, lectures provided by TUDIAS\n  10.2020 - 04.2023\nMaster in Dresden University of Technology, Germany, majored in Informatik\n  Awarded Status Abilities   Language Field\n  English\n  CET4 576\n  CET6 551\n    German, GER C1.1 - C1.2\n   French\n  Russian\n  Spanish\n  Italian\n  Japanese\n  Icelandic\n    Programm Field\n  Languages I\u0026rsquo;ve learned:\n  Applications \u0026amp; Enviroments:\n  Certificates on Coursera:\n  Programm written by myself    Social Field\n  Other Field ( Doesn\u0026rsquo;t achieve yet )\n  ACCA\n  CTCSOL\n    ","permalink":"https://daijiabin.github.io/about/","tags":null,"title":"About"},{"categories":null,"contents":"Lecture 1 What is NodeJS?   Node.js is a JavaScript runtime built on Chrome\u0026rsquo;s V8\n  Node.js uses an event-driven, non-blocking I/O model\n  Blocking: When I/O processing, process waits until I/O finishes.\n  Non-blocking: When I/o processing, process doesn\u0026rsquo;t wait.\n  Event-driven: i.g., Click event.\n    Advantages of NodeJS  Deals well with High Concurrency and I/O intensiv  CPU Intensiv vs. I/O Intensiv   CPU Intensiv: compress, decompress, encrpt, descrypt\n  I/O Intensiv: Operations on File, Network and Database, which are offen used by Web ( Reading Static Resources, Operate Database, Render).\n  How to deal with High Concurrency   Increase Servers\n  Increase the numbers of CPU-Cores\n  And\u0026hellip; NodeJS deals well with high Concurrency and I/O intensiv.\n  NodeJS working Model Lecture 2 CommonJS, global and process   CommonJS:\n  Each file is a module, and has its own field.\n  Inner the module, the parameter \u0026ldquo;module\u0026rdquo; represents module itself.\n  Module.exports represents the API of module.\nmodules.exports.\u0026lt;Variable/Function\u0026gt; = \u0026lt;Rename\u0026gt;\n    Rules of require()\n  support extensions of js, json and node.\n  Without path build-in Module or other third modules in node_modules will be used.\n    Characters of require()\n  In the 1st load module will be executed, and then stores in cache.\n  When a module loaded repeatly, output the executed part only, instead of the unexecuted part.\n  1 2 3 4 5 6  module.exports.test = \u0026#39;A\u0026#39;; const modB = require(\u0026#39;./05_modB\u0026#39;); console.log(\u0026#39;modA: \u0026#39;, modB.test); module.exports.test = \u0026#39;AA\u0026#39;;   1 2 3 4 5 6  module.exports.test = \u0026#39;B\u0026#39;; const modA = require(\u0026#39;./05_modA\u0026#39;); console.log(\u0026#39;modB: \u0026#39;, modA.test); module.exports.test = \u0026#39;BB\u0026#39;;     ","permalink":"https://daijiabin.github.io/nodejs/","tags":["NodeJS"],"title":"NodeJS"},{"categories":["Language"],"contents":"德福考试论据汇总——写作 Aber jede Medaille hat auch Kehrseite.\n一、在德大学生应选择何种工作(大学生兼职)   Pro:\n  通过一份与专业相关的兼职学生可以积累职业经验，以此他们可以在以后的职场上更好地维持。\nDurch einen fachbezogenen Job können die Studenten Berufserfahrungen sammeln, mit denen sie sich später auf dem Arbeitsmarkt besser behaupten können.\n  在做与专业相关的兼职工作的同时人不仅可以获得(erzielen)更好的收入(Gehalt)，也积累很多必将(sicherlich)使他在职场上的职业前景更加美好的经验。\nBei einem fachbezogenen Job erzielt man nicht nur ein besseres Gehalt, sondern man sammelt viele Erfahrungen, die sicherlich seine Berufsaussicht auf dem Arbeitsmarkt verbessert.\n  学业一直是学生的核心工作(im Mittelpunkt stehen)。在兼职工作中，他们也应该一直思考：他们应该如何将所学的东西(Gelernte)在实习中得以转化——这仅实现在专业相关的工作。\nDas Studium steht immer im Mittelpunkt für die Studenten. Auch beim Nebenjob sollen sie ständig daran denken, wie sie das Gelernte in der Praxis umsetzen sollen. Und dies erfolgt nur bei einem fachbezogenen Job.\n  专业相关的工作也是学业与实习的连接。许多在学习过程中获得的知识，将会在专业相关的工作中得以应用。而且专业知识也将会通过在这类工作中所积累的经验而得以补充(ergänzen)。\nEin fachbezogner Job ist auch eine Verbindung zwischen der Praxis und dem Studium. Vieles, was man sich während des Studiums erworben hat, wird in einem fachbezogenen Job angewandt. Und die Fachkenntnisse werden durch gesammelte Erfahrungen bei solchen Jobs ergänzt.\n    Übergang:\n  做兼职工作的意图或多或少都折射(widerspiegeln)了资产独立的意愿。但此外(hinaus)他们应该思考全局(Tellerrand)。\nDie Absicht, einen Ferienjob zu machen, spiegelt mehr oder weniger den Wunsch nach finanzieller Unabhängigkeit wider. Aber Sie sollen über den Tellerrand hinaus denken.\n    Kontra:\n  尽管一份简单的工作很容易获得且执行，但是人为此必须花费(aufwenden)许多时间。因此它并不值得(sich lohnen)。\nEin einfacher Job ist zwar leicht zu bekommen und durchzuführen, aber dafür muss man viel Zeit aufwenden. Deswegen lohnt es sich gar nicht.\n    二、SMS(现代媒体作用)   Pro:\n  SMS使得人与人之间的交流变得简单。人们可以随时随地与其他人交换(austauschen)信息。实际在会议(Sitzung)上人们不允许打电话，否则的话(Sonst)会议一定会被打断。通过SMS的帮助人可以在不打扰其他人的情况下获得重要的消息。\nSMS erleichtert die Kommunikation zwischen den Menschen. Man kann jeder Zeit und überall Informationen mit anderen austauschen. In Sitzungen darf man eigentlich nicht telefonieren. Sonst werden die Sitzungen ständig gestört. Mit Hilfe von SMS bekommt man wichtige Informationen, ohne Andere zu stören.\n  人可以通过SMS得到细节的路径描述。当人在一个陌生的地方寻找特定的地址时，需要一份详尽的(ausführlich)路程描述。 但在路途中(unterwegs)人不可以写东西。在SMS的帮助下一切都将会展现在显示屏上，以此人可以轻松的找到方向。\nMan bekommt per SMS eine detaillierte Wegbeschreibung. Wenn man an einem fremden Ort bestimmite Adresse sucht, benötigt man eine ausführliche Wegbeschreibung. Aber unterwegs kann man nichts aufschreiben. Mit Hilfe von SMS wird alles auf dem Display dargestellt, so dass man sich leicht orientieren kann.\n  SMS也有聊天的作用。伴着重要的信息人们也会发送一些笑话或简短的历史。当一个人孤身一人感到无聊的时候，他就可以阅读之前存储的有趣的SMS并转发(weiterleiten)。以此越来越多的人在日常生活中感受欢乐。正是这些社会性的功能对SMS的使用及扩散尤为重要。\nSMS hat eine Unterhaltungsfunktion. Neben wichtigen Informationen verschicken Menschen auch Witze oder kurze Geschichte. Wenn man allein ist und sich langweilig fühlt, kann man die vorher gespeicherten interessanten SMS lesen und weiterleiten. Dabei erleben immer mehr Menschen Freude im Alltag. Genau diese soziale Funktion ist besonders wichtig für die Nutzung und Verbreitung von SMS.\n  这种新的交流对绩效的提高有所贡献。在SMS中句子将写(verfassen)为更为短小的形式。这有一个优点，人可以快速地获得(vermitteln)观点或从他人得到观点。阅读时间将会显著缩短。在如今快速的(schnellebig)时代人有许多需要阅读的东西，并因此没有内在损失(Verlust)的短句十分的重要。\nDie neue Kommunikation trägt zur Leistungserhöhung bei. In SMS werden die Sätze in kurzer Form verfasst. Dies hat einen Vorteil, dass man ganz schnell die Meinungen vermittelt oder die Meinungen von anderen bekommt. Die Lesezeit wird wesentlich verkürzt. In dem heutigen schnellebigen Zeitalter hat man viel zu lesen und deshalb sind kurze Sätze ohne inhaltlichen Verlust ganz wichtig.\n    Kontra:\n  尽管有这种可能性：青少年在SMS过度使用的过程中遇到成瘾(Süchtigkeit)的问题，但这仅发生在当父母和学校完全不管控青少年为SMS所使用(verwenden)的时间的情况下。\nEs besteht zwar die Möglichkeit, dass die Jugendlichen bei der exzessiven Nutzung von SMS in Süchtigkeit geraten. Aber dies passiert nur dann, wenn die Eltern und die Schule die Zeit, die die Jugendlichen für SMS verwenden, überhaupt nicht kontrollieren.\n  人只需要注意年轻人不应该过久地玩弄手机，因为这事关健康的眼睛。\nMan braucht nur darauf zu achten, dass junge Menschen nicht zu lange mit dem Handy beschäftigt sein sollen. Denn es geht um die gesunden Augen.\n  在SMS中的表达并非一直是语法正确的。\nIm SMS gibt es nicht immer richtige Ausdrücke.\n    三、电子游戏与儿童教育(现代媒体对青少年的影响)   Pro:\n  在管控下青年人可以节省花费在电脑游戏上的时间。\nDie Jugendlichen können durch die Kontrolle über Computerspiele Zeit sparen.\n  管控将在儿童和青少年地成长过程中发挥积极的作用——他们可以获得正确的方向。他们主要的任务是通过学习持续深造并为出色的未来做准备。没有管控许多青少年将会陷入上瘾以及依赖性。\nDie Kontrolle auswirkt sich possitiv auf die Entwicklung der Kinder und Jugendlichen. Sie können richtige Orientierung bekommen. Ihre Hauptaufgabe besteht darin, dass sie sich durchs Lernen immer weiter qualifizieren und sich auf blendende Zukunft vorbereiten. Ohne Kontrolle werden viele junge Menschen in Sucht und Abhängigkeit verfallen.\n  管控使儿童和青少年地良好习惯成为可能。他们应该在日常生活中设计一个正确的计划，以充实生活。他们应该明白，他们的生活不仅仅只由电脑和互联网组成。\nDie Kontrolle kann den Kindern und Jugendlichen gute Gewohnheit ermöglichen. Sie sollen im Alltag einen richtigen Plan schmieden, um das Leben zu bereichern. Sie sollten wissen, dass ihr Leben nicht nur aus Computer und Internet besteht.\n  这与健康有关。一方面管控对青少年的物理健康的改良有所贡献。当人在电脑面前坐太久，不仅仅是眼睛，脊椎也会被损伤。年轻人应该按时睡觉，而不是忙于电脑游戏或聊天直到深夜。另一方面管控也关照青年人的心理健康。因为儿童和青少年可以在有害信息前被保护。许多关于暴力、犯罪、诈骗和性将会损伤年轻人的心理健康。\nEs geht um Gesundheit. Zum einen trägt die Kontrolle zur Verbesserung physiologischer Gesundheit der Jugendlichen bei. Wenn man zu lange vor dem Computer sitzt, werden nicht nur Augen, sondern auch Wirbelsäulen geschädigt. Die jungen Leute sollen pünktlich ins Bett gehen, statt Computerspiele oder Chat bis in die Nacht zu treiben. Zum anderen sorgt die Kontrolle auch die psychische Gesundheit der Jugendlichen. Denn die Kinder und Jugendlichen können vor schädlichen Informationen geschützt werden. Viele Informationen über Gewalt, Kriminalität, Betrüge und Sex werden die psychische Gesundheit der jungen Leute beeinträchtigen.\n    Kontra:\n  短时期内青少年得到多面且丰富的信息会被阻碍。\nKurzfristig können die Jugendlichen verhindert werden, an vielfältige und reichliche Informationen zu kommen.\n  儿童和青少年失去了自我控制的机会。独自一人的时候自律不会自己出现。当学校和父母给学生和儿童展示互联网上的何种内容是对儿童、青少年合适的以及如何计划他们的时间，这再好不过了。\nKinder und Jugendlichen verlieren die Chance, sich selbst zu kontrollieren. Die Selbstdisziplin kommt nicht automatisch von allein. Es wäre besser, wenn Schulen und Eltern den Schülern und den Kindern zeigen, welche Inhalte im Internet für Kinder und Jugendliche geeignet sind und wie sie ihre Zeit planen können.\n  当儿童们仅仅使用传统的媒体学习是很无聊的。因为知识在互联网上会连续的更新。除此之外互联网上的知识比在书上更加直观。许多电脑游戏也须要战略以及对游戏的思考。由此年轻人将自己明白，有意义地使用电脑和互联网。\nEs ist langweilig für Kinder, wenn sie nur mit traditionallen Medien lernen. Denn das Wissen im Internet wird ständig aktualisiert. Außerdem ist das Wissen im Internet viel anschaulicher als das in Büchern. Auch viele Computerspiele verlangen die Strategie und das Nachdenken von den Spielen. Drüber hinaus werden junge Menschen selbst darauf kommen, Computer und Internet sinnvoll zu nutzen.\n  对生活在信息时代的人来说现代媒体的使用是最重要的能力之一。如今不擅长使用电脑和互联网的人在学业以及求职过程中注定有着不小的困难。\nDer Umgang mit modernen Medien ist eine der wichtigsten Kompetenze für die Menschen im Informationszeitalter. Wer heutzutage ungeschickt mit Computer und Internet umgeht, hat bestimmt große schwierigkeit beim Studium und bei der Suche nach einer Arbeit.\n    四、家庭办公(现代工作方式，人与人之间的联系， 现代媒体的应用)   Pro:\n  人必须明白，鉴于强烈的交通密度人不得不在去工作的路上牺牲更多的时间，当所有人每天同时开车前去工作的时候。交通堵塞所浪费的时间，至少是人在家里为一通不情愿的电话所花费时间的三倍。更不用说，开车前往工作需要许多的汽油并因此会污染空气。\nMan muss einsehen, dass angesichts der starken Verkehrsdichte man auf dem Weg zur Arbeit mehr Zeit zu widmen hat, wenn alle Menschen jeden Tag gleichzeitig zur Arbeit fahren. Die Zeit, die der Stau kostet, ist mindestens dreifach wie die Zeit, die man für ein unerwünschtes Telefonat zu Hause braucht. Ganz zu schweigen davon ist, dass die Fahrt zur Arbeit sehr viel Benzin verbraucht und damit auch die Luft verschmutzt.\n  现代交通技术使得许多办公室的工作在家里完成成为可能。在这个意义上办公室和家没有太大的区别。\nMit der modernen Kommunikationstechnik ist es jetzt möglich, viele Büroarbeiten zu Hause zu erledigen. In diesem Sinne gibt es keinen großen Unterschied zwischen Büro und zu Hause.\n  公司以及职员都可以从居家办公中获益。因为更长的工作时间企业必须为他们的职员支付附加费，这对企业来讲无疑是一份附加的负担。\nSowohl die Unternehmen als auch die Angestellten können von der Heimarbeit profitieren. Wegen der längeren Arbeitszeit müssen die Unternehmen einen Zuschlag für ihre Mitarbeiter zahlen, der sicherlich eine zusätzliche finanzielle Belastung für die Unternehmen ist.\n  当人在家里工作时拥有灵活的工作时间。因为人可以根据自己的意愿组织他工作的时间。优点是，人可以做一些日常活动并更多地关照他的家庭。\nMan hat flexible Arbeitszeit, wenn man zu Hause arbeitet. Denn man kann die Zeit für seine Arbeit nach eigenem Wunsch organisieren. Der Vorteil ist, dass man seine eigenen Tätigkeiten machen und sich mehr um seine Familie kümmern kann.\n  人在家里可以高效地工作。人可以在早上稍微赖床一会，之后在写字桌前注意力完全集中地工作。\nMan kann zu Hause effizient arbeiten. Man kann morgens ein bisschen länger schlafen und dann ganz konzentriert am Schreibtisch arbeiten.\n  当人在家里工作时人可以拥有更多自由的时间。人不需要每早早早起床并匆忙地驾驶汽车或搭乘公交去办公室工作。\nMan kann mehr Freizeit haben, wenn man zu Hause arbeitet. Man braucht nicht jeden Morgen früh aufzustehen und ganz eilig mit Pkw oder Bus ins Büro zu fahren.\n    Kontra:\n  家中有许多消遣，因此人经常不能集中精力工作并因此浪费许多时间。\nEs gibt viele Ablenkungen zu Hause, so dass man sich oft nicht auf die Arbeit konzentrieren kann und damit viel Zeit verloren geht.\n  当许多工作者在家中工作时，效率会降低。如今在许多领域团队合作是必要的。在做许多重要的决定之前建议或者草稿必须被彻底讨论。这仅在办公室里奏效。当人不在办公室里他的职位上时，那么这将十分重要，呼叫所有的员工来一起研讨。人必须长时间的等待，直到某些人从家里来到办公室。\nWenn viele Erwerbstätige zu Hause arbeiten, sinken die Effizienzen. Heutzutage ist die Teamarbeit in vielen Bereichen notwendig. Vor vielen wichtigen Entscheidungen müssen Vorschläge oder Entwürfe ausdiskutiert werden. Das erfolgt nur im Büro. Wenn man nicht im Büro an seinem Arbeitsplatz ist, dann ist es sehr wichtig, alle Mitarbeiter zur Besprechung zusammenzurufen. Man muss lange warten, bis jemand von zu Hause ins Büro kommt.\n  当人在家里工作时，不可能每时每刻与同时交流。企业将由此受影响。因为合作以及团队精神对企业的成功来讲是第一线。当人已经习惯居家工作时，人不会喜欢同其他人一起工作。更糟糕的是，人会慢慢的从外部世界独立并可能因此罹患抑郁。\nEs ist nicht mehr möglich, jederzeit mit Kollegen zu kommunizieren, wenn man zu Hause arbeitet. Davon wird vor allem das Unternehmen betroffen. Denn für Erfolg eines Unternehmens zählen in erster Linie die Zusammenarbeit und der Teamgeist. Wenn man schon an die Heimarbeit gewöhnt ist, arbeitet man nicht mehr gerne mit anderen Menschen zusammen. Noch schlimmer ist, dass man langsam von der Außenwelt isoliert ist und damit sehr wahrscheinlich an Depression leiden kann.\n  当更多公共服务的职员在家工作时，人会有更多的问题和困难。让人生气的是，当一些公共职位一直处于未被占据的状态。因此许多人的时间将被挥霍，因为公共服务技术人员的缺失而必须经常等待一整个上午。\nMan hat mehr Probleme und Schwierigkeiten, wenn mehr Angestellte im öffentlichen Dienst zu Hause arbeiten. Es ist doch ärgerlich, wenn einige öffentlichen Stellen immer unbesetzt sind. So wird die Zeit vieler Menschen verschwendet, die wegen des Mangels an Sacharberitern im öffentlichen Dienst oft ganzen Vormittag warten müssen.\n    五、联网电视机在德国(现代媒体-人机互动、人际关系是否重要)   Pro:\n  长远来看这样的设备对儿童和青少年有着积极的影响。使用现代仪器人可以与其他人不受时间限制地交换意见。借此人节省许多时间和精力。最首要的是当儿童和青少年在电视放送节目中找到有趣的话题时，他们可以直接同朋友们讨论它。他们再也无需打开一台电脑。\nSolche Geräte haben auf lange Sicht positive Auswirkung auf Kinder und Jugendliche. Bei der Benutzung des modernen Gerätes kann man Meinungen ohne Zeitverzögerung mit anderen austauschen. Daher spart man viel Zeit und Energie. Vor allem wenn Kinder und Jugendliche interessantes Thema in der Fernsehen-Sendung finden, können sich direkt mit Freunden darüber diskutieren. Sie brauchen nicht mehr zusätzlich einen Computer einzuschalten.\n  这项技术发明对工作市场上境况的改善有所贡献。因为人们在看电视的同时也可以访问互联网，网上购物便成为了可能。借此许多工作岗位会被创造。\nZudem hat diese technische Erfindung zur Verbesserung der Situation auf dem Arbeitsmarkt beigetragen. Da Menschen beim Fernsehen gleichzeitig einen Internetzugang haben, ist das Online-Geschäft möglich. Dabei werden viele Arbeitsplätze geschafft.\n  除此之外这个新的设备提供给了青少年这样的可能性：建立他们对民主政治(Demokratie)的意识。过去的数年他们在电脑上花费了如此多的时间，他们几乎对电视新闻没有兴趣。凭借(Anhand)这项设备青少年可以在电视中跟踪(verfolgen)政治事件(Ereignisse)，并在此表达他们的观点，并积极参与电视中的一些民意调查。\nAußerdem bietet dieses neue Gerät den Jugendlichen die Möglichkeit, ihr Bewusstsein von Demokratie zu bilden. In den letzten Jahren wenden sie so viel Zeit für Computer auf, dass sie sich kaum für die Fernsehennachricht interessiert haben. Anhand des Hybrid-TV-Gerätes können die Jugendlichen politische Ereignisse im Fernsehen verfolgen und dabei ihre Meinungen äußern und an einigen Umfragen im Fernsehen aktiv teilnehmen.\n    Kontra:\n  对青少年来讲告别这类设备间或会越来越困难。\nEs manchmal wird für Jugendliche immer schwieriger, sich von den Hybrid-TV-Geräten zu verabschieden.\n  尽管这类电视设备或多或少使得聊天变得轻松，但这并不意味着，没有互联网人便不能同他人交流。由此看来(Von daher)这项技术并不是不可或缺的。\nObwohl diese TV-Gerät mehr oder weniger das Chatten erleichert, aber das bedeutet nicht, dass man sich mit anderen ohne Internet nicht unterhalten kann. Von daher ist diese Technik nicht unentbehrlich.\n  这类设备会损伤青少年的健康。过度使用电视和互联网会损伤眼睛。\nSolches Gerät schädet der Gesundheit der Jugendlichen. Die exzessive Fernseh- und Internetnutzung gefährdet die Augen.\n  同他人的交际中交往能力会衰退(nachlassen)。在交流过程中手势和面部表情扮演着重要的角色。人在看电视和线上聊天不需要这些重要的元素。这些缺失的联系有如下后果，人在真实的(richtigen)交流中对其他人的手势、表情不能立刻作出反应。\nDie Kommunikationsfähigkeit lässt im Umgang mit anderen Menschen in der realen Welt nach. Bei der Kommunikation spielen Geste und Mimik auch eine wichtige Rolle. Diese wichtigen Elemente braucht man beim Fernsehen und Chatten nicht. Diese fehlende Übung hat die Folge, dass man beim richtigen Gespräch nicht mehr sofort auf Geste und Mimik der anderen Menschen reagieren kann.\n  互联网电视的消费造成了对电视、互联网的依赖，进而造成了青少年学校成绩的变差。长此以往的后果是，他们的职业前景被儿戏所替代。\nDer Konsum vom internetfähigen TV-Gerät verursacht die Abhängigkeit vom Fernsehen und Internet und damit auch die Verschlechterung der Schulleistungen von den Jugendlichen. Die langfristige Folge davon ist, dass ihre berufliche Aussicht dadurch aufs Spiel gesetzt wird.\n    六、学业，职业和家庭(家庭与事业话题，尤其针对妇女) 此处两个观点为女性应选择文科(更好地照顾家庭)还是理科(更好的社会地位)\n  Für Naturwissenschaft:\n  对女性自然科学家来说在毕业之后找到一份高薪水的工作并不困难。对许多家庭来说一个稳定的资金来源是儿童抚养的最重要的因素。\nEs fällt den Naturwissenschaftlerinnen nicht schwer, eine gut bezahlte Arbeit nach ihrem Studienabschluss zu finden. Für viele Familien ist eine sichere finanzielle Quelle der Schlüsselfaktor für die Kindererwartung.\n  在现代社会中男性已参与进家庭工作。他们也以他们事业有成的妻子而自豪。\nMänner in moderner Gesellschat sind bereit, die Hausarbeit mitzumachen. Sie sind auch stolz auf ihre beruflich erfolgreiche Frau.\n  加班感觉不一定是令人厌烦的，只要这份工作给女性带来愉悦。\nDie Überstunden sind nicht unbedingt als lästig empfunden, sobald die Arbeit den Frauen Spaß macht.\n  ( Die Argumentation, dass dioe Frauen mit einem Studienabsclhluss in Geisteswissenschaften eine leichte Arbeit bekommen und sich mehr um Familie und Kinder kümmern können, ist nicht überzeugend.)\n    Für Geisteswissenschaft\n  女性在自然科学、工学学业结束后可能可以得到一份高薪职业并以此改善资金条件。但这样的工作往往与许多缺陷捆绑在一起。她们中的不少人必须加班并且工作对女性来讲太过劳累(stressig)。\nVielleicht können die Frauen nach dem Studium in Natur- und Ingeniurwissenschaft eine gut bezahlte Arbeit bekommen und damit die finanzielle Lage verbessern. Aber soclche Arbeit ist oft mit vielen Nachteilen verbunden. Nicht selten müssen sie Überstunden machen und die Arbeit ist für die Frauen sehr stressig.\n  女性人文科学家工作在愉悦的氛围中并且工作带来他们愉悦。女性可以在出版社(Verlag)或编辑室(Redaktion)安静地工作，并不需要在机器旁边转悠或不停地出差。\nDie Geisteswissenschafterinnen arbeiten in der angenehmen Atmosphäre und die Arbeit macht ihnen Spaß. Im Verlag oder in der Redaktion können die Frauen in Ruhe arbeiten und brauchen nicht, an die Maschinen zu gehen oder ständig Diensreise zu machen.\n  女性在出版社或编辑部可以经常与不同的作家就有趣地主题交流。所有这些工作都给女性带来了欢乐。当女性有育儿计划时，这尤为重要。\nFrauen können im Verlag oder Redaktion oft mit verschiedenen Autoren kommunizieren, über interessante Themen sprechen. All diese Arbeiten bringen den Frauen Freude. Dies ist besonders wichtig, wenn die Frauen einen Kinderplan haben.\n  许多女性想要自由时间，因为他们可以在他们的自由时间里教育孩子，同孩子玩耍、和孩子一同做(unternehmen)其他的事情。对大多数女性来讲与孩子在一起时的愉悦不能与金钱或事业相提并论。\nViele Frauen wollen Freizeit haben, denn sie können in ihrer Freizeit Kinder erziehen, mit Kindern spielen und etwas mit ihren Kindern gemeinsam unternehmen. Für die meisten Frauen kann die Freude mit Kindern nicht mit Geld oder beruflicher Karriere gleichgesetzt werden.\n    七、漂亮的包装？(环保话题，对环境和生态的影响)   Pro:\n  带有包装的生活用品很容易被带走和存储。这些优点对这些人尤为重要：忙于工作并因此一次性购买大量的生活用品。对企业来讲包装也是成功的钥匙。因为企业使用创新的、漂亮的包装，顾客的购买决定可以被建议并且企业可以由此获得高额的利润。\nDas Lebensmittel mit Verpackung ist leicht zu tragen und lagern.Diesen Vorteil sehen besonders die Menschen, die mit der Arbeit beschäftigt sind und deswegen Lebensmittel oft einmal in großer Menge kaufen. Auch für die Unternehmen sind die Verpackung der Schlüssel zum Erfolg. Weil Unternehmen kreative und schöne Verpackung benutzen, kann die Kaufentscheidung der Kunden suggeriert werden und die Unternehmen können dadurch hohen Gewinn erzielen.\n  漂亮的包装可以(in der Lage sein)，提高物品的吸引力（Anziehungskraft）并借此促成消费。\nDie schöne Verpackung ist in der Lage, die Anziehungskraft der Ware zu erhöhen und daher den Konsum zu fördern.\n    Kontra:\n  过度的（übertrieben）包装生产对环境十分有害(umweltschädlich)， 因为大多数包装是纸质的。也就是说，为了得到（gewinnen）生产包装的原材料（Rohstoff），大量的(zahlreiche)树木将被砍伐，这完全不利于可持续发展（nachhaltige Entwicklung）\nDie übertriebene Herstellung der Verpackung ist sehr umweltschädlich, weil die Verpackung meistens aus Papier ist. Das heißt, dass zahlreiche Bäume gefällt werden, um den Rohstoff für die Herstellung von Verpackungen zu gewinnen, was gar nicht günstig für die nachhaltige Entwicklung ist.\n  包装的生产造成了（erzeugen）许多难以被清理的（K.I. rntsorgen）垃圾，这将种下（säen）地表和水严重的（fatal）祸根（Saat(本意幼苗)）\nDie Produktion der Verpackung erzeugt viele schwer zu entsorgende Abfälle, die die Saat der fatalen Verschmutzung im Boden und Wasser sät.\n  生产商更多的注意在产品的外观而不是质量上。因为按照他们的观点单凭漂亮的包装就可以提升销量（Umsatz）,生产商减少了许多生产成本（Erzeugungskosten）\nDie Hersteller achten mehr auf das Ansehen von Verpackungen statt die Qualität der Produkten. Da die schöne Verpackung ihrer Meinung nach allein den Umsatz erhöhen kann, verringert der Hersteller viele Erzeugungskosten.\n  人必须明白（einsehen），多面的包装影响顾客的购买决定。消费者（Verbraucher）可能因为华丽的（prächtig）包装而购买一个质量低下的产品。\nMan muss doch einsehen, dass die vielfältige Verpackung die Kaufentscheindung der Konsumenten beeinflusst. Die Verbraucher können wegen der prächtigen Verpackung ein Produkt mit niedriger Qualität kaufen.\n  一些包装难以被循环利用（recycle），当他们由塑料生产比如塑料薄膜（Plastikfolie）和塑料袋（Plastiktüte）。当人随意丢弃（herumwerfen）它们时，他们漂浮（schweben）在空中或者躺在地上。这样环境将被污染。一个塑料袋经常被短时间的使用，它们降解（Zum Verrotten）却需要至多500年。人类的健康也会被危及生命的细菌威胁，当生活用品的包装不整洁地（ungereinigt）乱放（herumliegen）\nManche Verpackung sind schwer zu recyceln, wenn sie aus Plastik bestehen wie Plastikfolie und Plastiktüte. Wenn man sie herumwirft, schweben sie dann in der Luft oder liegen auf dem Boden. Dadurch wird die Umwelt verschmutzt. Eine Plastiktüte wird oft nur für kurze Zeit verwendet, zum Verroten braucht sie jedoch bis zu 500 Jahre. Auch menschliche Gesundheit wird durch lebensgefährliche Bakterien gefährdet, wenn die Lebensmittelverpackungen ungereinigt herumliegen.\n  这些包装须要消耗（verbrauchen）运输过程中附加的能量。 当来自全世界越来越多的货物通过飞机或者船运输的时候，巨量的(enorm)燃料(Brennstoffe)将被消耗。\nDiese Verpackungen verbrauchen zusätzliche Energie beim Transport. Wenn immer mehr Waren aus der ganzen Welt mit Flugzuegen oder Schiffen transportiert werden, werden enorme Brennstoffe verbraucht.\n  他也与经济问题有关（Es handelt sich um\u0026hellip;）。消费者将被迫（zwingen）支付更多仅仅因为漂亮的包装而产生的附加的花费。\nEs handelt sich auch um die finanzielle Frage. Die Verbraucher werden gezwungen, mehr für die zusätzliche Kosten zu bezahlen, die allein wegen schöner Verpackung entstehen.\n    八、媒体(传统媒体与现代媒体之间的矛盾与互补)   Pro( Die traditionellen Medien werden durch die modernen Medien ersetzt):\n  人不可以随时随地阅读很多书籍。当人出于旅行或者Vorlesung的需要带着许多书时，是很笨重的（Es fällt vielen schwer）\nMan kann nicht jederzeit und überall viele Bücher lesen. Es fällt vielen schwer, viele Bücher mitzunehmen, wenn man sie auf der Reise oder zur Vorlesung braucht.\n  这有关资源浪费。为了生产纸张，人需要许多的木材（Holz）。这样的后果是，许多森林（Wälder）被摧毁了。当太多的样品被印制的时候，这意味着木材、水、能量资源的极大浪费。森林的砍伐也可以将肥沃的（fruchtbar）地区变为（in A. verwandeln）荒漠（Wüste）\nEs geht um Ressourcenverschwendung. Um Papier herzustellen, braucht man sehr viel Holz. Die Folge davon ist, dass viele Wälder zerstört sind. Wenn zu viele Exemplare gedruckt werden, die dann später wegen geringen Verkaufs vernichtet werden müssen, bedeutet dies eine enorme Verschwendung von Ressourcen von Holz, Wasser und Energie. Auch die Abholzung der Wälder kann die fruchtbare Landschaft in eine Wüste verwandeln.\n  青年人使用新的媒体如电脑可以快速发现多面的、及时的消息，而不是经常阅读书本里早已过时的（veraltete）知识。\nDie jungen Menschen sind mit den neuen Medien wie Computer in der Lage, vielfältige und aktuelle Informationen schnell zu erfahren, statt dass oft schon veraltete Wissen in den Büchern zu lesen.\n  在电脑和因特网上的知识比在书本上的知识更加生动直观(veranschaulich)，这将促进青少年学习。\nDas Wissen im Computer und Internet ist veranschaulicher als in den Büchern, was die Jugendlichen zum Lernen motiviert.\n    Übergang:\n  许多人认为，传统媒体如书籍和报纸是需求资源的（ressourcenintensiv）、这是清楚的，成产纸张的需要木材。但是使用现代科技人可以毫无问题的回收旧的纸张并再用于书籍和报纸的生产（bereitstellen）。相反的电子器件是有毒的（giftig）并因此在销毁（Vernichtung）时须要一个特定的过程。\nViele behaupten, dass die traditionellen Medien wie Bücher und Zeitungen ressourcenintensiv sind. Es ist klar, dass bei der Herstellung von Papier Holz gebraucht wird. Aber mit modernen Technik kann man jetzt das Altpapier problemlos recyceln und wieder zum Druck von Büchern und Zeitungen bereitstellen. Im Gegensatz dazu ist der Elektro-Schrott zum Teil giftig und benötigt deshalb einen besonderen Prozess bei der Vernichtung.\n  当年轻人整日从事电脑工作，尽管这可能对他们眼睛有害，但这可以通过父母的管控而避免发生。\nZwar konnte es schädlich für ihre Augen, wenn sich die jungen Leute den ganzen Tag mit dem Computer beschäftigen, was durch Kontrolle der Eltern aber vermeiden werden kann.\n    Kontra( Die traditionellen Medien werden durch die modernen Medien nicht ersetzt):\n  书籍的优点显而易见：人可以抓握它，翻页（in ihnen blättern），闻嗅并放在书架上（ins Regal stellen）作为教育显著的象征。\nDer Vorteil von Bücher liegt auf der Hand, dass man sie anfassen können, in ihnen blättern, sie riechen und als sichtbare Zeichen von Bildung ins Regal stellen.\n  书籍还有一个优点：人在阅读书籍过程中，尤其是他们的朋友或亲戚已经读过的书，体验特定的（）感觉和情绪，因为人在此过程中自动想起这些人。书籍的这个功能是电子阅读器没有的。\nBücher haben einen weiteren Vorteil, dass man beim Lesen von Büchern, vor allem von den Büchern, die seine Freunde oder Verwandte schon mal gelesen haben, gewisse Gefühle und Emotionen spürt, weil man sich dabei automatisch an diese Personen erinnert. Diese Funktion von Büchern hat ein elektronisches Lesegerät nicht.\n  人可以随处阅读书籍和报纸。人可以在野营地（Camping-Platz）或在公园毫无问题的翻阅书籍、阅读日报上的消息。而电脑必须有（Strom vorhandeln sein）电流。\nMan kann Bücher und Zeitungen überall lesen. Auf dem Camping-Platz oder im Park kann man problemlos in den Bücher blättern und Nachrichten in der Tageszeitung lesen. Für den Computer muss Strom vorhanden sein.\n  这事关眼睛的健康。当人数小时忙于电脑时，首先（zunächst）人感觉到眼部不适（Unbequemlichkeit）。儿童和青少年恰好处于发育时期（Wachstumsphase），此时他们的眼睛还是可塑的。当他们每天阅读屏幕上的文章和消息时，他们的眼睛会被强烈地损害（gefährden）。\nEs geht um die Gesundheit der Augen. Wenn man stundenlang mit dem Computer beschäftigt ist, spürt man zunächst die Unbequemlichkeit der Augen. Kinder und Jugendliche befinden sich gerade in der Wachstumsphase, wobei ihre Augen noch formbar sind. Wenn sie täglich Artikel und Informationen auf dem Bildschirm lesen, werden ihre Augen stark gefährdet.\n  这与内容有关。在互联网上有许多不适合儿童和青少年的东西。因为儿童和青少年还缺乏自我约束（Selbstdisziplin）和判断力（Urteilvermögen），他们在网上冲浪的时候很容易会被欺骗（verführen）\nEs handlet sich um die Inhalte. Im Internet gibt es viele Sachen, die den Kindern und Jugendlichen nicht geeignet sind. Da die Kindern und Jugendlichen noch an Selbstdisziplin und Urteilvermögen fehlt, können sie beim Surfen im Internet leicht verführt werden.\n    九、Pkw和环境(交通工具与环保，可延伸到绿色出行、自行车出行)   Meinungen:\n  首先人应该改变他的生活习惯（Gewohnheit）。当然这不是如此舒服的：当人带着满满的购物袋（Einkaufstüte）乘坐公交或城市轻轨回家时。但是许多优点不应该被忽略。乘坐公共交通工具人为节省能源做出了贡献。一辆公交车满载时（volle Belastung）人均（pro Kopf）将比Pkw消耗更少的汽油。除此之外人可以借此节省时间。许多机车也意味着所有街道上的堵塞。人乘坐诸如地铁的公共交通工具比开自己的Pkw更快的到达目的地（ans Ziel kommen）。不适也可以被避免，人通过在住所附近的小商店购买重要的生活用品或在网上购买（stellen）想要的物品。没有自己的Pkw而使用汽车去上班也可以通过共享汽车（Car-Sharing）来实现。一些同事可以一同驾驶汽车。借此人不仅节省了汽油的花销，也可以在行驶过程（Fahrt）中聊天。借此友谊会被深化（vertiefen）。这有利于（Dies dient dayu, dass\u0026hellip;），人在日常生活和岗位上一直拥有欢乐。\nErstens sollte man seine Gewohnheiten ändern. Natürlich ist es nicht so bequem, wenn man mit vollen Einkaufstüten mit dem Bus oder der Straßenbahn nach Hause fährt. Aber viele Vorteile sollten nicht vernachlässtigt werden. Mit den öffentlichen Verkehrsmitteln trägt man zum Sparen von Energie bei. Bei voller Belastung verbraucht ein Bus viel weniger Benzin pro Kopf als ein Pkw. Außerdem spart man dabei die Zeit. Viele Autos bedeuten auch Stau auf allen Straßen. Oft kommt man mit öffentlichen Verkehrsmitteln wie U-Bahn viel schnell ans Ziel als mit dem eigenen Pkw. Auch die so genannte Unbequemlichkeit lässt sich vermeiden, indem man in kleinen Laden in der Nähe der Wohnung wichtige Lebensmittel kauft oder die gewünschten Sachen im Internet bestellt. Auch die Nutzung eines Autos zur Arbeit kann ohne eigenen Pkw realisiert werden durch Carsharing. Einige Kollegen können zusammen ein Auto fahren. Dabei spart man nicht nur Geld für Benzin, sondern man kann sich während der Fahrt unterhalten. Dadurch wird die Freundschaft vertieft. Dies dient dazu, dass man immer Freude im Alltag und am Arbeitsplatz hat.\n  其次这有关汽车制造业（Automobil-Industrie）里的技术发展。当人要买节省能源的汽车时，汽车工厂将会被促使（zwingen）发展环境友好的发动机。一个典型的例子是氢能源驱动（Hybride-Antrib）。尽管现在这样的汽车是昂贵的，但它属于（zu D. gehören）未来。尤其是当人长距离（Strecke）行驶时，如去度假（auf den Urlaub），人可以节省许多的金钱并向空气排放（in die Luf ausstoßen）更少的CO2。在汽车工厂或想要掌控（behaupten）未来的人，必须现在投资(in A. investieren)这些技术。并且消费者也应该支持（unterstützen）这项发展。当所有这些点子转化为实际（in der Praxis umsetzen）时，环境将一步步地被减轻负担（entlasten）。\nZweitens geht es um technische Entwicklung in der Automobil-Industrie. Wenn man energisparendes Auto kaufen will, wird die Autoindustrie gezwungen, umweltfreundliche Motoren zu entwickeln. Ein typisches Beispiel ist der Hybride-Antrieb. Derzeit ist solches Auto zwar teuer, gehört aber zur Zukunft. Besonders wenn man lange Strecke fährt, wie auf den Urlaub, kann man viel Geld sparen und viel weniger CO2 in die Luft ausstoßen. Wer sich in der Automobil-Industrie auch in Zukunft behaupten will, muss jetzt schon in diese Technologie investieren. Und Verbraucher sollten auch diese Entwicklung unterstützen. Wenn all diese Ideen in der Praxis umgesetzt werden, wird die Umwelt Schritt für Schritt entlastet.\n    十、事业选择与专业选择(相互关系)   Meinungen:\n  我的个人观点是，成功的学业更确切地说（eher）来自动机。尽管几乎所有的高中毕业生（Abiturienten）有一个目标：凭借着他们的毕业证书找到一份高薪水的职业，借此可以使得事业飞黄腾达（Karrierer）、物质富裕（materieller Wohlstand）成真。但人必须了解（damit rechnen），钱并不一直是作为幸福（Glück）和生活欢乐的唯一决定性的前提条件。更重要的是精神上的丰富（geistige Bereicherung）和自我实现（Selbstverwirklichung）。如果高中毕业生对一个专业如Maschinenbau或Informatik完全没有兴趣（Interessie für）的时候在他们的学习过程中他们也找不到快乐。与之相反如果年轻人喜欢这门学科，他们是一直有动力的。当他们自己在学习过程中有大的困难时，他们可以经受得住（aushalten）并以一个好的成绩结束学业。\nPrinzipiell bin ich der Auffassung, ein erfolgreiches Studium eher vom Motiv bestimmt ist. Zwar haben fast alle Abiturienten ein Ziel, dass sie mit ihrem Studienabschluss eine gut bezahlte Arbeit finden, wodurch sie Karriere und materiellen Wohlstand verwirklichen können. Dabei versuchen sie, ein glückliches Leben zu führen. Aber man muss damit rechnen, dass das Geld nicht immer die einzige entscheidende Voraussetzung für das Glück und die Freude des Lebens schafft. Noch wichtiger sind die geistige Bereicherung und Selbstverwirklichung. Wenn die Arbiturienten überhaupt kein Interesse für ein Studiunfach wie Maschinenbau oder Informatik haben, finden sie auch keinen Spaß während ihres Studiums. Im Vergleich dazu sind die jungen Menschen ständig motiviert, wenn das Studienfach ihnen gefällt. Selbst wenn sie während des Studiums große Schwierigkeiten haben, können sie es aushalten und ihr Studium mit guten Leistungen absolvieren.\n  广为人知的意见是，如学习如哲学或教育学的人文科学家，很难找到一个工作岗位，是彻底（durchaus）不正确的。所有人都知道，哲学视作许多学业的基础（Grundlage）。在我们现代社会中没有哲学知识的工程师几乎不能想象。教育学也是科技发展的根基（Fundament）并培养了（für A. sorgen）有资质的工作人员。因此长远来看人文科学家也有欣欣向荣的（blühend）未来。\nDie weit verbereitete Auffassung ist, dass die Geistenswissenschaftler, die z.B. Phiilosophie oder Pädagogie studieren, nur sehr schwer einen Arbeitsplatz finden, durchaus nicht korrekt. Es ist allen bekannt, dass Philosophie als Grundlage für viele Studienfächer gilt. Ingenieure ohne philosophische Kenntnisse sind in unserer modernen Gesellschaft kaum zu denken. Auch Pädagogik ist das Fundament für die technische Entwicklung und sorgt für qualifizierte Mitarbeiter. Deswegen haben die Geistenswissenschaftler auch auf lange Sicht blühende Zukunft.\n    十一、志愿生态年——是或否？(是都应该从事公益活动，人与社会责任)   Pro:\n  人必须认识到，企业偏爱（bevorzogen）有社会经验的学生。因此这样的人：没有实习经验毕业的人，在寻找职位的过程中碰到更多的困难（auf Schwierigkeiten stoßen）\nMann mus damit rechnen, dass das Unternehmen einen Studierenden mit sozialen Erfahungen bevorzugt. Deswegen haben diejenigen, die früher einen Hochschulabschluss ohne praktische Erfahrungen haben, bei der Suche nach einer Stelle auf mehr Schwierigkeiten stoßen.\n  经验对个人成长时必要的。在为环保、动物保护工作时他们不仅可以获得专业知识，他们的责任意识（Verantwortungsbewusstsen）也会被提高。在儿童-青少年工作或照看病人时他们也学到，人应该如何应对在关键（kritisch）情况里的突发事件（plötzliches Geschehen）。也就是说，他们的处理能力（Handlungsfähigkeit）也会被完善。\nDie Erfahungen sind notwendig für die persönliche Entwicklung. Beim Einsatz für umweltschutz oder Tierschutz können sie nicht nur Fachkenntnisse erwerben, auch ihr Verantwortungsbewusstsen wird erhöht. Bei Kinder- und Jugendlichenarbeit oder Krankenpflege lernen sie auch, wie man in kristischer Situation auf das plötzliche Geschehen reagieren soll. Das heißt, dass ihre Handlungsfähigkeit auch verbessert wird.\n  人应该在社会视角下判断这一个志愿年。首先社会支出会通过一个志愿年而减少。人可以使用这些省下来的钱帮助许多处于贫困处境的（aus armen Sozialverhältnissen）人。\nMan sollte ein freiwilliges Jahr unter dem gesellschaftlichen Aspekt beurteilen. Zuerst wird die soziale Ausgabe durch ein freiwilliges Jahr reduziert. Mit dem ersparten Geld kann man vielen Menschen aus armen Sozialverhältnissen helfen.\n  专业工作者也可以从志愿年获益。因为志愿者已经接手日常工作（Routinearbeit），这些专业工作者可以专注于核心（Wesentlische）。\nFacharbeiter können auch vom freiwilligen Jahr profitieren. Da die Freiwilligen Routinearbeit übernommen haben, können sich die Facharbeiter auf das Wesentliche konzentrieren.\n  人应该站在个人发展角度观察（betrachten）这个现象（Erscheinung）。当年轻人在医院照顾病人时，他们必须了解患者的需求。借此他们不仅可以在医生或护士旁学习专业知识，他们也学习他们如何与他人交流。\nMan sollte diese Erscheinung unter dem Aspekt von persönlicher Entwicklung betrachten. Wenn die junge Leute sich im Krankenhaus um die Patienten kümmern, müssen sie die Bedürfnisse der Patienten kennen. Dadurch können sie nicht nur die Fachkenntnisse beim Arzt oder Krankenschwester lernen, sondern auch sie lernen, wie sie mit anderen zu kommunizieren.\n  除此之外人应该站在社会视角下评价一个志愿年。志愿者促进了社会和谐（die Harmonisierung der Gesellschaft）。他们在日常生活中无偿（ohne Belohnung）帮助残疾人。他们为残疾人或老人购物并同这些人聊天，借此这些人不再感觉孤独（einsam）、无助。他们感受到社会的温暖和生活中的愉悦。所有的这些都对整体（gesamt）社会起积极作用。\nAußerdem sollte man ein freiwilliges Jahr unter dem sozialen Aspekt beurteilen. Die Freiwilligen tragen auch zur Harmonisierung der Gesellschaft bei. Sie helfen den Behinderten im Alltagsleben ohne Belohnung. Sie kaufen für die Behinderten oder alte Menschen ein und unterhalten sich mit diesen Menschen, damit sich diese Menschen nicht mehr einsam und hilflos fühlen. Sie spüren die Wärme der Gesellschaft und Freude im Leben. All das wirkt sich positiv auf die gesamte Gesellschaft aus.\n  一个志愿年有这样的功能，青少年可以借此学习，当他们帮助一个人的时候承担责任（Verantwortung übernehmen）\nEin freiwilliges Jahr hat die Funktion, dass Jugendliche dabei lernen können, Verantwortung zu übernehmen, wenn sie einem helfen.\n    Kontra:\n  青少年失去了有价值的、本来可以用来为获取专业知识安排（）的时间。当他们真的想为环境、动物界、人类做一些什么（in Not tun）的时候，他们必须有相对应的专业知识。仅仅有一颗热情的心是不够的（nicht ausreichen）\nJungendliche verlieren wertvolle Zeit, die sie eigentliche für das Erwerben von Fachkenntnissen einsetzen können. Wenn sie wirklich etwas für die Umwelt, die Tierwelt, die Menschen in Not tun wollen, müssen sie entsprechende Fachkenntnisse haben. Nur ein warmes Herz reicht nicht aus.\n  除此之外越来越多固定的工作职位会因此受威胁，因为志愿者再工作过程中不挣钱。处于花费理由许多机构（Einrichtung）或企业要为容易学习的工作（leicht erlernte Arbeit）安排廉价劳动力。这样的后果是，越来越少的工作岗位将被提供。\nAußerdem werden immer mehr feste Arbeitsplätze dadurch bedroht, denn die Freiwilligen verdienen kein Geld bei der Arbeit. Aus Kostengründen wollen viele Einrichtung oder Untenehmen billige Arbeitskräfter für leicht erlernte Arbeit anstellen. Die Folge davon ist, dass immer weniger Arbeitsplätze angeboten werden.\n  许多岗位如患者护理和残疾人帮助是挑剔的（anspruchsvoll）并这样的工作岗位要求特殊的专业知识。没有医药知识的青少年的工作，会导致病人照顾复杂（Komplikation）\nSchließlich sind viele Stellen wie Krankenpflege und Behinderthilfe anspruchsvoll und solche Arbeitsplätze spezielle Fachkenntnisse verlangen. Die Anstellung von Jugendlichen, die keine medizinischen Kenntnisse haben, können bei der Pflege von kranken Menschen zur Komplikation führen.\n  人可以通过职业教育不做志愿年更早的结束学业。在这种意义上人也可以早早开始找工作。\nMan kann das Studium per die Berufsausbildung ohne freiwilliges Jahr früher beenden. In diesem Sinne kann man auch früh mit der Suche nach Arbeit beginnen.\n  当志愿者拥有所要求的专业知识时，志愿者可能会占据（wegnehmen）专业力量的工作岗位。\nDie Freiwilligen können den Fachkräften Arbeitsplätze wegnehmen, wenn die Freiwilligen die erforderlichen Fachkenntnisse haben.\n    十二、全天学校(青少年教育问题，是否应该给青少年更多自由发展空间)   Pro:\n  父母可以从全天学校获益良多。因为他们再也不用一直去照顾他们的孩子，即使在下午他们所在的工作岗位上仍有许多需要做的事情。除此之外他们也将从他们孩子的监护工作中获得解放(befreit sein)。\nDie Eltern können von der Gantztagesschule vieles profitieren. Denn sie brauchen nicht mehr, sich ständig um ihre Kinder zu kümmern, auch wenn sie nachmittags am Arbeitsplatz noch viel zu erledigen haben. Außerdem sind sie von der Btreuungsarbeit ihrer Kinder befreit.\n    Kontra:\n  然而学校有传授知识的任务。但它们不应该不停地（pausenlos）灌输（eintrichtern）知识。因为学生也需要时间，消化所学的并正确地理解。\nDie Schule hat zwar die Aufgabe, das Wissen zu vermitteln. Aber sie sollten das Wissen nicht pausenlos eintrichtern. Denn die Schüler brauchen auch Zeit, das Gelernte zu verdauern und richtig zu verstehen.\n  除此之外学生需要放松的时间。科学已证明的是（Es ist wissenschaftlich bewiesen, dass），人在学习过程中集中注意力在学习材料上最长1小时。因此下午的课间休息（der unterrichtsfreie Nachmittag）对高效学习时不可或缺的。\nAußerdem benötigen die Schüler die Zeit, sich zu entspannen. Es ist wissenschaftlich bewiesen, dass man sich beim Lernen höchsten eine Stunde auf den Lernstoff konzentrieren kann. Deswegen ist der unterrichtsfreie Nachmittag für das effektive Lernen unentbehrlich.\n  全天雪线应该在健康的角度下思考。学生需要有规律的体育活动。当他们下午没有课程时，他们可以和朋友们踢足球、游泳或打羽毛球（Federball）。这不仅关于身体训练，也关于他们交流能力的提高。在一同玩耍的过程中他们可以亲自体会，合作、信任、团结（Zusammenhalt）是多么的重要。所有的这些能力对个人成长是有着大的含义的。\nZudem sollte die Ganztagsschule unter dem gesundheitlichen Aspekt betrachten. Die Schüler brauchen regelmäßige sportliche Aktivität. Wenn sie nachmittags keine Schule haben, können sie mit Freunden Fußball spielen, schwimmen gehen oder Federball spelen. Dabei geht es nicht nur um das körperliche Training, sondern auch um die Steigerung ihrer Kommunikationsfähigkeit. Beim Zusammenspiel können sie persönlich erleben, wie wichtig Kooperation, Vertrauen und Zusammenhalt sind. All diese Fähigkeiten sind für die persönliche Entwicklung von großer Bedeutung.\n  下午的课间休息提供了学生更好控制自己的可能性。他们可以学习，人如何为学习和娱乐（Vergnügung）分配（einteilen）时间，如何有意义地安排（arrangieren）空闲时间。这不仅对他们的在校时间是重要的，也对他们的整个生活很重要。\nSchließlich bietet der unterrichtsfreie Nachmittag den Schülern die Möglichkeit, sich selbst zu kontrollieren. Sie können lernen, wie man Zeit für das Lernen und die Vergnügung einteilt und wie man seine Freizeit sinnvoll arrangiert. Das ist nicht nur wichtig für ihre Schulzeit, sondern auch für ihr ganzes Leben.\n    十三、互联网是机会吗？(现代媒体对经济发展的影响)   Pro:\n  互联网提供了机会，所有人自由地表达（Meinungen äußern）自己的意见。每天再互联网上有关于政治、日常生活中的变化如生活用品价格的上涨的个人意见不同的调查（Umfrage）。通过互联网人们可以知道他们所处的困境（in Notlage ihre Schwierigkeiten）。\nDas Internet bietet die Möglichkeit, dass alle Menschen ihre Meinung frei zu äußern. Jeden Tag gibt es im Internet verschiedene Umfragen um die eigene Meinung über Politik, Veränderugen im Alltag wie Preiserhöhung von Lebensmitteln. Durch das Internet können die Menschen in Notlage ihre Schwierigkeiten wissen lassen.\n  除此之外人应该从经济的角度评论增长的互联网使用。尽管不排除，互联网上有欺诈（Betrügerei）。\nAußerdem sollte man die zunehmende Nutzung vom Internet aus der wirtschaftlichen Perspektive beurteilen. Zwar ist es nicht auszuschlißen, dass es im Internet Betrügerei gibt.\n  人也应该明白，互联网为一个国家的经济增长做出了巨大贡献。许多小公司是通过在线商务（Online-Geschäft）被拯救的。现在它们大多数（überwiegend）通过互联网销售它们的产品或服务。借此许多失业者再次找到了工作岗位。\nDoch man muss einsehen, dass das Internet großen Beitrag zur wirtschaftlichen Entwicklung eines Landes leistet. Viele kleine Firmen sind durch das Online-Geschäft gerettet. Jetzt verkaufen sie ihre Produkte oder Dienstleistungen schon überwiegend durch das Internet. Dabei haben viele Arbeitslose wieder neuen Arbeitsplatz gefunden.\n  此外人应该从国家与人民之间的文化交流观察互联网现象。尽管不能绝对地（hunderprozentig）否认：歧视意见（Diskriminierungsideen）或敌视（Feindseligkeit）自我传播。\nWeiterhin sollte man das Phänomen vom Internet aus der Sicht des Kulturaustausches zwischen den Ländern und Völkern betrachten. Es ist zwar nicht hunderprozentig zu vermeiden, dass sich Diskriminierungsideen oder Feindseligkeit verbreiten.\n  互联网时人们可以是人们认知其他的风俗（Sitten）和文化。借此人发现，其他州的人如何生活，人在国际贸易（internationaler Handel）应该尊重（berücksichtigen）何种传统和习惯。\nDoch das Internet ermöglicht den Menschen, andere Sitten und Kulturen kennenzulernen. Dabei erfährt man, wie man in anderen Kontinenten lebt und welche Traditionen und Gewohnheiten man beim internationalen Handel berücksichtigen soll.\n    Kontra:\n  当管控被忽略(vernachlässigen)时，会产生私人数据在未经当事人(Betroffene)的允许便被公布在互联网上的危险。\nEs besteht die Gefahr, dass private Daten ohne Erlaubnis der Betroffenen im Internet veröffentlicht werden, wenn die Kontrolle vernachlässigt wird.\n    十四、学业还是工作(青少年教育，是否应该打工)   Pro:\n  学生有机会，将他们在学校已学到的专业知识在实习中转化，这对往后的学习和职业生涯十分重要。一方面他们可以深化已学过的知识并正确地掌握学习的意义。另一方面他们在工作过程中可以学到新的东西。借此他们将积极学习（zum Lernen motiviert werden）。\nDie Schulkinder haben wohl die Möglichkeit, die Fachkenntnisse, die sie in der Schule gelernt haben, in die Praxis umzusetzen, was besonders wichtig für das spätere Studium und Berufsleben ist. Zum einen können sie das Gelernte vertiefen und den Sinn des Lernens richtig begreifen, zum anderen können sie sich etwas Neues während der Arbeit erwerben. Dadurch werden sie zum Lernen motiviert.\n  他们可以更好地理解父母的辛劳（Anstreng），当他们在家照料一个年幼的兄弟姐妹（Geschwister）的时候。借此他们可以发现，抚养一个孩子（ein Kind aufziehen）有多么的困难。\nSie können die Anstreng ihrer Eltern besser verstehen, wenn sie sich z.B. zu Hause um kleine Geschwister kümmern. Dadurch können sie erfahren, wie schwer es ist, ein Kind aufzuziehen.\n  他们可以提高他们的处理能力和思维能力。在工作过程中他们得到特定的任务：偶尔这些任务不是太容易被完成（erledigen）。在这种情况下（In diesem Fall）学生必须想出可能的解决方案并对不同的情境做反应。这是一个好的训练。因此有兼职的学生在学习过程中有更少的困难，相比没有兼职工作的学生。\nSie können ihre Handlungsfähigkeit und Denkfähigkeit erhöhen. Beim Jobben bekommen sie bestimmte Aufgaben, die manchmal nicht so ganz leicht zu erledigen sind. In diesem Fall müssen Schulkinder mögliche Lösungen ausdenken und auf verschiedenen Situationen reagieren. Das ist ein gutes Training. Deswegen haben die Schulkinder mit Nebenjob weniger Schwierigkeiten beim Lernen in der Schule als die Schulkinder, die keinen Nebenjob machen.\n  因为工作市场上的激烈竞争实习经验在求职过程中扮演者越来越重要的角色。学校之后的一份工作有助于提供学生一个个人发现工作岗位上视角（？）的机会。他们可以在工作过程中观察，现实生活中所有的一切是被如何完成的以及哪些知识是必要的。\nWegen der harten Konkurrenz auf dem Arbeitsmarkt spielen praktische Erfahrungen eine immer wichtigere Rolle bei der Suche nach einer Arbeit. Ein Job nach der Schule trägt dazu bei, den Schulkindern eine Chance anzubieten, das Gesehen am Arbeitsplatz persönlich zu erfahren. Sie können während des Jobs beobachten, wie alles in der Realität gemacht wird und welche Kenntnisse dabei erforderlich sind.\n  除此之外学生的自立能力和处理能力通过工作而被提高。有时学生必须应对不同的问题反应并在此过程中同专业工作者一同找到合适的解决方法。这种能力不在教科书里并只能通过工作被获得。有这种能力的人在未来得到更好地机会。\nAußerdem werden die Selbstständigkeit und Handlungsfähigkeit der Schüler durch den Job erhöht. Manchmal müssen die Schulkinder auf verschiedene Probleme reagieren und dabei entsprechende Lösungen mit Facharbeitern zusammen finden. Diese Fähigkeit steht nicht in den Lehrbüchern und kann nur durch Job erworben werden. Wer solche Fähigkeit hat, bekommt in Zukunft bessere Chance.\n  学生会被工作激发学习知识的积极性。在实习过程中他们认识到知识的必要性之后，他们想要自己学习知识。他们在学习过程中不再感到无聊。\nSchließlich werden die Schulkinder durch Job zum Lernen von Kenntnisse motiviert. Nachdem sie in der Praxis die Notwendigkeit der Kenntnisse erkannt haben, wollen sie selbst Kenntnisse lernen. Sie fühlen sich beim Lernen nicht mehr langweilig.\n    Kontra:\n  一份兼职工作或多或少都会花费时间和精力。\nEin Nebenjob kostet mehr oder weniger Zeit und Energie.\n    十五、年长或年轻的教师？(青少年教育、与青少年沟通与教师就业之间的矛盾)   für jungere Lehrerinnen und Lehrer:\n  首先这事关健康和能力(Leistungsfähigkeit)。年长的教师身体状况不再是如此充沛的。因为学校里的工作经常是累人(anstrengend)的， 年长的教师很容易患病。因此经常会发生以下情况：课程时不时的(ab und zu)停止(ausfallen)。\nErstens geht es um die Gesundheit und Leistungsfähigkeit. Ältere Lehrer sind körperlich nicht mehr so fit. Da die Arbeit in der Schule oft anstrengend ist, werden ältere Lehrer leicht krank. Deswegen passiert es oft, dass der Unterricht ab und zu ausfällt.\n  除此之外他们的收入高于年轻教师的收入。也就是说，学校必须支付(auszahlen)更多的钱，这些钱实际上应该被用于(bereitstellen)置购(Beschaffung)现代设备如电脑或学校基础设施的改善如操场或体育馆。所有的这些对教学质量以及学生身体健康的提高都是至关重要的。\nAußerdem sind ihr Einkommen höher als das jüngeren Lehrer, d.h Die Schule muss mehr Geld auszahlen, das eigentlich für die Beschaffung moderner Geräte wie Computer oder die Verbesserung der Infrastruktur der Schule wie Sportplatz oder Sporthalle bereitgestellt werden soll. All das ist besonders wichtig für die Erhöhung von Lehrqualität und körperliche Gesundheit der Schüler.\n  相反地，与年长的教师相比尽管年轻的教师有较少的教学经验，但是年轻的教师是活跃的(dynamisch)、这有益于(dienen zu)，他们同学生有好的联系。他们可以同学生谈论体育和时尚(Mode)。借此师生之间的关系将被深化(vertiefen)。\nIm Vergleich dazu haben die jüngeren Lehrer zwar wenigere Lehrerfahrungen im Vergleich zu älteren Lehrern, aber die jüngere Lehrer sind dynamisch. Dies dient dazu, dass sie einen guten Kontakt mit Schülern haben. Sie können über Sport oder Mode mit Schüler diskutieren. Dadurch wird die Beziehung zwischen Lehrern und Schülern vertieft.\n  从学生的视角来看，同年轻的教师交流更加容易。在学生的眼里年轻的教师向他们的大哥哥或大姐姐。因此学生会同年轻的教师讲出他们的顾虑。处于学生的这种角度青年教师是不可或缺的（unentbehrlich）\nAus der Sicht der Schüler ist es leichter, mit jüngeren Lehrern zu kommunizieren. In den Augen der Schüler sind die jüngeren Lehrer wie ihre ältere Brüder oder Schwester. Deswegen wollen Schüler ihre Sorgen bei jüngeren Lehrern aussprechen. Aus der Aspekt der Schulen sind die jüngen Lehrer unentbehrlich.\n  除此之外年轻的教师对现代科技保持着开放的态度(gegenüber aufgeschlossen stehen)。他们可以通过互联网快速的更新他们的知识，因为他们连续地使用电脑和互联网工作。通过互联网他们可以找到(herausfinden)高新技术或者新的点子，他们使用这些以使课程丰富(bereichern)。借此学生有机会获得(schaffen)现代科技的概况(Überblick)并更有动力去学习。\nAußerdem stehen jüngere Lehrer der modernen Technik gegenüber aufgeschlossen. Sie können ihre Kenntnis durch Internet schnell erneuern, weil sie stöndig mit Computer und Internet arbeiten. Durch das Internet können sie High-Technick oder neue Idee herausfinden, mit der sie Unterricht bereichern. Dabei haben die Schüler die Möglichkeit, einen Überblick über die moderne Technik zu schaffen und mehr zum Lernen motiviert zu werden.\n  现如今可以观察到，新兴媒体是基础教育和高级教育完整的（integral）组成部分(Bestandteil)。青年教师有将新知识、新的思考方式带入教育的能力。这的前提是来自互联网、电脑以及其他现代媒体的知识。因此这些都是必要的，因为学生今后不论是在大学还是在职业生活中都需要这种能力（Fertigkait）。除此之外通过安置（Einsatz)现代媒体更生动（lebendig）、更有吸引力。学生会更有动力学习，实际上这将对学业成绩有所贡献。\nZurziet ist es zu beobachten, dass die neuen Medien ein integraler Bestandteil der Grund- und Hochschulausbilung ist. Die jüngen Lehrer haben die Fähigkeit, neues Wissen und neue Dankenweise in die Ausbildung einzubringen. Die Voraussetzung dafür sind die Kenntnisse von Internet, Computer und dem kompetenten Umgang mit anderen modernen Medien. All das ist deswegen notwendig, weil die Schüler später sowohl an der Hochschule als auch in ihrem Berufsleben die Fertigkeit brauchen. Außerdem wird der Unterricht durch den Einsatz von modernen Medien lebendiger und attraktiver. Die Schüler werden noch besser zum Lernen motiviert, was wesentlich zur Schulleistungen beiträgt.\n  首先这是可能的：年长的教师会发现理解、得到新的点子十分困难。他们中很少有人通过互联网收集学生感兴趣的信息。除此之外他们经常把偶尔提出古怪（seltsam）问题的学生视为问题儿童（problematische Kinder）。\nZuerst ist es möglich, dass ältere Lehrer es sehr schwer finden, neue Ideen zu verstehen und zu erhalten. Selten sammeln sie durch das Internet die Informationen, die die Schüler interessieren. Auch halten sie oft die Schüler für problematische Kinder, die ab und zu einige seltsame Fragen stellen.\n    für ältere Lehrerinnen und Lehrer:\n  年长的教师可以使用许多经验和知识。在学生为结业考试的准备过程年长的教师可以稍微更好地帮助。除此之外不排除(ausschließen)，按照大多数家长的意见年长的教师是值得信任的（zuverlässig）、可靠的(verantwortlich)。\nDie älteren Lehrer verfügen über viele Erfahrungen und das Wissen. Die älteren Lehrer können den Schülern beim Vorbereitung für Abitur vielleicht ein bisschen besser helfen. Außerdem ist es nicht auszuschlißen, dass nach der Meinung der meisten Eltern ältere Lehrer zuverlässig und verantworlich sind.\n    十六、营养摄入教学科目(中小学课程设置与青少年饮食习惯的培养)   Pro:\n  学校在儿童教育工程中扮演着重要的角色。学生，尤其是小学生，会接受老师说的，作为父母所要求的。\nDie Schule spielt eine sehr wichtige Rolle bei der Kindererziehung. Die Schulkinder, besonders in der Grundschule, akzeptieren eher das, was die Lehrer sagen, als das, was die Eltern auffordern.\n  除此之外儿童只有当认识到超重的潜在的（latent）危险时才倾向于（zu D. neigen）健康的饮食习惯。他们主要在学校学习这些理论。\nAußerdem neigen die Kinder zu der gesunden Essgewohnheit nur, wenn sie die Ursachen bzw. das latente Risiko vom Übergewicht erkennen. Und diese Theorien lernen sie haupsächlich in der Schule.\n  学生经常相互比较并效仿（nachmachen）其他的学生。在学校他们一直交换他们的时髦的东西（die Sachen, die im Trend stehen）的观点和信息，尤其是小吃和快餐如薯片和汉堡这类容易导致超重的东西。当学校采取传授-管控措施时，儿童可以更好地发展。\nDie Schulkinder vergleichen sich oft miteinander und machen den anderen Mitschülern nach. In der Schule tauschen sie immer ihre Meinungen und Informationen über die Sachen, die im Trend stehen, besonders über Snacks und Fastfood wie Kartoffeln Chips und Hamburger, die leicht zu Übergewicht führen können. Wenn Schule die Vermittlungs- und Kontrollefunktion übernimmt, können sich Kinder besser entwickeln.\n    Kontra:\n  儿童的饮食习惯是诸如媒体和父母等不同因素的融合（Zusammenspiel）。因为儿童通常模仿他们父母的饮食习惯和生活方式，或通过媒体里的广告简单的接受甜食和快餐。\nDie Essgewohnheit der Kinder ist ein Zusammenspiel verschiedener Faktoren wie Medien und Eltern. Denn die Kinder ahmen normalerweise die Essgewohnheit und die Lebensweise ihrer Eltern nach oder akzeptieren einfach Süßigkeiten und Fastfood durch Werbungen in Medien.\n  学生呆在他们父母身边远比呆在学校时间长。他们在家吃早餐晚餐。营养学对儿童来讲也是一份附加的负担。当这门营养学专业是必修的（obligatorisch）时候，学生必须花费时间（Zeit nehmen）学习一些其他的东西并为考试做准备（sich auf A. vorbereiten）。放学后学生有太多的作业，以至于他们拥有为体育的更少的时间，当他们必须写新的专业的附加的任务或背诵。\nDie Schulkinder bleiben bei ihren Eltern viel länger als in der Schule. Sie frühstücken und Abend essen zu Hause. Weiterhin ist das Fach Ernährung eine zusätzliche Belastung für die Kinder. Wenn das Schulfach Ernährung obligatorisch ist, müssen sich die Schulkinder noch Zeit nehmen, um etwas zu lernen und sich auf die Prüfung vorzubereiten, dabei verlieren sie aber viel Zeit für die Bewegung. Nach der Schule haben Kinder zu viele Hausaufgaben, so dass sie noch weniger Zeit für Sport haben, wenn sie zusätzlich Aufgaben für das neue Fach schreiben oder auswendig lernen müssen.\n  父母应该亲自照顾他们儿童的营养。父母在家里决定儿童吃什么。当父母经常带着他们的孩子去麦当劳，老师在课堂上所阐述(erzählen)的快餐的坏的作用完全不适用（Es nützt gar nicht, dass）。\nDie Eltern soll sich um die gesunde Ernährung ihrer Kinder kümmern. Was die Kinder essen, entscheiden sich die Eltern zu Hause. Wenn die Eltern oft mit ihren Kindern in McDonald´s gehen, nützt es gar nicht, dass die Lehrer im Unterricht etwas von schlechter Auswikung des Fastfoods erzählen.\n  很多教师是此方面未被认证的（zu D. qualifizieren）。因为为这门专业必须是系统学习过营养科学的老师才能被雇用。\nViele Lehrer sind nicht dazu qualifiziert. Denn für das Scuhlfach Ernährung müssen Lehrer angestellt werden, die systematisch die Ernährungswissenschaften studiert haben.\n    十七、移民话题(多元文化领域问题)   Pro:\n  移民对许多在发达国家的企业来讲是一份后备力量（Nothilfe）。这些国家因为持续低下的（andauernd niedriger）出生率而缺少劳动力。这如今对企业和发达国家的一个巨大的障碍（Barrierer）。移民会对此有帮助。\nDie Migranten sind eine Nothilfe für viele Unternehmen in den Industrieländern. Wegen andauernd niedrieger Geburtenrate mangelt es diesen Ländern an Arbeitskräften. Dies ist jetzt schon eine große Barriere für die Entwicklung der Unternehmen und der Industrieländer. Dabei helfen die Migranten.\n  尤其要提到的是（Besonders zu erwähnen ist, dass\u0026hellip;），许多移民受过职业教育或有已结束的高校教育。因此他们可以为许多企业和社会的发展做杰出的（hervorragend）贡献。\nBesonders zu erwähnen ist, dass viele Migranten beruflich ausgebildet sind oder eine abgeschlossene Hochschulausbildung haben. Deswegen können sie hervorragenden Beitrag zur Entwicklung vieler Unternehmen und der Gesellschaft leisten.\n  他们也给他们迁往的国家带来了多样的文化。从此本地人尤其获益良多。因为他们整日同来自全世界的人一同生活，他们有机会私下打听外来文化和其他的心性。这对一个国家、一个民族的全球化来说是一个重要的前提之一。\nWeiterhin bringen sie dem Land, in das sie einwandern, viefältige Kultur. Davon profitieren die Einheimischen besonders viel. Da sie im Alltag mit Menschen aus aller Welt zusammen leben, haben sie die Möglichkeit, sich genau und persönlich über die fremde Kultur und andere Mentalität zu informieren. Das ist eine der wichtigen Voraussetzung für eine Globalisierung eines Landes und eines Volkes.\n  移民经常接过（übernehmen）本地人（Einheimische）不愿做的工作。一个典型的例子是垃圾清理（Müllentsorgung）。一些移民在东道国也从事商业（Geschäfte machen）并借此为本地人创造新的工作岗位。在这个意义上（In diesem Sinn）人可以说，移民为东道国的经济做了大的贡献（Beitrag zu D. leisten）并扮演着一个不可或缺的角色。\nDie Migranten übernehmen oft die Aufgaben, die die Einheimischen nicht machen wollen. Ein typisches Beispiel ist die Müllentsorgung. Manche Migranten machen auch Geschäfte im Gastland und schaffen damit auch neue Arbeitsplätze für die Einheimischen. In diesem Sinn kann man wohl sagen, dass die Migranten einen großen Beitrag zur Wirtschafsentwicklung des Gastlandes leisten und eine unentbehrliche Rolle spielen.\n  在发达国家有许多人，他们已经在那里学习或生活过。他们现在搬去（auswandern）另一个国家，因为他们要在一个有着纯净空气的安静的生活空间居住。他们也将技术和心性（Mentalität）带到了东道国。这造成了，在发展中国家的人们也有机会打听最新的研究情况。世界范围的全球化进程便是如此工作的。\nEs gibt viele Menschen in den Industrieländern, die dort studiert und gelebt haben. Sie wandern nun in ein anderes Land aus, weil sie im ruhigen Lebensraum mit sauberer Luft wohnen wollen. Sie bringen auch Technik und Mentalität in das Gastland. Dies führt dazu, dass die Menschen in den Entwicklungsland auch die Möglichkeit haben, sich über den neusten Forschungsstand zu informieren. So funktioniert die Globalisierung weltweit.\n    Kontra:\n  东道国（Gastland）的经济会被或多或少的影响，如果移民将他们的钱待会他们的祖国。\nDie Wirtschaft im Gastland wird mehr oder weniger beeinflusst, wenn die Migranten ihr Geld nach eigner Heimat mitbringen.\n    十八、 工作的孩子(学习负担加重问题、青少年是否应该了解社会问题)   Pro:\n  伙子和姑娘的自立能力在工作过程中小扮演着十分重要的角色。\nDie Selbstständigkeit bei der Arbeit von Jungen un Mädchen spielt eine wichtige Rolle.\n  不可忽视的是（Es sit nicht auszuschließen, dass\u0026hellip;），家庭通过儿童工作经济上稍微可以减轻一些。\nEs ist nicht auszuschließen, dass die Familie durch Arbeit von Kindern finanziell ein bisschen erleichtert werden kann.\n    Kontra:\n  显而易见的是（Es liegt klar aif der Hand, dass），因为工作儿童错失了（verpassen）有价值的选择：被系统地（systematisch）教育，如果他们中断学校教育（Schulbildung abbrechen）并工作。如果一个人缺失了基础的学校教育，这将促进（贬义），文盲率（Analphabetenquote）在这个国家会提高（sich erhöhen）。\nEs liegt klar auf der Hand, dass Kinder wegen Arbeit wertvolle Chance verpassen, systematisch ausgebildet zu werden, wenn sie Schulbildung abbrechen und arbeiten. Dies trägt dazu bei, dass sich die Analphebetenquote in diesem Land erhöhen kann, wenn einem die gründliche Schulausbildung fehlt.\n  长远（Ferne）来看健康方面的损伤作为后果也不能被无视。因为差劲的工作条件和沉重的负担（Belastung）儿童经常承受特定的疾病。但一家儿童工作的企业，并不关照儿童的健康，而仅仅是关照价钱。\nFerne sind gesundheitliche Schäden als Folge nicht zu vermeiden. Wegen der schlimmen Arbeitsbedingungen und schwerer Belastung leiden Kinder öfter an bestimmten Krankheiten. Aber ein Betrieb, der Kinder beschäftigt, kümmert sich nicht um die Gesundheit der Kinder, sondern nur um das Geld.\n  除此之外儿童工作将会被支付很差劲的薪水。因为他们只做简单的工作（Arbeit leisten）。他们挣得的，只能很少的帮助减轻家庭的经济负担。\nAußerdem wird Kinderaibeit sehr schlecht bezahlt. Denn sie leisten nur einfache Arbeit. Was sie verdienen, hilft aber nur wenig, die Familie finanziell zu entlasten.\n  儿童在危险且剥削性质（ausbeuterisch）的条件下为微薄的（kümmerlich）收入辛苦工作（schupfen），并为此牺牲（opfern）了自己的健康。长远来看缺乏的教育是一个后果，但其中之一的原因就是儿童工作。因为家长无法承担（sich leisten）儿童上学或忽视了教育的意义。这些儿童得不到一份高薪工作所必要知识的机会。他们必须一生（das Leben lang）做简单的、廉价的工作。当这些儿童长大后，拥有了自己的家庭，也就是说拥有了自己的孩子，所有的一切都将如同他们的父母运行。以此产生了恶性循环（Teufelkreis）。为了打断（durchbrechen）这个恶性循环，父母必须如此想（auf A. kommen）：知识是对他们以及他们的孩子唯一的救赎（Rettung）\nDie Kinder schuften unter gefährlichen und ausbeuterischen Bedingungen für kümmerliches Einkommen und opfern dabei ihre Gesundheit. Ferne ist mangelnde Bildung eine Folge, aber auch eine der Ursachen von Kinderarbeit. Weil die Eltern sich einen Schulbesuch der Kinder nicht leisten können oder die Bedeutung der Bildung ignorieren, bekommen diese Kinder keine Gelegenheit, notwendige Kenntnisse für eine gut bezahlte Arbeit zu bekommen. Sie müssen das Leben lang eine einfache und schlecht bezahlte Arbeit machen. Wenn diese Kinder groß werden, eigene Familie bzw. eigene Kinder haben, läuft alles genauso wie bei ihren Eltern. So entsteht der Teufelskreis. Um diesen Teufelskreis zu durchbrechen, müssen die Eltern darauf kommen, dass das Wissen die einzige Rettung für sich und vor allem für ihre Kinder ist.\n    十九、留学是否有必要？   Pro:\n  积极（intensiv）接纳外国学生有诸多优点。因为外国学生来自不同文化，在德国高校的学生有机会在学习时间认识不同的文化和心性（Mentalität）。这将促进毕业生没有太大的困难而变得国际化。这种资质在一个全球化的世界是十分受欢迎的（gefragt）。通过毕业生的成功德国高校自然也会在专业世界（Fachwelt）完善它们的声誉（Ansehen）。\nDaneben gibt es viele Vorteile für die intensive Aufnahme ausländischer Studierender. Da ausländische Studierende aus verschiedenen Kultur kommen, haben Studierende an deutschen Hochschulen die Möglichkeit, während der Studienzeit verschiedene Kurturen und Mentalitäten kennenzulernen. Dies trägt dazu bei, dass die Absolventen ohne große Schwierigkeiten international eingesetzt werden. In einer globalisierten Welt ist diese Qualifikation bei Unternehmen besonders gefragt. Durch den Erfolg der Absolventen verbessern deutsche Hochschulen natürlich auch ihr Ansehen in der Fachwelt.\n  此措施旨在于（sorgen dafür, dass\u0026hellip;），德国高校可以同外国高校建立联系。因为许多外国学业申请者早已在他们的祖国结结束了学业。如果他们在德国高校学习的话，他们将会促进他们祖国的高校与德国高校之间的联系。通过国际合作德国高校必然打造他们的名声（Ruf schaffen）。\nDiese Maßnahme sorgt dafür, dass die deutschen Hochschulen Kontakt mit ausländischen Hochschulen verknüpfen können. Denn viele ausländische Studienbewerber haben schon ein abgeschlossenes Studium in ihrem Heimat. Wenn sie an deutschen Hochschulen studieren, werden sie Kontakt zwischen Hochschule in ihrem Heimatland und deutscher Hochschule vermitteln. Durch internationale Zusammenarbeit werden deutsche Hochschulen sicherlich ihren Ruf schaffen.\n  外国学生带来了多样的文化。这将有助于德国高校和德国学生体验其他文化。通过与外国学生的交流德国学生不仅完善了他们的外语知识，也完善了他们的交流能力。在全球化的框架下越来越多的德国人为外国企业工作。因此这些德国学生在在校期间获得的文化经验可以对他们的职业生活十分重要。毕业生越成功，德国高校的形象（Image）也就越好。\nDie ausländischen Studenten bringen vielfältige Kulturen mit sich. Dies trägt dazu bei, dass deutsche Hochschulen und Studierende andere Kulturen erfahren können. Durch die Kommunikation mit ausländischen Studierenden verbessern die deutschen Studenten nicht nur ihre Fremdsprachenkenntnisse, sondern auch ihre Kommunikationsfähigkeit. Im Rahmen der Globalisierung arbeiten immer mehr Deutsche für ausländische Firmen. Deshalb können die kulturellen Erfahrungen, die die deutschen Studenten an der Universität erworben haben, sehr wichtig für ihr Berufsleben sein. Je erfolgreicher die Absolventen sind, desto besser wird das Image deutscher Hochschulen.\n    Kontra:\n  通过限制外国学生教授可以在学期、Vorlesung上传授更多的知识，当大多数参与者是德国学生的时候。\nDurch die Begrenzung der ausländischen Studierenden können die Professoren in Seminar und Vorlesung mehr Kenntnisse vermitteln, wenn die meisten Teilnehmer deutsche Studierende sind.\n  随着外国学生数目的增长高校资源会紧缺。学生可能必须为学生公寓的一间房间或辅导时间的一个Termin等待稍长一些。但这些困难恰好对学生来讲是一个有意义的前提。此间他们应该尝试，用自己的力量解决问题、克服困难（Schwierigkeiten bewältigen）。这种自立能力对他们的职业生活尤为重要。因为在他们的职业中高校毕业生所有可能的任务和问题。在此他们的处理能力是一项决定性的资质，这也是德国高校应该重视(auf\u0026hellip; großen Wert legen)的\n(优点+缺点)Mit der zunehmenden Zahl ausländischer Studierenden werden die Ressourcen von Hochschulen knapp. Die Studierenden, müssen vielleicht ein bisschen länger auf ein Zimmer im Studentenwohnheim oder einen Termin für Sprechstunden warten. Aber solche Schwierigkeiten sind gerade eine sinnvolle Herausforderung für Studierende. Dabei sollen sie versuchen, mit eigener Kraft Probleme zu lösen und Schwierigkeiten selbst zu bewältigen. Diese Selbstständigkeit ist besonders wichtig für ihr Berufsleben. Denn in ihrem Beruf haben die Hochschulabsolventen alle möglichen Aufgaben und Probleme. Dabei ist ihre Handlungsfähigkeit eine entscheidene Qualifikation, worauf deutsche Hochschulen großen Wert legen sollen.\n    二十、大学生实习是否重要？   Pro:\n  学生有很多机会，将他们的知识在实习中投入使用（in A umsetzen）。借此这成为了可能：在大学中被传授的理论，同实践建立联系（in Verbindung setzen）。他们也会学到，他们为何种问题使用何种理论，以及他们还缺乏什么。他们在此也可以发现（erfahren），人如何同同事、顾客以及科技设备（Anlage）打交道（umgehen）。\nStudierende haben mehr Gelegenheiten, ihr Wissen in der Praxis umzusetzen. Dadurch sind die in der Lage, Theorie, die an der Uni vermittelt ist, mit Praxis in Verbindung zu setzen. Sie lernen auch, welche Theorie sie für welche praktische Probleme verwenden sollen und was ihnen noch fehlt. Sie können dabei noch erfahren, wie man mit Kollegen, Kunden oder technischer Anlage umgeht.\n  学生不仅会认识许多专业人士，也可以为今后的职业生活铺平道路（Weg zu \u0026hellip; ebnen）。许多专业人士有着年长的实践经验，这些经验对高校毕业生的工作培训（Einarbeitung）很有价值而且恰恰（eben）不在任何教科书里。在实习期间他们也有机会，向雇主亲自介绍自己并建立一个积极的影响。这事关（sorgen für）一个相对顺利（reibungslos）的雇用。\nStudierende können nicht nur viele Fachleute kennen lernen, sondern auch den Weg zu späten Berufsleben ebnen. Viele Fachleute haben langjährige praktische Erfahrungen. Diese Erfahrungen sind für die Einarbeitung der Hochschulabsolventen wertvoll und stehen eben nicht in irgendwelchen Lehrbüchern. Während des Praktikums haben sie auch die Möglichkeit, sich dem Arbeitgeber persönlich vorzustellen und dabei einen positiven Eindruck zu machen. Dies sorgt für eine relativ reibungslose Einstellung.\n  人可以找到很多使用他的知识的机会。当一位医学生面前有一位患者时，他便有可能实际使用他在教科书上读到过的治疗法。\nMan kann mehr Chancen haben, Anwendung für sein Wissen finden. Wenn ein Mediziner einen Patienten vor sich hat, hat er die Möglichkeit, Therapie, die er in den Lehrbüchern gelesen hat, praktisch verwenden.\n  学生可以同企业建立(verknüpfen)紧密的联系(Kontakt zu)并认识许多专业人士。这可以变得很有帮助：当他们之后寻找一份工作的时候。一名想要在办公厅(Kanzlei)工作的法律学者可以通过实习打听判决(Gerichts)前的流程。这是赢得一场官司处理的第一步也是重要的一步(Schritt zu)\nStudierende können engen Kontakt zu Unternehmen verknüpfen und viele Fachleute kennen lernen. Das kann hilfreich sein, wenn sie später einen Job suchen. Durch Praktikum kann ein Rechtswissenschaftler, der in einer Kanzlei arbeiten möchte, sich über den Prozess vor Gericht informieren. Das wäre ein erster und wichtiger Schritt zum Gewinn einer Gerichtsverhandlung.\n    Kontra:\n  有一些将实习生作为廉价劳动动力使用的企业。实习对高校毕业生来讲也是一个附加的时间浪费。\nEs gibt einige Unternehmen, welche die Praktikanten als günstige Arbeitskräfte ausnutzen. Auch für Hochshculabsolventen ist ein Praktikum ein zusätzlicher Zeitaufwand.\n  一些实习生可以在学业结束后在企业花费一些更多的时间。除此之外一些实习生不可以凭他们的工作得到薪水。\nEinige Praktikanten können nach ihrem Studium bei Unternehmen ein bisschen mehr Zeit aufwenden. Außerdem können manche Praktikanten für ihre Arbeit kein Geld bekommen.\n    ","permalink":"https://daijiabin.github.io/testdaf-reference/","tags":["German"],"title":"TestDaF Arguments ( German / zh-CN )"},{"categories":null,"contents":"+++ +++\n","permalink":"https://daijiabin.github.io/search/","tags":null,"title":"Search"}]